{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18397a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# --- 1. Global Configuration ---\n",
    "\n",
    "# --- Model definitions and their required input sizes ---\n",
    "MODELS = {\n",
    "    \"MobileNetV2\": {\"class\": tf.keras.applications.MobileNetV2, \"input_size\": 224},\n",
    "    \"MobileNetV3Large\": {\"class\": tf.keras.applications.MobileNetV3Large, \"input_size\": 224},\n",
    "    \"EfficientNetB0\": {\"class\": tf.keras.applications.EfficientNetB0, \"input_size\": 224},\n",
    "    \"EfficientNetB7\": {\"class\": tf.keras.applications.EfficientNetB7, \"input_size\": 600},\n",
    "    \"InceptionV3\": {\"class\": tf.keras.applications.InceptionV3, \"input_size\": 299},\n",
    "    \"InceptionResNetV2\": {\"class\": tf.keras.applications.InceptionResNetV2, \"input_size\": 299},\n",
    "    \"VGG16\": {\"class\": tf.keras.applications.VGG16, \"input_size\": 224},\n",
    "    \"VGG19\": {\"class\": tf.keras.applications.VGG19, \"input_size\": 224},\n",
    "    \"ResNet50\": {\"class\": tf.keras.applications.ResNet50, \"input_size\": 224},\n",
    "    \"ResNet152\": {\"class\": tf.keras.applications.ResNet152, \"input_size\": 224}\n",
    "}\n",
    "\n",
    "# --- Best batch sizes from your initial experiments ---\n",
    "BEST_BATCH_SIZES = {\n",
    "    \"MobileNet\": 8,\n",
    "    \"EfficientNet\": 16,\n",
    "    \"Inception\": 8,\n",
    "    \"VGG\": 16,\n",
    "    \"ResNet\": 8\n",
    "}\n",
    "\n",
    "RESULTS_DIR = 'results'\n",
    "\n",
    "# --- 2. The Master Experiment Function ---\n",
    "\n",
    "def run_experiment(model_choice, training_mode='fine_tuning', batch_size=None, learning_rate=1e-4):\n",
    "    \"\"\"\n",
    "    Runs a complete, configurable training and evaluation experiment.\n",
    "\n",
    "    Args:\n",
    "        model_choice (str): Name of the model to run (e.g., \"MobileNetV2\").\n",
    "        training_mode (str): One of 'transfer_learning', 'fine_tuning', or 'from_scratch'.\n",
    "        batch_size (int, optional): Batch size. If None, uses the best default for the model family.\n",
    "        learning_rate (float, optional): The initial learning rate.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Dynamic Setup ---\n",
    "    model_config = MODELS[model_choice]\n",
    "    input_size = model_config[\"input_size\"]\n",
    "    model_family = model_choice.split(\"V\")[0].split(\"B\")[0]\n",
    "    \n",
    "    if batch_size is None:\n",
    "        batch_size = BEST_BATCH_SIZES.get(model_family, 16) # Default to 16 if family not found\n",
    "\n",
    "    MODEL_NAME = f'{model_choice}_{training_mode}_bs{batch_size}'\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, MODEL_NAME)\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"--- Starting Experiment: {MODEL_NAME} ---\")\n",
    "    print(f\"Mode: {training_mode}, Batch Size: {batch_size}, LR: {learning_rate}, Input: {input_size}x{input_size}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # --- Data Loading (Conditional) ---\n",
    "    if training_mode == 'from_scratch':\n",
    "        PROCESSED_DIR = os.path.join('processed_data', f'BrinjalFruitX_{input_size}x{input_size}_balanced_classless')\n",
    "    elif input_size == 299:\n",
    "        PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_299x299_balanced_classless')\n",
    "    elif input_size == 600:\n",
    "        PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_600x600_balanced_classless')\n",
    "    else:\n",
    "        PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_balanced_classless')\n",
    "    \n",
    "    print(f\"\\nLoading data from '{PROCESSED_DIR}'...\")\n",
    "    try:\n",
    "        X_train = np.load(os.path.join(PROCESSED_DIR, 'X_train.npy'))\n",
    "        y_train = np.load(os.path.join(PROCESSED_DIR, 'y_train.npy'))\n",
    "        X_val = np.load(os.path.join(PROCESSED_DIR, 'X_val.npy'))\n",
    "        y_val = np.load(os.path.join(PROCESSED_DIR, 'y_val.npy'))\n",
    "        X_test = np.load(os.path.join(PROCESSED_DIR, 'X_test.npy'))\n",
    "        y_test = np.load(os.path.join(PROCESSED_DIR, 'y_test.npy'))\n",
    "        with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'r') as f:\n",
    "            class_names = json.load(f)\n",
    "        print(\"Data loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Data not found. Please create the required dataset at '{PROCESSED_DIR}'.\")\n",
    "        return\n",
    "\n",
    "    # --- Model Definition ---\n",
    "    data_augmentation = models.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.2),\n",
    "        layers.RandomZoom(0.2), layers.RandomContrast(0.2)], name=\"data_augmentation\")\n",
    "\n",
    "    base_model_class = model_config[\"class\"]\n",
    "    \n",
    "    # --- Training Logic based on Mode ---\n",
    "    if training_mode == 'from_scratch':\n",
    "        print(\"\\n--- CONFIGURATION: Training from Scratch ---\")\n",
    "        base_model = base_model_class(input_shape=(input_size, input_size, 3), include_top=False, weights=None)\n",
    "        base_model.trainable = True\n",
    "        \n",
    "        inputs = layers.Input(shape=(input_size, input_size, 3))\n",
    "        x = data_augmentation(inputs)\n",
    "        x = base_model(x, training=True)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "        model = models.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True),\n",
    "            ModelCheckpoint(filepath=os.path.join(model_results_dir, 'best_model.keras'), monitor='val_loss', save_best_only=True, verbose=1),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, verbose=1)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=callbacks)\n",
    "\n",
    "    else: # Handles 'transfer_learning' and 'fine_tuning'\n",
    "        print(f\"\\n--- CONFIGURATION: {training_mode.replace('_', ' ').title()} ---\")\n",
    "        base_model = base_model_class(input_shape=(input_size, input_size, 3), include_top=False, weights='imagenet')\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        inputs = layers.Input(shape=(input_size, input_size, 3))\n",
    "        x = data_augmentation(inputs)\n",
    "        x = base_model(x, training=False)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "        model = models.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)])\n",
    "        \n",
    "        if training_mode == 'fine_tuning':\n",
    "            print(\"\\n--- STAGE 2: Fine-Tuning ---\")\n",
    "            class_labels = np.unique(y_train)\n",
    "            weights = class_weight.compute_class_weight('balanced', classes=class_labels, y=y_train)\n",
    "            class_weights_dict = dict(zip(class_labels, weights))\n",
    "            print(\"Applying Class Weights:\", class_weights_dict)\n",
    "\n",
    "            base_model.trainable = True\n",
    "            fine_tune_at = math.ceil(len(base_model.layers) * 0.5)\n",
    "            for layer in base_model.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "            \n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            callbacks_finetune = [\n",
    "                EarlyStopping(monitor='val_loss', patience=15, verbose=1),\n",
    "                ModelCheckpoint(filepath=os.path.join(model_results_dir, 'best_model.keras'), monitor='val_loss', save_best_only=True, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
    "            ]\n",
    "            \n",
    "            total_epochs = history.epoch[-1] + 1 + 50\n",
    "            history_fine_tune = model.fit(X_train, y_train, epochs=total_epochs, initial_epoch=history.epoch[-1] + 1, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights_dict, callbacks=callbacks_finetune)\n",
    "            # Combine history objects for plotting\n",
    "            history.history['accuracy'].extend(history_fine_tune.history['accuracy'])\n",
    "            history.history['val_accuracy'].extend(history_fine_tune.history['val_accuracy'])\n",
    "            history.history['loss'].extend(history_fine_tune.history['loss'])\n",
    "            history.history['val_loss'].extend(history_fine_tune.history['val_loss'])\n",
    "            \n",
    "            model.load_model(os.path.join(model_results_dir, 'best_model.keras'))\n",
    "\n",
    "    # --- ADDED: Visualization Section ---\n",
    "    print(\"\\nGenerating and saving performance plot...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{MODEL_NAME}: Model Accuracy & Loss')\n",
    "    plt.ylabel('Accuracy & Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(model_results_dir, 'performance_plot.png'))\n",
    "    plt.close() # Close the plot to free up memory\n",
    "\n",
    "    # --- Evaluation and Saving ---\n",
    "    end_time = time.time()\n",
    "    training_duration = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Final Test Set Evaluation ---\")\n",
    "    y_pred_test_probs = model.predict(X_test)\n",
    "    y_pred_test_classes = np.argmax(y_pred_test_probs, axis=1)\n",
    "    report_dict = classification_report(y_test, y_pred_test_classes, target_names=class_names, output_dict=True)\n",
    "    print(\"\\nTest Set Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred_test_classes, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_test_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{MODEL_NAME} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(model_results_dir, 'confusion_matrix.png'))\n",
    "    plt.close() # Close the plot\n",
    "    \n",
    "    print(\"\\nUpdating summary results file...\")\n",
    "    summary_file = os.path.join(RESULTS_DIR, 'summary_results.csv')\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    summary_data = {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'test_accuracy': f\"{test_accuracy:.4f}\",\n",
    "        'test_loss': f\"{test_loss:.4f}\",\n",
    "        'macro_avg_f1-score': f\"{report_dict['macro avg']['f1-score']:.4f}\",\n",
    "        'weighted_avg_f1-score': f\"{report_dict['weighted avg']['f1-score']:.4f}\",\n",
    "        'training_time': training_duration\n",
    "    }\n",
    "    new_results_df = pd.DataFrame([summary_data])\n",
    "    if os.path.exists(summary_file):\n",
    "        summary_df = pd.read_csv(summary_file)\n",
    "        if MODEL_NAME in summary_df['model_name'].values:\n",
    "            summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.iloc[0].values\n",
    "        else:\n",
    "            summary_df = pd.concat([summary_df, new_results_df], ignore_index=True)\n",
    "        summary_df.to_csv(summary_file, index=False)\n",
    "    else:\n",
    "        new_results_df.to_csv(summary_file, index=False)\n",
    "\n",
    "    print(f\"\\n--- Experiment for {MODEL_NAME} is complete. Total time: {training_duration} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Main Execution Block ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Example of how to run experiments ---\n",
    "    \n",
    "    # --- Run the best fine-tuning experiment for a specific model ---\n",
    "    run_experiment(\n",
    "        model_choice=\"MobileNetV2\",\n",
    "        training_mode='fine_tuning'\n",
    "    )\n",
    "    \n",
    "    # --- Run a simple transfer learning experiment ---\n",
    "    # run_experiment(\n",
    "    #     model_choice=\"ResNet50\",\n",
    "    #     training_mode='transfer_learning',\n",
    "    #     batch_size=32,\n",
    "    #     learning_rate=1e-3\n",
    "    # )\n",
    "\n",
    "    # --- Run a 'from scratch' experiment ---\n",
    "    # NOTE: This requires a balanced dataset to be created first.\n",
    "    # run_experiment(\n",
    "    #     model_choice=\"EfficientNetB0\",\n",
    "    #     training_mode='from_scratch'\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945853e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# --- 1. Global Configuration ---\n",
    "\n",
    "# --- Model definitions and their required input sizes ---\n",
    "MODELS = {\n",
    "    \"MobileNetV2\": {\"class\": tf.keras.applications.MobileNetV2, \"input_size\": 224},\n",
    "    \"MobileNetV3Large\": {\"class\": tf.keras.applications.MobileNetV3Large, \"input_size\": 224},\n",
    "    \"EfficientNetB0\": {\"class\": tf.keras.applications.EfficientNetB0, \"input_size\": 224},\n",
    "    \"EfficientNetB7\": {\"class\": tf.keras.applications.EfficientNetB7, \"input_size\": 600},\n",
    "    \"InceptionV3\": {\"class\": tf.keras.applications.InceptionV3, \"input_size\": 299},\n",
    "    \"InceptionResNetV2\": {\"class\": tf.keras.applications.InceptionResNetV2, \"input_size\": 299},\n",
    "    \"VGG16\": {\"class\": tf.keras.applications.VGG16, \"input_size\": 224},\n",
    "    \"VGG19\": {\"class\": tf.keras.applications.VGG19, \"input_size\": 224},\n",
    "    \"ResNet50\": {\"class\": tf.keras.applications.ResNet50, \"input_size\": 224},\n",
    "    \"ResNet152\": {\"class\": tf.keras.applications.ResNet152, \"input_size\": 224}\n",
    "}\n",
    "\n",
    "# --- Best batch sizes from your initial experiments ---\n",
    "BEST_BATCH_SIZES = {\n",
    "    \"MobileNet\": 8,\n",
    "    \"EfficientNet\": 16,\n",
    "    \"Inception\": 8,\n",
    "    \"VGG\": 16,\n",
    "    \"ResNet\": 8\n",
    "}\n",
    "\n",
    "RESULTS_DIR = 'results'\n",
    "\n",
    "# --- 2. The Master Experiment Function ---\n",
    "\n",
    "def run_experiment(model_choice, training_mode='full_monty', batch_size=None, learning_rate=1e-4):\n",
    "    \"\"\"\n",
    "    Runs a complete, configurable training and evaluation experiment.\n",
    "\n",
    "    Args:\n",
    "        model_choice (str): Name of the model to run (e.g., \"MobileNetV2\").\n",
    "        training_mode (str): One of 'transfer_learning', 'fine_tuning', 'from_scratch', or 'full_monty'.\n",
    "        batch_size (int, optional): Batch size. If None, uses the best default for the model family.\n",
    "        learning_rate (float, optional): The initial learning rate.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Dynamic Setup ---\n",
    "    model_config = MODELS[model_choice]\n",
    "    input_size = model_config[\"input_size\"]\n",
    "    model_family = model_choice.split(\"V\")[0].split(\"B\")[0]\n",
    "    \n",
    "    if batch_size is None:\n",
    "        batch_size = BEST_BATCH_SIZES.get(model_family, 16)\n",
    "\n",
    "    MODEL_NAME = f'{model_choice}_{training_mode}_bs{batch_size}'\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, MODEL_NAME)\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"--- Starting Experiment: {MODEL_NAME} ---\")\n",
    "    print(f\"Mode: {training_mode}, Batch Size: {batch_size}, LR: {learning_rate}, Input: {input_size}x{input_size}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # --- Data Loading (Conditional) ---\n",
    "    use_balanced_data = training_mode in ['from_scratch', 'full_monty']\n",
    "    \n",
    "    if use_balanced_data:\n",
    "        PROCESSED_DIR = os.path.join('processed_data', f'BrinjalFruitX_{input_size}x{input_size}_balanced_classless')\n",
    "    elif input_size == 299:\n",
    "        PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_299x299_balanced_classless')\n",
    "    elif input_size == 600:\n",
    "        PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_600x600_balanced_classless')\n",
    "    else:\n",
    "        PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_balanced_classless')\n",
    "    \n",
    "    print(f\"\\nLoading data from '{PROCESSED_DIR}'...\")\n",
    "    try:\n",
    "        X_train = np.load(os.path.join(PROCESSED_DIR, 'X_train.npy'))\n",
    "        y_train = np.load(os.path.join(PROCESSED_DIR, 'y_train.npy'))\n",
    "        X_val = np.load(os.path.join(PROCESSED_DIR, 'X_val.npy'))\n",
    "        y_val = np.load(os.path.join(PROCESSED_DIR, 'y_val.npy'))\n",
    "        X_test = np.load(os.path.join(PROCESSED_DIR, 'X_test.npy'))\n",
    "        y_test = np.load(os.path.join(PROCESSED_DIR, 'y_test.npy'))\n",
    "        with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'r') as f:\n",
    "            class_names = json.load(f)\n",
    "        print(\"Data loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Data not found. Please create the required dataset at '{PROCESSED_DIR}'.\")\n",
    "        return\n",
    "\n",
    "    # --- Model Definition ---\n",
    "    data_augmentation = models.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.2),\n",
    "        layers.RandomZoom(0.2), layers.RandomContrast(0.2)], name=\"data_augmentation\")\n",
    "\n",
    "    base_model_class = model_config[\"class\"]\n",
    "    \n",
    "    # --- Training Logic based on Mode ---\n",
    "    use_transfer_weights = training_mode != 'from_scratch'\n",
    "    \n",
    "    print(f\"\\n--- CONFIGURATION: {training_mode.replace('_', ' ').title()} ---\")\n",
    "    base_model = base_model_class(\n",
    "        input_shape=(input_size, input_size, 3), \n",
    "        include_top=False, \n",
    "        weights='imagenet' if use_transfer_weights else None\n",
    "    )\n",
    "    base_model.trainable = not use_transfer_weights\n",
    "\n",
    "    inputs = layers.Input(shape=(input_size, input_size, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = base_model(x, training=(not use_transfer_weights))\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=os.path.join(model_results_dir, 'best_model.keras'), monitor='val_loss', save_best_only=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    fit_kwargs = {'class_weight': None}\n",
    "    if training_mode == 'fine_tuning': # Only use class_weight for this specific mode\n",
    "        class_labels = np.unique(y_train)\n",
    "        weights = class_weight.compute_class_weight('balanced', classes=class_labels, y=y_train)\n",
    "        fit_kwargs['class_weight'] = dict(zip(class_labels, weights))\n",
    "        print(\"Applying Class Weights for training on imbalanced data.\")\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=callbacks, **fit_kwargs)\n",
    "    \n",
    "    is_two_stage = training_mode in ['fine_tuning', 'full_monty']\n",
    "    if is_two_stage:\n",
    "        print(\"\\n--- STAGE 2: Fine-Tuning ---\")\n",
    "        base_model.trainable = True\n",
    "        fine_tune_at = math.ceil(len(base_model.layers) * 0.5)\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        total_epochs = history.epoch[-1] + 1 + 50\n",
    "        history_fine_tune = model.fit(X_train, y_train, epochs=total_epochs, initial_epoch=history.epoch[-1] + 1, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=callbacks, **fit_kwargs)\n",
    "        \n",
    "        # Combine history objects for plotting\n",
    "        history.history['accuracy'].extend(history_fine_tune.history['accuracy'])\n",
    "        history.history['val_accuracy'].extend(history_fine_tune.history['val_accuracy'])\n",
    "        history.history['loss'].extend(history_fine_tune.history['loss'])\n",
    "        history.history['val_loss'].extend(history_fine_tune.history['val_loss'])\n",
    "        \n",
    "        model = tf.keras.models.load_model(os.path.join(model_results_dir, 'best_model.keras'))\n",
    "\n",
    "\n",
    "    # --- ADDED: Visualization Section ---\n",
    "    print(\"\\nGenerating and saving performance plot...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{MODEL_NAME}: Model Accuracy & Loss')\n",
    "    plt.ylabel('Accuracy & Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(model_results_dir, 'performance_plot.png'))\n",
    "    plt.close() # Close the plot to free up memory\n",
    "\n",
    "    # --- Evaluation and Saving ---\n",
    "    end_time = time.time()\n",
    "    training_duration = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Final Test Set Evaluation ---\")\n",
    "    y_pred_test_probs = model.predict(X_test)\n",
    "    y_pred_test_classes = np.argmax(y_pred_test_probs, axis=1)\n",
    "    report_dict = classification_report(y_test, y_pred_test_classes, target_names=class_names, output_dict=True)\n",
    "    print(\"\\nTest Set Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred_test_classes, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_test_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{MODEL_NAME} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(model_results_dir, 'confusion_matrix.png'))\n",
    "    plt.close() # Close the plot\n",
    "    \n",
    "    print(\"\\nUpdating summary results file...\")\n",
    "    summary_file = os.path.join(RESULTS_DIR, 'summary_results.csv')\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    summary_data = {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'test_accuracy': f\"{test_accuracy:.4f}\",\n",
    "        'test_loss': f\"{test_loss:.4f}\",\n",
    "        'macro_avg_f1-score': f\"{report_dict['macro avg']['f1-score']:.4f}\",\n",
    "        'weighted_avg_f1-score': f\"{report_dict['weighted avg']['f1-score']:.4f}\",\n",
    "        'training_time': training_duration\n",
    "    }\n",
    "    new_results_df = pd.DataFrame([summary_data])\n",
    "    if os.path.exists(summary_file):\n",
    "        summary_df = pd.read_csv(summary_file)\n",
    "        if MODEL_NAME in summary_df['model_name'].values:\n",
    "            summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.iloc[0].values\n",
    "        else:\n",
    "            summary_df = pd.concat([summary_df, new_results_df], ignore_index=True)\n",
    "        summary_df.to_csv(summary_file, index=False)\n",
    "    else:\n",
    "        new_results_df.to_csv(summary_file, index=False)\n",
    "\n",
    "    print(f\"\\n--- Experiment for {MODEL_NAME} is complete. Total time: {training_duration} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3716284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV2_from_scratch_bs8 ---\n",
      "Mode: from_scratch, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.6481 - loss: 0.7053\n",
      "Epoch 1: val_loss improved from inf to 0.68157, saving model to results\\MobileNetV2_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 269ms/step - accuracy: 0.6481 - loss: 0.7051 - val_accuracy: 0.5887 - val_loss: 0.6816 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.6902 - loss: 0.6368\n",
      "Epoch 2: val_loss improved from 0.68157 to 0.67767, saving model to results\\MobileNetV2_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 259ms/step - accuracy: 0.6903 - loss: 0.6363 - val_accuracy: 0.5887 - val_loss: 0.6777 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.7239 - loss: 0.5472\n",
      "Epoch 3: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 257ms/step - accuracy: 0.7240 - loss: 0.5473 - val_accuracy: 0.5887 - val_loss: 0.6787 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.7545 - loss: 0.5247\n",
      "Epoch 4: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 256ms/step - accuracy: 0.7545 - loss: 0.5247 - val_accuracy: 0.5887 - val_loss: 0.6812 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.7785 - loss: 0.5377\n",
      "Epoch 5: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 257ms/step - accuracy: 0.7786 - loss: 0.5374 - val_accuracy: 0.5887 - val_loss: 0.6877 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.7771 - loss: 0.4965\n",
      "Epoch 6: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.7772 - loss: 0.4964 - val_accuracy: 0.5887 - val_loss: 0.7152 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.7791 - loss: 0.5029\n",
      "Epoch 7: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.7791 - loss: 0.5029 - val_accuracy: 0.5887 - val_loss: 0.7248 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.8093 - loss: 0.4638\n",
      "Epoch 8: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.8092 - loss: 0.4640 - val_accuracy: 0.5887 - val_loss: 0.7291 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.7776 - loss: 0.4825\n",
      "Epoch 9: val_loss did not improve from 0.67767\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.7777 - loss: 0.4823 - val_accuracy: 0.5887 - val_loss: 0.7388 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8282 - loss: 0.3927\n",
      "Epoch 10: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.8280 - loss: 0.3931 - val_accuracy: 0.5887 - val_loss: 0.7521 - learning_rate: 2.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8084 - loss: 0.4366\n",
      "Epoch 11: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.8083 - loss: 0.4367 - val_accuracy: 0.5887 - val_loss: 0.7704 - learning_rate: 2.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.8267 - loss: 0.4090\n",
      "Epoch 12: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.8266 - loss: 0.4090 - val_accuracy: 0.5887 - val_loss: 0.7915 - learning_rate: 2.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.8245 - loss: 0.3991\n",
      "Epoch 13: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.8244 - loss: 0.3993 - val_accuracy: 0.5887 - val_loss: 0.8149 - learning_rate: 2.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.8080 - loss: 0.4277\n",
      "Epoch 14: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.8081 - loss: 0.4276 - val_accuracy: 0.5887 - val_loss: 0.8309 - learning_rate: 2.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.8332 - loss: 0.3697\n",
      "Epoch 15: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 257ms/step - accuracy: 0.8332 - loss: 0.3697 - val_accuracy: 0.5887 - val_loss: 0.8868 - learning_rate: 2.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8366 - loss: 0.4060\n",
      "Epoch 16: val_loss did not improve from 0.67767\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.8364 - loss: 0.4062 - val_accuracy: 0.5887 - val_loss: 0.9020 - learning_rate: 2.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8342 - loss: 0.3816\n",
      "Epoch 17: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.8341 - loss: 0.3817 - val_accuracy: 0.5887 - val_loss: 0.9299 - learning_rate: 4.0000e-06\n",
      "Epoch 18/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.7971 - loss: 0.4406\n",
      "Epoch 18: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.7972 - loss: 0.4403 - val_accuracy: 0.5887 - val_loss: 0.9421 - learning_rate: 4.0000e-06\n",
      "Epoch 19/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.8210 - loss: 0.4070\n",
      "Epoch 19: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 257ms/step - accuracy: 0.8210 - loss: 0.4069 - val_accuracy: 0.5887 - val_loss: 0.9699 - learning_rate: 4.0000e-06\n",
      "Epoch 20/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.8386 - loss: 0.3921\n",
      "Epoch 20: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.8385 - loss: 0.3921 - val_accuracy: 0.5887 - val_loss: 0.9923 - learning_rate: 4.0000e-06\n",
      "Epoch 21/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.8465 - loss: 0.3875\n",
      "Epoch 21: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 257ms/step - accuracy: 0.8464 - loss: 0.3875 - val_accuracy: 0.5887 - val_loss: 1.0235 - learning_rate: 4.0000e-06\n",
      "Epoch 22/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8352 - loss: 0.3920\n",
      "Epoch 22: val_loss did not improve from 0.67767\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.8351 - loss: 0.3922 - val_accuracy: 0.5887 - val_loss: 1.0562 - learning_rate: 4.0000e-06\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV2_from_scratch_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 286ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.00      0.00      0.00       103\n",
      "Shoot and Fruit Borer       0.58      1.00      0.74       145\n",
      "\n",
      "             accuracy                           0.58       248\n",
      "            macro avg       0.29      0.50      0.37       248\n",
      "         weighted avg       0.34      0.58      0.43       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment for MobileNetV2_from_scratch_bs8 is complete. Total time: 00:12:21 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dr-basab\\AppData\\Local\\Temp\\ipykernel_15668\\1544972724.py:225: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5847' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.iloc[0].values\n",
      "C:\\Users\\dr-basab\\AppData\\Local\\Temp\\ipykernel_15668\\1544972724.py:225: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6789' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.iloc[0].values\n",
      "C:\\Users\\dr-basab\\AppData\\Local\\Temp\\ipykernel_15668\\1544972724.py:225: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3690' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.iloc[0].values\n",
      "C:\\Users\\dr-basab\\AppData\\Local\\Temp\\ipykernel_15668\\1544972724.py:225: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4314' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.iloc[0].values\n",
      "C:\\Users\\dr-basab\\AppData\\Local\\Temp\\ipykernel_15668\\1544972724.py:225: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '00:12:21' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.iloc[0].values\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV2\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f80abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV2_transfer_learning_bs8 ---\n",
      "Mode: transfer_learning, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.5635 - loss: 0.8881 - val_accuracy: 0.6048 - val_loss: 0.6180\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.6535 - loss: 0.6961 - val_accuracy: 0.7016 - val_loss: 0.5421\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.7671 - loss: 0.5229 - val_accuracy: 0.7661 - val_loss: 0.4633\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.7502 - loss: 0.5279 - val_accuracy: 0.7742 - val_loss: 0.4620\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.7980 - loss: 0.4475 - val_accuracy: 0.7903 - val_loss: 0.4170\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8398 - loss: 0.3832 - val_accuracy: 0.8065 - val_loss: 0.3900\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8600 - loss: 0.3548 - val_accuracy: 0.8306 - val_loss: 0.3664\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.8568 - loss: 0.3579 - val_accuracy: 0.8387 - val_loss: 0.3752\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8766 - loss: 0.3190 - val_accuracy: 0.8629 - val_loss: 0.3228\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8819 - loss: 0.2823 - val_accuracy: 0.8387 - val_loss: 0.3426\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.8561 - loss: 0.3043 - val_accuracy: 0.8468 - val_loss: 0.3304\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.8960 - loss: 0.2686 - val_accuracy: 0.8548 - val_loss: 0.3363\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8925 - loss: 0.2935 - val_accuracy: 0.8790 - val_loss: 0.3016\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8735 - loss: 0.2800 - val_accuracy: 0.8871 - val_loss: 0.2840\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8986 - loss: 0.2702 - val_accuracy: 0.8871 - val_loss: 0.3002\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8872 - loss: 0.2748 - val_accuracy: 0.8952 - val_loss: 0.2765\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8955 - loss: 0.2690 - val_accuracy: 0.8952 - val_loss: 0.2877\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.9148 - loss: 0.2037 - val_accuracy: 0.9032 - val_loss: 0.2689\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.9271 - loss: 0.1975 - val_accuracy: 0.9113 - val_loss: 0.2660\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.9044 - loss: 0.2225 - val_accuracy: 0.9194 - val_loss: 0.2465\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8978 - loss: 0.2585 - val_accuracy: 0.9032 - val_loss: 0.2666\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9326 - loss: 0.1810 - val_accuracy: 0.9194 - val_loss: 0.2457\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.9347 - loss: 0.1787 - val_accuracy: 0.9032 - val_loss: 0.2703\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9268 - loss: 0.1880 - val_accuracy: 0.9113 - val_loss: 0.2379\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9167 - loss: 0.2093 - val_accuracy: 0.9032 - val_loss: 0.2595\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9114 - loss: 0.2139 - val_accuracy: 0.9113 - val_loss: 0.2237\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9315 - loss: 0.1929 - val_accuracy: 0.9113 - val_loss: 0.2232\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9225 - loss: 0.1819 - val_accuracy: 0.9194 - val_loss: 0.2306\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9157 - loss: 0.2074 - val_accuracy: 0.9113 - val_loss: 0.2223\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9075 - loss: 0.2121 - val_accuracy: 0.9113 - val_loss: 0.2275\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.9022 - loss: 0.2113 - val_accuracy: 0.9113 - val_loss: 0.2432\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.9396 - loss: 0.1793 - val_accuracy: 0.9113 - val_loss: 0.2165\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9206 - loss: 0.1976 - val_accuracy: 0.9113 - val_loss: 0.2099\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9258 - loss: 0.2148 - val_accuracy: 0.9113 - val_loss: 0.2091\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9176 - loss: 0.2111 - val_accuracy: 0.9194 - val_loss: 0.2301\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9245 - loss: 0.1833 - val_accuracy: 0.9113 - val_loss: 0.2094\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.9366 - loss: 0.1632 - val_accuracy: 0.9113 - val_loss: 0.2372\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9417 - loss: 0.1588 - val_accuracy: 0.9113 - val_loss: 0.2160\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.9173 - loss: 0.1726 - val_accuracy: 0.9194 - val_loss: 0.2083\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9314 - loss: 0.1662 - val_accuracy: 0.9113 - val_loss: 0.2222\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9408 - loss: 0.1759 - val_accuracy: 0.9194 - val_loss: 0.2164\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9487 - loss: 0.1480 - val_accuracy: 0.9194 - val_loss: 0.1936\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9264 - loss: 0.1754 - val_accuracy: 0.9194 - val_loss: 0.2021\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9375 - loss: 0.1699 - val_accuracy: 0.9194 - val_loss: 0.2153\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9569 - loss: 0.1366 - val_accuracy: 0.9194 - val_loss: 0.2052\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9489 - loss: 0.1439 - val_accuracy: 0.9274 - val_loss: 0.1865\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9385 - loss: 0.1623 - val_accuracy: 0.9194 - val_loss: 0.2060\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9416 - loss: 0.1541 - val_accuracy: 0.9194 - val_loss: 0.2010\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9433 - loss: 0.1530 - val_accuracy: 0.9194 - val_loss: 0.2023\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9413 - loss: 0.1578 - val_accuracy: 0.9194 - val_loss: 0.2020\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV2_transfer_learning_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 284ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.90      0.98      0.94       103\n",
      "Shoot and Fruit Borer       0.99      0.92      0.95       145\n",
      "\n",
      "             accuracy                           0.95       248\n",
      "            macro avg       0.94      0.95      0.95       248\n",
      "         weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for MobileNetV2_transfer_learning_bs8 is complete. Total time: 00:07:17 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV2\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcaa4467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV2_fine_tune_bs8 ---\n",
      "Mode: fine_tune, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 325ms/step - accuracy: 0.5145 - loss: 1.0096 - val_accuracy: 0.6532 - val_loss: 0.6676\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 316ms/step - accuracy: 0.6009 - loss: 0.7333 - val_accuracy: 0.7177 - val_loss: 0.5552\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 324ms/step - accuracy: 0.6773 - loss: 0.6510 - val_accuracy: 0.7742 - val_loss: 0.4820\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 316ms/step - accuracy: 0.7715 - loss: 0.4845 - val_accuracy: 0.7903 - val_loss: 0.4552\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.7746 - loss: 0.4919 - val_accuracy: 0.8065 - val_loss: 0.4289\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 314ms/step - accuracy: 0.8192 - loss: 0.3809 - val_accuracy: 0.8226 - val_loss: 0.4011\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 332ms/step - accuracy: 0.7966 - loss: 0.4673 - val_accuracy: 0.8226 - val_loss: 0.3748\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 334ms/step - accuracy: 0.8626 - loss: 0.3177 - val_accuracy: 0.8226 - val_loss: 0.3553\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 341ms/step - accuracy: 0.8553 - loss: 0.3386 - val_accuracy: 0.8226 - val_loss: 0.3859\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 341ms/step - accuracy: 0.8727 - loss: 0.2922 - val_accuracy: 0.8468 - val_loss: 0.3197\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 316ms/step - accuracy: 0.8711 - loss: 0.2808 - val_accuracy: 0.8468 - val_loss: 0.3246\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 320ms/step - accuracy: 0.8890 - loss: 0.2871 - val_accuracy: 0.8710 - val_loss: 0.3120\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 330ms/step - accuracy: 0.8878 - loss: 0.2557 - val_accuracy: 0.8226 - val_loss: 0.3813\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 327ms/step - accuracy: 0.9006 - loss: 0.2434 - val_accuracy: 0.8548 - val_loss: 0.3020\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 319ms/step - accuracy: 0.9003 - loss: 0.2454 - val_accuracy: 0.8710 - val_loss: 0.2928\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 326ms/step - accuracy: 0.9189 - loss: 0.2098 - val_accuracy: 0.8790 - val_loss: 0.2884\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 321ms/step - accuracy: 0.9045 - loss: 0.2275 - val_accuracy: 0.8871 - val_loss: 0.2953\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 318ms/step - accuracy: 0.9049 - loss: 0.2337 - val_accuracy: 0.8790 - val_loss: 0.2649\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9151 - loss: 0.2348 - val_accuracy: 0.8871 - val_loss: 0.2821\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9039 - loss: 0.2297 - val_accuracy: 0.8871 - val_loss: 0.2807\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9111 - loss: 0.2206 - val_accuracy: 0.8871 - val_loss: 0.2630\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 318ms/step - accuracy: 0.9133 - loss: 0.2099 - val_accuracy: 0.9032 - val_loss: 0.2553\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.9284 - loss: 0.1907 - val_accuracy: 0.9032 - val_loss: 0.2513\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9195 - loss: 0.2123 - val_accuracy: 0.9032 - val_loss: 0.2531\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 318ms/step - accuracy: 0.9222 - loss: 0.1977 - val_accuracy: 0.9194 - val_loss: 0.2380\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9133 - loss: 0.2312 - val_accuracy: 0.9113 - val_loss: 0.2535\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.9358 - loss: 0.1825 - val_accuracy: 0.9032 - val_loss: 0.2527\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9246 - loss: 0.1884 - val_accuracy: 0.9194 - val_loss: 0.2443\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9223 - loss: 0.2092 - val_accuracy: 0.9113 - val_loss: 0.2438\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.9244 - loss: 0.2202 - val_accuracy: 0.9032 - val_loss: 0.2608\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.9356 - loss: 0.1797 - val_accuracy: 0.9113 - val_loss: 0.2463\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.9292 - loss: 0.1837 - val_accuracy: 0.9113 - val_loss: 0.2460\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9336 - loss: 0.2289 - val_accuracy: 0.9274 - val_loss: 0.2162\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9372 - loss: 0.1771 - val_accuracy: 0.9274 - val_loss: 0.2168\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9315 - loss: 0.1774 - val_accuracy: 0.9274 - val_loss: 0.2168\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9448 - loss: 0.1590 - val_accuracy: 0.9274 - val_loss: 0.2209\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9336 - loss: 0.1691 - val_accuracy: 0.9274 - val_loss: 0.2143\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9381 - loss: 0.1627 - val_accuracy: 0.9274 - val_loss: 0.2168\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9309 - loss: 0.1645 - val_accuracy: 0.9274 - val_loss: 0.2061\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9336 - loss: 0.1878 - val_accuracy: 0.9274 - val_loss: 0.2129\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9378 - loss: 0.1767 - val_accuracy: 0.9274 - val_loss: 0.2023\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9290 - loss: 0.1842 - val_accuracy: 0.9194 - val_loss: 0.2341\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.9324 - loss: 0.1773 - val_accuracy: 0.9194 - val_loss: 0.2205\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9413 - loss: 0.1552 - val_accuracy: 0.9274 - val_loss: 0.2033\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9282 - loss: 0.1685 - val_accuracy: 0.9274 - val_loss: 0.2062\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.9403 - loss: 0.1490 - val_accuracy: 0.9194 - val_loss: 0.2188\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.9372 - loss: 0.1674 - val_accuracy: 0.9274 - val_loss: 0.1925\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 319ms/step - accuracy: 0.9428 - loss: 0.1486 - val_accuracy: 0.9274 - val_loss: 0.2081\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 319ms/step - accuracy: 0.9461 - loss: 0.1465 - val_accuracy: 0.9274 - val_loss: 0.2102\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 319ms/step - accuracy: 0.9330 - loss: 0.1762 - val_accuracy: 0.9274 - val_loss: 0.2109\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV2_fine_tune_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 586ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.90      0.97      0.93       103\n",
      "Shoot and Fruit Borer       0.98      0.92      0.95       145\n",
      "\n",
      "             accuracy                           0.94       248\n",
      "            macro avg       0.94      0.95      0.94       248\n",
      "         weighted avg       0.95      0.94      0.94       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for MobileNetV2_fine_tune_bs8 is complete. Total time: 00:34:12 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV2\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e38d5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV2_full_monty_bs8 ---\n",
      "Mode: full_monty, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5660 - loss: 0.8670\n",
      "Epoch 1: val_loss improved from inf to 0.65366, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.5662 - loss: 0.8667 - val_accuracy: 0.6452 - val_loss: 0.6537 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6653 - loss: 0.6551\n",
      "Epoch 2: val_loss improved from 0.65366 to 0.53037, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.6655 - loss: 0.6549 - val_accuracy: 0.7097 - val_loss: 0.5304 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7136 - loss: 0.6190\n",
      "Epoch 3: val_loss improved from 0.53037 to 0.45699, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.7138 - loss: 0.6186 - val_accuracy: 0.7581 - val_loss: 0.4570 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7657 - loss: 0.4832\n",
      "Epoch 4: val_loss improved from 0.45699 to 0.42793, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.7658 - loss: 0.4830 - val_accuracy: 0.7742 - val_loss: 0.4279 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8048 - loss: 0.4390\n",
      "Epoch 5: val_loss improved from 0.42793 to 0.40069, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.8052 - loss: 0.4386 - val_accuracy: 0.7742 - val_loss: 0.4007 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8351 - loss: 0.3904\n",
      "Epoch 6: val_loss improved from 0.40069 to 0.37769, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.8351 - loss: 0.3905 - val_accuracy: 0.7984 - val_loss: 0.3777 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8445 - loss: 0.3630\n",
      "Epoch 7: val_loss improved from 0.37769 to 0.35681, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.8446 - loss: 0.3629 - val_accuracy: 0.8065 - val_loss: 0.3568 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8629 - loss: 0.3465\n",
      "Epoch 8: val_loss improved from 0.35681 to 0.33837, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.8629 - loss: 0.3465 - val_accuracy: 0.8145 - val_loss: 0.3384 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8810 - loss: 0.2859\n",
      "Epoch 9: val_loss did not improve from 0.33837\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.8809 - loss: 0.2861 - val_accuracy: 0.8387 - val_loss: 0.3489 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8771 - loss: 0.2868\n",
      "Epoch 10: val_loss improved from 0.33837 to 0.33557, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8771 - loss: 0.2869 - val_accuracy: 0.8387 - val_loss: 0.3356 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8637 - loss: 0.3249\n",
      "Epoch 11: val_loss improved from 0.33557 to 0.30424, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8638 - loss: 0.3246 - val_accuracy: 0.8226 - val_loss: 0.3042 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8598 - loss: 0.3227\n",
      "Epoch 12: val_loss did not improve from 0.30424\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.8600 - loss: 0.3224 - val_accuracy: 0.8387 - val_loss: 0.3154 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9141 - loss: 0.2486\n",
      "Epoch 13: val_loss improved from 0.30424 to 0.30322, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9140 - loss: 0.2487 - val_accuracy: 0.8468 - val_loss: 0.3032 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8854 - loss: 0.2486\n",
      "Epoch 14: val_loss improved from 0.30322 to 0.28370, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.8854 - loss: 0.2488 - val_accuracy: 0.8629 - val_loss: 0.2837 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8990 - loss: 0.2523\n",
      "Epoch 15: val_loss did not improve from 0.28370\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.8989 - loss: 0.2523 - val_accuracy: 0.8548 - val_loss: 0.2916 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9133 - loss: 0.2506\n",
      "Epoch 16: val_loss improved from 0.28370 to 0.28053, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9132 - loss: 0.2504 - val_accuracy: 0.8790 - val_loss: 0.2805 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8843 - loss: 0.2612\n",
      "Epoch 17: val_loss improved from 0.28053 to 0.27177, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8844 - loss: 0.2612 - val_accuracy: 0.8790 - val_loss: 0.2718 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9162 - loss: 0.2114\n",
      "Epoch 18: val_loss improved from 0.27177 to 0.27119, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9161 - loss: 0.2115 - val_accuracy: 0.8871 - val_loss: 0.2712 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8965 - loss: 0.2644\n",
      "Epoch 19: val_loss improved from 0.27119 to 0.26834, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8966 - loss: 0.2642 - val_accuracy: 0.8871 - val_loss: 0.2683 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9141 - loss: 0.2073\n",
      "Epoch 20: val_loss improved from 0.26834 to 0.25306, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9140 - loss: 0.2075 - val_accuracy: 0.8952 - val_loss: 0.2531 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9262 - loss: 0.1850\n",
      "Epoch 21: val_loss improved from 0.25306 to 0.25211, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.9261 - loss: 0.1851 - val_accuracy: 0.8952 - val_loss: 0.2521 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9308 - loss: 0.2077\n",
      "Epoch 22: val_loss improved from 0.25211 to 0.23791, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9307 - loss: 0.2077 - val_accuracy: 0.8952 - val_loss: 0.2379 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9112 - loss: 0.1987\n",
      "Epoch 23: val_loss did not improve from 0.23791\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9112 - loss: 0.1987 - val_accuracy: 0.8952 - val_loss: 0.2444 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9248 - loss: 0.1911\n",
      "Epoch 24: val_loss did not improve from 0.23791\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9248 - loss: 0.1912 - val_accuracy: 0.8952 - val_loss: 0.2482 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9237 - loss: 0.1821\n",
      "Epoch 25: val_loss did not improve from 0.23791\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9236 - loss: 0.1822 - val_accuracy: 0.8952 - val_loss: 0.2467 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9125 - loss: 0.2005\n",
      "Epoch 26: val_loss did not improve from 0.23791\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9125 - loss: 0.2006 - val_accuracy: 0.8952 - val_loss: 0.2422 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9260 - loss: 0.1856\n",
      "Epoch 27: val_loss improved from 0.23791 to 0.22344, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9259 - loss: 0.1860 - val_accuracy: 0.9032 - val_loss: 0.2234 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9274 - loss: 0.2236\n",
      "Epoch 28: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9273 - loss: 0.2235 - val_accuracy: 0.9113 - val_loss: 0.2370 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9349 - loss: 0.1773\n",
      "Epoch 29: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9347 - loss: 0.1774 - val_accuracy: 0.9113 - val_loss: 0.2355 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9301 - loss: 0.1793\n",
      "Epoch 30: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9302 - loss: 0.1792 - val_accuracy: 0.9113 - val_loss: 0.2427 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9278 - loss: 0.1902\n",
      "Epoch 31: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9278 - loss: 0.1903 - val_accuracy: 0.9113 - val_loss: 0.2377 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9390 - loss: 0.1706\n",
      "Epoch 32: val_loss did not improve from 0.22344\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9389 - loss: 0.1707 - val_accuracy: 0.9113 - val_loss: 0.2281 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9134 - loss: 0.2149\n",
      "Epoch 33: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9135 - loss: 0.2148 - val_accuracy: 0.9113 - val_loss: 0.2252 - learning_rate: 2.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9305 - loss: 0.1805\n",
      "Epoch 34: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.9305 - loss: 0.1805 - val_accuracy: 0.9113 - val_loss: 0.2290 - learning_rate: 2.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9352 - loss: 0.1668\n",
      "Epoch 35: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9352 - loss: 0.1668 - val_accuracy: 0.9113 - val_loss: 0.2259 - learning_rate: 2.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9464 - loss: 0.1629\n",
      "Epoch 36: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9463 - loss: 0.1630 - val_accuracy: 0.9113 - val_loss: 0.2238 - learning_rate: 2.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9297 - loss: 0.1816\n",
      "Epoch 37: val_loss did not improve from 0.22344\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9296 - loss: 0.1817 - val_accuracy: 0.9113 - val_loss: 0.2245 - learning_rate: 2.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9261 - loss: 0.1848\n",
      "Epoch 38: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9262 - loss: 0.1847 - val_accuracy: 0.9113 - val_loss: 0.2252 - learning_rate: 4.0000e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9289 - loss: 0.1761\n",
      "Epoch 39: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.9290 - loss: 0.1761 - val_accuracy: 0.9113 - val_loss: 0.2250 - learning_rate: 4.0000e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9333 - loss: 0.1747\n",
      "Epoch 40: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9333 - loss: 0.1748 - val_accuracy: 0.9113 - val_loss: 0.2242 - learning_rate: 4.0000e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8882 - loss: 0.2246\n",
      "Epoch 41: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8884 - loss: 0.2243 - val_accuracy: 0.9113 - val_loss: 0.2253 - learning_rate: 4.0000e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9381 - loss: 0.1602\n",
      "Epoch 42: val_loss did not improve from 0.22344\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9381 - loss: 0.1603 - val_accuracy: 0.9113 - val_loss: 0.2272 - learning_rate: 4.0000e-06\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 43/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8059 - loss: 0.4605\n",
      "Epoch 43: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 134ms/step - accuracy: 0.8060 - loss: 0.4602 - val_accuracy: 0.8226 - val_loss: 0.4478 - learning_rate: 1.0000e-05\n",
      "Epoch 44/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8849 - loss: 0.2786\n",
      "Epoch 44: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.8849 - loss: 0.2787 - val_accuracy: 0.7984 - val_loss: 0.5422 - learning_rate: 1.0000e-05\n",
      "Epoch 45/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8773 - loss: 0.2669\n",
      "Epoch 45: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.8775 - loss: 0.2667 - val_accuracy: 0.8387 - val_loss: 0.4434 - learning_rate: 1.0000e-05\n",
      "Epoch 46/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9044 - loss: 0.2517\n",
      "Epoch 46: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.9043 - loss: 0.2516 - val_accuracy: 0.8548 - val_loss: 0.4360 - learning_rate: 1.0000e-05\n",
      "Epoch 47/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8739 - loss: 0.2657\n",
      "Epoch 47: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.8740 - loss: 0.2657 - val_accuracy: 0.8710 - val_loss: 0.3398 - learning_rate: 1.0000e-05\n",
      "Epoch 48/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9102 - loss: 0.2283\n",
      "Epoch 48: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.9102 - loss: 0.2283 - val_accuracy: 0.8871 - val_loss: 0.3032 - learning_rate: 1.0000e-05\n",
      "Epoch 49/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9160 - loss: 0.2031\n",
      "Epoch 49: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.9160 - loss: 0.2032 - val_accuracy: 0.8548 - val_loss: 0.3412 - learning_rate: 1.0000e-05\n",
      "Epoch 50/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9242 - loss: 0.1986\n",
      "Epoch 50: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.9242 - loss: 0.1986 - val_accuracy: 0.8952 - val_loss: 0.2965 - learning_rate: 1.0000e-05\n",
      "Epoch 51/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9091 - loss: 0.2318\n",
      "Epoch 51: val_loss did not improve from 0.22344\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.9092 - loss: 0.2316 - val_accuracy: 0.9355 - val_loss: 0.2306 - learning_rate: 1.0000e-05\n",
      "Epoch 52/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9591 - loss: 0.1336\n",
      "Epoch 52: val_loss improved from 0.22344 to 0.20224, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.9589 - loss: 0.1338 - val_accuracy: 0.9355 - val_loss: 0.2022 - learning_rate: 1.0000e-05\n",
      "Epoch 53/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9490 - loss: 0.1293\n",
      "Epoch 53: val_loss improved from 0.20224 to 0.19610, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.9490 - loss: 0.1295 - val_accuracy: 0.9355 - val_loss: 0.1961 - learning_rate: 1.0000e-05\n",
      "Epoch 54/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9536 - loss: 0.1418\n",
      "Epoch 54: val_loss improved from 0.19610 to 0.18467, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.9535 - loss: 0.1420 - val_accuracy: 0.9435 - val_loss: 0.1847 - learning_rate: 1.0000e-05\n",
      "Epoch 55/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9301 - loss: 0.1830\n",
      "Epoch 55: val_loss improved from 0.18467 to 0.14554, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 122ms/step - accuracy: 0.9301 - loss: 0.1829 - val_accuracy: 0.9597 - val_loss: 0.1455 - learning_rate: 1.0000e-05\n",
      "Epoch 56/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9226 - loss: 0.1664\n",
      "Epoch 56: val_loss improved from 0.14554 to 0.13861, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 126ms/step - accuracy: 0.9226 - loss: 0.1664 - val_accuracy: 0.9597 - val_loss: 0.1386 - learning_rate: 1.0000e-05\n",
      "Epoch 57/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9398 - loss: 0.1568\n",
      "Epoch 57: val_loss did not improve from 0.13861\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9399 - loss: 0.1566 - val_accuracy: 0.9435 - val_loss: 0.1756 - learning_rate: 1.0000e-05\n",
      "Epoch 58/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9281 - loss: 0.1808\n",
      "Epoch 58: val_loss did not improve from 0.13861\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 116ms/step - accuracy: 0.9283 - loss: 0.1806 - val_accuracy: 0.9435 - val_loss: 0.1554 - learning_rate: 1.0000e-05\n",
      "Epoch 59/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9520 - loss: 0.0989\n",
      "Epoch 59: val_loss improved from 0.13861 to 0.13791, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.9520 - loss: 0.0991 - val_accuracy: 0.9435 - val_loss: 0.1379 - learning_rate: 1.0000e-05\n",
      "Epoch 60/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9486 - loss: 0.1480\n",
      "Epoch 60: val_loss did not improve from 0.13791\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.9486 - loss: 0.1479 - val_accuracy: 0.9435 - val_loss: 0.1598 - learning_rate: 1.0000e-05\n",
      "Epoch 61/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9597 - loss: 0.1036\n",
      "Epoch 61: val_loss improved from 0.13791 to 0.11908, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 126ms/step - accuracy: 0.9597 - loss: 0.1035 - val_accuracy: 0.9597 - val_loss: 0.1191 - learning_rate: 1.0000e-05\n",
      "Epoch 62/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9568 - loss: 0.1074\n",
      "Epoch 62: val_loss did not improve from 0.11908\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 117ms/step - accuracy: 0.9568 - loss: 0.1075 - val_accuracy: 0.9435 - val_loss: 0.1603 - learning_rate: 1.0000e-05\n",
      "Epoch 63/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9447 - loss: 0.1418\n",
      "Epoch 63: val_loss did not improve from 0.11908\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.9448 - loss: 0.1416 - val_accuracy: 0.9435 - val_loss: 0.1451 - learning_rate: 1.0000e-05\n",
      "Epoch 64/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9716 - loss: 0.0985\n",
      "Epoch 64: val_loss did not improve from 0.11908\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 122ms/step - accuracy: 0.9714 - loss: 0.0988 - val_accuracy: 0.9516 - val_loss: 0.1195 - learning_rate: 1.0000e-05\n",
      "Epoch 65/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9531 - loss: 0.1190\n",
      "Epoch 65: val_loss improved from 0.11908 to 0.10720, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 126ms/step - accuracy: 0.9531 - loss: 0.1190 - val_accuracy: 0.9597 - val_loss: 0.1072 - learning_rate: 1.0000e-05\n",
      "Epoch 66/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9504 - loss: 0.1249\n",
      "Epoch 66: val_loss improved from 0.10720 to 0.09766, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.9504 - loss: 0.1248 - val_accuracy: 0.9597 - val_loss: 0.0977 - learning_rate: 1.0000e-05\n",
      "Epoch 67/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9554 - loss: 0.1102\n",
      "Epoch 67: val_loss did not improve from 0.09766\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.9554 - loss: 0.1102 - val_accuracy: 0.9597 - val_loss: 0.1077 - learning_rate: 1.0000e-05\n",
      "Epoch 68/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9752 - loss: 0.0676\n",
      "Epoch 68: val_loss did not improve from 0.09766\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.9752 - loss: 0.0676 - val_accuracy: 0.9435 - val_loss: 0.1224 - learning_rate: 1.0000e-05\n",
      "Epoch 69/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9671 - loss: 0.0779\n",
      "Epoch 69: val_loss did not improve from 0.09766\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9671 - loss: 0.0780 - val_accuracy: 0.9677 - val_loss: 0.1009 - learning_rate: 1.0000e-05\n",
      "Epoch 70/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9501 - loss: 0.1242\n",
      "Epoch 70: val_loss did not improve from 0.09766\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9501 - loss: 0.1241 - val_accuracy: 0.9677 - val_loss: 0.1122 - learning_rate: 1.0000e-05\n",
      "Epoch 71/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9613 - loss: 0.0921\n",
      "Epoch 71: val_loss improved from 0.09766 to 0.08216, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.9613 - loss: 0.0922 - val_accuracy: 0.9758 - val_loss: 0.0822 - learning_rate: 1.0000e-05\n",
      "Epoch 72/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9606 - loss: 0.0945\n",
      "Epoch 72: val_loss improved from 0.08216 to 0.07698, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.9606 - loss: 0.0946 - val_accuracy: 0.9758 - val_loss: 0.0770 - learning_rate: 1.0000e-05\n",
      "Epoch 73/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9617 - loss: 0.1149\n",
      "Epoch 73: val_loss improved from 0.07698 to 0.07002, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.9617 - loss: 0.1149 - val_accuracy: 0.9758 - val_loss: 0.0700 - learning_rate: 1.0000e-05\n",
      "Epoch 74/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9746 - loss: 0.0671\n",
      "Epoch 74: val_loss improved from 0.07002 to 0.06727, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.9746 - loss: 0.0672 - val_accuracy: 0.9758 - val_loss: 0.0673 - learning_rate: 1.0000e-05\n",
      "Epoch 75/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9760 - loss: 0.0746\n",
      "Epoch 75: val_loss improved from 0.06727 to 0.06010, saving model to results\\MobileNetV2_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.9760 - loss: 0.0745 - val_accuracy: 0.9839 - val_loss: 0.0601 - learning_rate: 1.0000e-05\n",
      "Epoch 76/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9778 - loss: 0.0685\n",
      "Epoch 76: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.9778 - loss: 0.0686 - val_accuracy: 0.9758 - val_loss: 0.0721 - learning_rate: 1.0000e-05\n",
      "Epoch 77/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9794 - loss: 0.0572\n",
      "Epoch 77: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.9793 - loss: 0.0573 - val_accuracy: 0.9839 - val_loss: 0.0646 - learning_rate: 1.0000e-05\n",
      "Epoch 78/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9720 - loss: 0.0702\n",
      "Epoch 78: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.9719 - loss: 0.0704 - val_accuracy: 0.9758 - val_loss: 0.0711 - learning_rate: 1.0000e-05\n",
      "Epoch 79/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9767 - loss: 0.0785\n",
      "Epoch 79: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9766 - loss: 0.0785 - val_accuracy: 0.9677 - val_loss: 0.0978 - learning_rate: 1.0000e-05\n",
      "Epoch 80/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9746 - loss: 0.0563\n",
      "Epoch 80: val_loss did not improve from 0.06010\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.9746 - loss: 0.0563 - val_accuracy: 0.9677 - val_loss: 0.1107 - learning_rate: 1.0000e-05\n",
      "Epoch 81/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9596 - loss: 0.0939\n",
      "Epoch 81: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.9596 - loss: 0.0939 - val_accuracy: 0.9677 - val_loss: 0.1006 - learning_rate: 2.0000e-06\n",
      "Epoch 82/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9689 - loss: 0.0772\n",
      "Epoch 82: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.9689 - loss: 0.0770 - val_accuracy: 0.9677 - val_loss: 0.0924 - learning_rate: 2.0000e-06\n",
      "Epoch 83/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9671 - loss: 0.0789\n",
      "Epoch 83: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 117ms/step - accuracy: 0.9671 - loss: 0.0789 - val_accuracy: 0.9758 - val_loss: 0.0854 - learning_rate: 2.0000e-06\n",
      "Epoch 84/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9628 - loss: 0.0846\n",
      "Epoch 84: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9628 - loss: 0.0846 - val_accuracy: 0.9758 - val_loss: 0.0742 - learning_rate: 2.0000e-06\n",
      "Epoch 85/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9682 - loss: 0.0828\n",
      "Epoch 85: val_loss did not improve from 0.06010\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9682 - loss: 0.0828 - val_accuracy: 0.9758 - val_loss: 0.0749 - learning_rate: 2.0000e-06\n",
      "Epoch 86/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9857 - loss: 0.0399\n",
      "Epoch 86: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.9856 - loss: 0.0400 - val_accuracy: 0.9758 - val_loss: 0.0740 - learning_rate: 4.0000e-07\n",
      "Epoch 87/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9862 - loss: 0.0466\n",
      "Epoch 87: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9861 - loss: 0.0467 - val_accuracy: 0.9758 - val_loss: 0.0742 - learning_rate: 4.0000e-07\n",
      "Epoch 88/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9710 - loss: 0.0766\n",
      "Epoch 88: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.9710 - loss: 0.0766 - val_accuracy: 0.9758 - val_loss: 0.0732 - learning_rate: 4.0000e-07\n",
      "Epoch 89/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9748 - loss: 0.0500\n",
      "Epoch 89: val_loss did not improve from 0.06010\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - accuracy: 0.9748 - loss: 0.0502 - val_accuracy: 0.9758 - val_loss: 0.0723 - learning_rate: 4.0000e-07\n",
      "Epoch 90/92\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9704 - loss: 0.0720\n",
      "Epoch 90: val_loss did not improve from 0.06010\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 119ms/step - accuracy: 0.9704 - loss: 0.0720 - val_accuracy: 0.9758 - val_loss: 0.0723 - learning_rate: 4.0000e-07\n",
      "Epoch 90: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV2_full_monty_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 268ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.97      0.98      0.98       103\n",
      "Shoot and Fruit Borer       0.99      0.98      0.98       145\n",
      "\n",
      "             accuracy                           0.98       248\n",
      "            macro avg       0.98      0.98      0.98       248\n",
      "         weighted avg       0.98      0.98      0.98       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for MobileNetV2_full_monty_bs8 is complete. Total time: 00:18:42 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV2\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d9cc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV3Large_from_scratch_bs8 ---\n",
      "Mode: from_scratch, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.5752 - loss: 0.6859\n",
      "Epoch 1: val_loss improved from inf to 0.69107, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 262ms/step - accuracy: 0.5756 - loss: 0.6855 - val_accuracy: 0.5887 - val_loss: 0.6911 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7461 - loss: 0.5484\n",
      "Epoch 2: val_loss did not improve from 0.69107\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 235ms/step - accuracy: 0.7460 - loss: 0.5484 - val_accuracy: 0.5887 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7397 - loss: 0.5294\n",
      "Epoch 3: val_loss did not improve from 0.69107\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 236ms/step - accuracy: 0.7400 - loss: 0.5291 - val_accuracy: 0.5887 - val_loss: 0.6924 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7795 - loss: 0.4803\n",
      "Epoch 4: val_loss did not improve from 0.69107\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 237ms/step - accuracy: 0.7795 - loss: 0.4802 - val_accuracy: 0.5887 - val_loss: 0.6920 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.7988 - loss: 0.4380\n",
      "Epoch 5: val_loss did not improve from 0.69107\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 239ms/step - accuracy: 0.7988 - loss: 0.4380 - val_accuracy: 0.5887 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8001 - loss: 0.4804\n",
      "Epoch 6: val_loss improved from 0.69107 to 0.69063, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 242ms/step - accuracy: 0.8001 - loss: 0.4803 - val_accuracy: 0.5887 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.8106 - loss: 0.3972\n",
      "Epoch 7: val_loss did not improve from 0.69063\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 241ms/step - accuracy: 0.8107 - loss: 0.3973 - val_accuracy: 0.5887 - val_loss: 0.6929 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.8441 - loss: 0.3839\n",
      "Epoch 8: val_loss did not improve from 0.69063\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 239ms/step - accuracy: 0.8439 - loss: 0.3842 - val_accuracy: 0.4113 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8224 - loss: 0.4179\n",
      "Epoch 9: val_loss did not improve from 0.69063\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 234ms/step - accuracy: 0.8224 - loss: 0.4179 - val_accuracy: 0.5887 - val_loss: 0.6909 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8370 - loss: 0.3764\n",
      "Epoch 10: val_loss improved from 0.69063 to 0.69029, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 239ms/step - accuracy: 0.8371 - loss: 0.3763 - val_accuracy: 0.5887 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8417 - loss: 0.3718\n",
      "Epoch 11: val_loss improved from 0.69029 to 0.68849, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 247ms/step - accuracy: 0.8417 - loss: 0.3720 - val_accuracy: 0.5887 - val_loss: 0.6885 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.8653 - loss: 0.3512\n",
      "Epoch 12: val_loss improved from 0.68849 to 0.68790, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.8652 - loss: 0.3513 - val_accuracy: 0.5887 - val_loss: 0.6879 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.8348 - loss: 0.4300\n",
      "Epoch 13: val_loss did not improve from 0.68790\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 247ms/step - accuracy: 0.8348 - loss: 0.4298 - val_accuracy: 0.5887 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.8183 - loss: 0.3804\n",
      "Epoch 14: val_loss did not improve from 0.68790\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 246ms/step - accuracy: 0.8184 - loss: 0.3802 - val_accuracy: 0.4113 - val_loss: 0.6937 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.8424 - loss: 0.3613\n",
      "Epoch 15: val_loss did not improve from 0.68790\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 248ms/step - accuracy: 0.8424 - loss: 0.3613 - val_accuracy: 0.5887 - val_loss: 0.6894 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8615 - loss: 0.3393\n",
      "Epoch 16: val_loss did not improve from 0.68790\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 242ms/step - accuracy: 0.8614 - loss: 0.3395 - val_accuracy: 0.5887 - val_loss: 0.6917 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.8807 - loss: 0.3443\n",
      "Epoch 17: val_loss did not improve from 0.68790\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 246ms/step - accuracy: 0.8806 - loss: 0.3444 - val_accuracy: 0.5887 - val_loss: 0.6889 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.8589 - loss: 0.3638\n",
      "Epoch 18: val_loss did not improve from 0.68790\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.8590 - loss: 0.3637 - val_accuracy: 0.5887 - val_loss: 0.6884 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.8487 - loss: 0.3628\n",
      "Epoch 19: val_loss improved from 0.68790 to 0.68307, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.8488 - loss: 0.3626 - val_accuracy: 0.5887 - val_loss: 0.6831 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8703 - loss: 0.3327\n",
      "Epoch 20: val_loss did not improve from 0.68307\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 239ms/step - accuracy: 0.8703 - loss: 0.3326 - val_accuracy: 0.5887 - val_loss: 0.6852 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.8679 - loss: 0.3194\n",
      "Epoch 21: val_loss did not improve from 0.68307\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 237ms/step - accuracy: 0.8679 - loss: 0.3195 - val_accuracy: 0.4113 - val_loss: 0.6978 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8627 - loss: 0.3165\n",
      "Epoch 22: val_loss did not improve from 0.68307\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 238ms/step - accuracy: 0.8628 - loss: 0.3165 - val_accuracy: 0.5887 - val_loss: 0.6852 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.8781 - loss: 0.2980\n",
      "Epoch 23: val_loss did not improve from 0.68307\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 241ms/step - accuracy: 0.8781 - loss: 0.2979 - val_accuracy: 0.5887 - val_loss: 0.6853 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.8875 - loss: 0.2772\n",
      "Epoch 24: val_loss did not improve from 0.68307\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 240ms/step - accuracy: 0.8875 - loss: 0.2773 - val_accuracy: 0.5887 - val_loss: 0.6843 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8932 - loss: 0.2839\n",
      "Epoch 25: val_loss improved from 0.68307 to 0.68281, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 243ms/step - accuracy: 0.8931 - loss: 0.2839 - val_accuracy: 0.5887 - val_loss: 0.6828 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8615 - loss: 0.3250\n",
      "Epoch 26: val_loss did not improve from 0.68281\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 242ms/step - accuracy: 0.8616 - loss: 0.3250 - val_accuracy: 0.5887 - val_loss: 0.6909 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8982 - loss: 0.3035\n",
      "Epoch 27: val_loss improved from 0.68281 to 0.67844, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 246ms/step - accuracy: 0.8982 - loss: 0.3034 - val_accuracy: 0.5887 - val_loss: 0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9050 - loss: 0.2588\n",
      "Epoch 28: val_loss improved from 0.67844 to 0.67747, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.9049 - loss: 0.2589 - val_accuracy: 0.5887 - val_loss: 0.6775 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.8898 - loss: 0.2846\n",
      "Epoch 29: val_loss improved from 0.67747 to 0.67734, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 250ms/step - accuracy: 0.8898 - loss: 0.2847 - val_accuracy: 0.5887 - val_loss: 0.6773 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8711 - loss: 0.3478\n",
      "Epoch 30: val_loss did not improve from 0.67734\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 243ms/step - accuracy: 0.8712 - loss: 0.3475 - val_accuracy: 0.5887 - val_loss: 0.6774 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.8885 - loss: 0.2867\n",
      "Epoch 31: val_loss improved from 0.67734 to 0.67732, saving model to results\\MobileNetV3Large_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 246ms/step - accuracy: 0.8884 - loss: 0.2867 - val_accuracy: 0.5887 - val_loss: 0.6773 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9093 - loss: 0.2702\n",
      "Epoch 32: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.9092 - loss: 0.2703 - val_accuracy: 0.5887 - val_loss: 0.6782 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9015 - loss: 0.2594\n",
      "Epoch 33: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 243ms/step - accuracy: 0.9013 - loss: 0.2596 - val_accuracy: 0.5887 - val_loss: 0.6779 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9156 - loss: 0.2467\n",
      "Epoch 34: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 243ms/step - accuracy: 0.9156 - loss: 0.2468 - val_accuracy: 0.5887 - val_loss: 0.6811 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8980 - loss: 0.2529\n",
      "Epoch 35: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.8981 - loss: 0.2530 - val_accuracy: 0.5887 - val_loss: 0.6859 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9183 - loss: 0.2443\n",
      "Epoch 36: val_loss did not improve from 0.67732\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 246ms/step - accuracy: 0.9182 - loss: 0.2445 - val_accuracy: 0.5887 - val_loss: 0.6853 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9012 - loss: 0.2533\n",
      "Epoch 37: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.9012 - loss: 0.2532 - val_accuracy: 0.5887 - val_loss: 0.6900 - learning_rate: 2.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9159 - loss: 0.2448\n",
      "Epoch 38: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.9158 - loss: 0.2448 - val_accuracy: 0.5887 - val_loss: 0.6905 - learning_rate: 2.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9241 - loss: 0.2236\n",
      "Epoch 39: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.9240 - loss: 0.2237 - val_accuracy: 0.5887 - val_loss: 0.6960 - learning_rate: 2.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9156 - loss: 0.2327\n",
      "Epoch 40: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 243ms/step - accuracy: 0.9157 - loss: 0.2327 - val_accuracy: 0.5887 - val_loss: 0.7028 - learning_rate: 2.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9243 - loss: 0.2012\n",
      "Epoch 41: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.9243 - loss: 0.2013 - val_accuracy: 0.5887 - val_loss: 0.7147 - learning_rate: 2.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9142 - loss: 0.2125\n",
      "Epoch 42: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.9143 - loss: 0.2123 - val_accuracy: 0.5887 - val_loss: 0.7502 - learning_rate: 2.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9312 - loss: 0.1864\n",
      "Epoch 43: val_loss did not improve from 0.67732\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 242ms/step - accuracy: 0.9312 - loss: 0.1864 - val_accuracy: 0.5887 - val_loss: 0.7565 - learning_rate: 2.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9348 - loss: 0.1997\n",
      "Epoch 44: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 241ms/step - accuracy: 0.9348 - loss: 0.1997 - val_accuracy: 0.5887 - val_loss: 0.7763 - learning_rate: 4.0000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9127 - loss: 0.2403\n",
      "Epoch 45: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 242ms/step - accuracy: 0.9128 - loss: 0.2401 - val_accuracy: 0.5887 - val_loss: 0.7784 - learning_rate: 4.0000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9419 - loss: 0.1599\n",
      "Epoch 46: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 243ms/step - accuracy: 0.9419 - loss: 0.1600 - val_accuracy: 0.5887 - val_loss: 0.8056 - learning_rate: 4.0000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9043 - loss: 0.2287\n",
      "Epoch 47: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 242ms/step - accuracy: 0.9044 - loss: 0.2285 - val_accuracy: 0.5887 - val_loss: 0.8420 - learning_rate: 4.0000e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9475 - loss: 0.1577\n",
      "Epoch 48: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.9475 - loss: 0.1578 - val_accuracy: 0.5887 - val_loss: 0.8137 - learning_rate: 4.0000e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9458 - loss: 0.1665\n",
      "Epoch 49: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 243ms/step - accuracy: 0.9457 - loss: 0.1667 - val_accuracy: 0.5887 - val_loss: 0.8593 - learning_rate: 4.0000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9477 - loss: 0.1593\n",
      "Epoch 50: val_loss did not improve from 0.67732\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 240ms/step - accuracy: 0.9476 - loss: 0.1594 - val_accuracy: 0.5887 - val_loss: 0.8753 - learning_rate: 4.0000e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9502 - loss: 0.1454\n",
      "Epoch 51: val_loss did not improve from 0.67732\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 242ms/step - accuracy: 0.9502 - loss: 0.1455 - val_accuracy: 0.5887 - val_loss: 0.9057 - learning_rate: 8.0000e-07\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV3Large_from_scratch_bs8 Final Test Set Evaluation ---\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C2F06613A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.00      0.00      0.00       103\n",
      "Shoot and Fruit Borer       0.58      1.00      0.74       145\n",
      "\n",
      "             accuracy                           0.58       248\n",
      "            macro avg       0.29      0.50      0.37       248\n",
      "         weighted avg       0.34      0.58      0.43       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment for MobileNetV3Large_from_scratch_bs8 is complete. Total time: 00:26:39 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV3Large\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c0b12aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV3Large_transfer_learning_bs8 ---\n",
      "Mode: transfer_learning, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.5014 - loss: 0.7969 - val_accuracy: 0.4113 - val_loss: 0.7151\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.4428 - loss: 0.7518 - val_accuracy: 0.4032 - val_loss: 0.6989\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.4853 - loss: 0.7348 - val_accuracy: 0.5887 - val_loss: 0.6928\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5186 - loss: 0.7292 - val_accuracy: 0.5806 - val_loss: 0.6891\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.4836 - loss: 0.7200 - val_accuracy: 0.5968 - val_loss: 0.6858\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5283 - loss: 0.7081 - val_accuracy: 0.7500 - val_loss: 0.6888\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.4896 - loss: 0.7127 - val_accuracy: 0.7258 - val_loss: 0.6878\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.4737 - loss: 0.7065 - val_accuracy: 0.6452 - val_loss: 0.6823\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.5613 - loss: 0.6974 - val_accuracy: 0.7258 - val_loss: 0.6828\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.5176 - loss: 0.6938 - val_accuracy: 0.7339 - val_loss: 0.6834\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.5178 - loss: 0.7014 - val_accuracy: 0.7258 - val_loss: 0.6783\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5035 - loss: 0.7016 - val_accuracy: 0.7339 - val_loss: 0.6775\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.4969 - loss: 0.6966 - val_accuracy: 0.6935 - val_loss: 0.6738\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5369 - loss: 0.6924 - val_accuracy: 0.7097 - val_loss: 0.6764\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5494 - loss: 0.6896 - val_accuracy: 0.7419 - val_loss: 0.6743\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5156 - loss: 0.6950 - val_accuracy: 0.7419 - val_loss: 0.6748\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5376 - loss: 0.6875 - val_accuracy: 0.7581 - val_loss: 0.6746\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5739 - loss: 0.6859 - val_accuracy: 0.7258 - val_loss: 0.6717\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5736 - loss: 0.6793 - val_accuracy: 0.7177 - val_loss: 0.6654\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5391 - loss: 0.6849 - val_accuracy: 0.7500 - val_loss: 0.6707\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5478 - loss: 0.6870 - val_accuracy: 0.7500 - val_loss: 0.6682\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5744 - loss: 0.6797 - val_accuracy: 0.7419 - val_loss: 0.6629\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.5541 - loss: 0.6886 - val_accuracy: 0.7581 - val_loss: 0.6666\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.5958 - loss: 0.6710 - val_accuracy: 0.7581 - val_loss: 0.6606\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5635 - loss: 0.6781 - val_accuracy: 0.7581 - val_loss: 0.6595\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.5706 - loss: 0.6800 - val_accuracy: 0.7581 - val_loss: 0.6583\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5783 - loss: 0.6808 - val_accuracy: 0.7661 - val_loss: 0.6573\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5682 - loss: 0.6804 - val_accuracy: 0.7339 - val_loss: 0.6556\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5632 - loss: 0.6769 - val_accuracy: 0.7258 - val_loss: 0.6594\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5417 - loss: 0.6807 - val_accuracy: 0.7419 - val_loss: 0.6564\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5868 - loss: 0.6730 - val_accuracy: 0.7581 - val_loss: 0.6546\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.6344 - loss: 0.6659 - val_accuracy: 0.7500 - val_loss: 0.6579\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.6100 - loss: 0.6650 - val_accuracy: 0.7258 - val_loss: 0.6548\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.5614 - loss: 0.6801 - val_accuracy: 0.7581 - val_loss: 0.6566\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.6167 - loss: 0.6618 - val_accuracy: 0.7339 - val_loss: 0.6530\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5719 - loss: 0.6831 - val_accuracy: 0.7661 - val_loss: 0.6497\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.6187 - loss: 0.6661 - val_accuracy: 0.7258 - val_loss: 0.6517\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.6252 - loss: 0.6692 - val_accuracy: 0.7581 - val_loss: 0.6486\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5783 - loss: 0.6676 - val_accuracy: 0.7419 - val_loss: 0.6485\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5821 - loss: 0.6744 - val_accuracy: 0.7581 - val_loss: 0.6454\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5815 - loss: 0.6738 - val_accuracy: 0.7581 - val_loss: 0.6467\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5997 - loss: 0.6662 - val_accuracy: 0.7581 - val_loss: 0.6497\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5855 - loss: 0.6711 - val_accuracy: 0.7581 - val_loss: 0.6455\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.6088 - loss: 0.6763 - val_accuracy: 0.7661 - val_loss: 0.6432\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5957 - loss: 0.6699 - val_accuracy: 0.7258 - val_loss: 0.6462\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.6110 - loss: 0.6682 - val_accuracy: 0.7339 - val_loss: 0.6443\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.6157 - loss: 0.6685 - val_accuracy: 0.7581 - val_loss: 0.6429\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.6460 - loss: 0.6603 - val_accuracy: 0.7258 - val_loss: 0.6442\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.5749 - loss: 0.6702 - val_accuracy: 0.7258 - val_loss: 0.6435\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.5935 - loss: 0.6721 - val_accuracy: 0.7258 - val_loss: 0.6416\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV3Large_transfer_learning_bs8 Final Test Set Evaluation ---\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C3DCAE6340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.81      0.46      0.58       103\n",
      "Shoot and Fruit Borer       0.71      0.92      0.80       145\n",
      "\n",
      "             accuracy                           0.73       248\n",
      "            macro avg       0.76      0.69      0.69       248\n",
      "         weighted avg       0.75      0.73      0.71       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for MobileNetV3Large_transfer_learning_bs8 is complete. Total time: 00:07:39 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV3Large\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e477b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV3Large_fine_tune_bs8 ---\n",
      "Mode: fine_tune, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 210ms/step - accuracy: 0.4894 - loss: 0.7667 - val_accuracy: 0.5968 - val_loss: 0.6880\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - accuracy: 0.5305 - loss: 0.7446 - val_accuracy: 0.5161 - val_loss: 0.6915\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - accuracy: 0.4719 - loss: 0.7404 - val_accuracy: 0.6774 - val_loss: 0.6891\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 195ms/step - accuracy: 0.5166 - loss: 0.7126 - val_accuracy: 0.4516 - val_loss: 0.6913\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 194ms/step - accuracy: 0.4695 - loss: 0.7464 - val_accuracy: 0.4355 - val_loss: 0.6905\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 196ms/step - accuracy: 0.5198 - loss: 0.7306 - val_accuracy: 0.6694 - val_loss: 0.6822\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 187ms/step - accuracy: 0.5149 - loss: 0.7104 - val_accuracy: 0.6613 - val_loss: 0.6802\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - accuracy: 0.4774 - loss: 0.7191 - val_accuracy: 0.7339 - val_loss: 0.6804\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - accuracy: 0.5274 - loss: 0.7040 - val_accuracy: 0.7016 - val_loss: 0.6773\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 194ms/step - accuracy: 0.5510 - loss: 0.7061 - val_accuracy: 0.7500 - val_loss: 0.6789\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 194ms/step - accuracy: 0.5370 - loss: 0.7003 - val_accuracy: 0.7500 - val_loss: 0.6774\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 194ms/step - accuracy: 0.5382 - loss: 0.6912 - val_accuracy: 0.7419 - val_loss: 0.6755\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 195ms/step - accuracy: 0.5203 - loss: 0.7064 - val_accuracy: 0.7500 - val_loss: 0.6732\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 196ms/step - accuracy: 0.5190 - loss: 0.6953 - val_accuracy: 0.7419 - val_loss: 0.6735\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 196ms/step - accuracy: 0.4981 - loss: 0.7035 - val_accuracy: 0.7097 - val_loss: 0.6686\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 196ms/step - accuracy: 0.5361 - loss: 0.6906 - val_accuracy: 0.7339 - val_loss: 0.6679\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 197ms/step - accuracy: 0.5529 - loss: 0.6906 - val_accuracy: 0.7339 - val_loss: 0.6675\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 198ms/step - accuracy: 0.5630 - loss: 0.6854 - val_accuracy: 0.7419 - val_loss: 0.6701\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 200ms/step - accuracy: 0.5378 - loss: 0.6922 - val_accuracy: 0.7661 - val_loss: 0.6659\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 206ms/step - accuracy: 0.5353 - loss: 0.6880 - val_accuracy: 0.7258 - val_loss: 0.6627\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 208ms/step - accuracy: 0.5442 - loss: 0.6861 - val_accuracy: 0.7419 - val_loss: 0.6669\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 209ms/step - accuracy: 0.5543 - loss: 0.6818 - val_accuracy: 0.7339 - val_loss: 0.6639\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 212ms/step - accuracy: 0.5617 - loss: 0.6804 - val_accuracy: 0.7419 - val_loss: 0.6619\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 212ms/step - accuracy: 0.5641 - loss: 0.6829 - val_accuracy: 0.7339 - val_loss: 0.6580\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 208ms/step - accuracy: 0.5562 - loss: 0.6861 - val_accuracy: 0.7661 - val_loss: 0.6593\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.5911 - loss: 0.6743 - val_accuracy: 0.7661 - val_loss: 0.6575\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 204ms/step - accuracy: 0.5624 - loss: 0.6853 - val_accuracy: 0.7419 - val_loss: 0.6585\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 206ms/step - accuracy: 0.5713 - loss: 0.6742 - val_accuracy: 0.7581 - val_loss: 0.6571\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.6041 - loss: 0.6764 - val_accuracy: 0.7419 - val_loss: 0.6587\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.5327 - loss: 0.6899 - val_accuracy: 0.7419 - val_loss: 0.6562\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.5725 - loss: 0.6778 - val_accuracy: 0.7419 - val_loss: 0.6559\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.6114 - loss: 0.6718 - val_accuracy: 0.7339 - val_loss: 0.6509\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 206ms/step - accuracy: 0.5528 - loss: 0.6857 - val_accuracy: 0.7339 - val_loss: 0.6548\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.5626 - loss: 0.6769 - val_accuracy: 0.7419 - val_loss: 0.6540\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.5858 - loss: 0.6789 - val_accuracy: 0.7581 - val_loss: 0.6497\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 204ms/step - accuracy: 0.6103 - loss: 0.6741 - val_accuracy: 0.7419 - val_loss: 0.6511\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 204ms/step - accuracy: 0.5914 - loss: 0.6719 - val_accuracy: 0.7661 - val_loss: 0.6478\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.5932 - loss: 0.6705 - val_accuracy: 0.7661 - val_loss: 0.6475\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 201ms/step - accuracy: 0.5739 - loss: 0.6784 - val_accuracy: 0.7661 - val_loss: 0.6477\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.5869 - loss: 0.6726 - val_accuracy: 0.7500 - val_loss: 0.6480\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.5857 - loss: 0.6767 - val_accuracy: 0.7419 - val_loss: 0.6479\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.6029 - loss: 0.6682 - val_accuracy: 0.7661 - val_loss: 0.6427\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.5866 - loss: 0.6689 - val_accuracy: 0.7419 - val_loss: 0.6462\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.5953 - loss: 0.6727 - val_accuracy: 0.7661 - val_loss: 0.6438\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.6084 - loss: 0.6755 - val_accuracy: 0.7500 - val_loss: 0.6438\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.6352 - loss: 0.6677 - val_accuracy: 0.7661 - val_loss: 0.6483\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.6223 - loss: 0.6660 - val_accuracy: 0.7419 - val_loss: 0.6435\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.5911 - loss: 0.6723 - val_accuracy: 0.7500 - val_loss: 0.6385\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.6049 - loss: 0.6615 - val_accuracy: 0.7661 - val_loss: 0.6385\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.5830 - loss: 0.6747 - val_accuracy: 0.7661 - val_loss: 0.6384\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV3Large_fine_tune_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 486ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.83      0.38      0.52       103\n",
      "Shoot and Fruit Borer       0.68      0.94      0.79       145\n",
      "\n",
      "             accuracy                           0.71       248\n",
      "            macro avg       0.76      0.66      0.66       248\n",
      "         weighted avg       0.74      0.71      0.68       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for MobileNetV3Large_fine_tune_bs8 is complete. Total time: 00:21:25 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV3Large\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcc62a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: MobileNetV3Large_full_monty_bs8 ---\n",
      "Mode: full_monty, Batch Size: 8, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4546 - loss: 0.8186\n",
      "Epoch 1: val_loss improved from inf to 0.69612, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 0.4548 - loss: 0.8183 - val_accuracy: 0.3710 - val_loss: 0.6961 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5259 - loss: 0.7368\n",
      "Epoch 2: val_loss improved from 0.69612 to 0.69518, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5259 - loss: 0.7367 - val_accuracy: 0.3952 - val_loss: 0.6952 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5089 - loss: 0.7447\n",
      "Epoch 3: val_loss improved from 0.69518 to 0.69026, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5088 - loss: 0.7447 - val_accuracy: 0.6532 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4852 - loss: 0.7317\n",
      "Epoch 4: val_loss improved from 0.69026 to 0.68471, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.4853 - loss: 0.7317 - val_accuracy: 0.5887 - val_loss: 0.6847 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7136\n",
      "Epoch 5: val_loss did not improve from 0.68471\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.5358 - loss: 0.7136 - val_accuracy: 0.6452 - val_loss: 0.6861 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4768 - loss: 0.7402\n",
      "Epoch 6: val_loss improved from 0.68471 to 0.68380, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.4769 - loss: 0.7401 - val_accuracy: 0.6613 - val_loss: 0.6838 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4734 - loss: 0.7247\n",
      "Epoch 7: val_loss improved from 0.68380 to 0.68131, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.4735 - loss: 0.7246 - val_accuracy: 0.6371 - val_loss: 0.6813 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5181 - loss: 0.7256\n",
      "Epoch 8: val_loss did not improve from 0.68131\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5181 - loss: 0.7256 - val_accuracy: 0.7258 - val_loss: 0.6827 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5494 - loss: 0.6986\n",
      "Epoch 9: val_loss did not improve from 0.68131\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5493 - loss: 0.6986 - val_accuracy: 0.7339 - val_loss: 0.6817 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4959 - loss: 0.7155\n",
      "Epoch 10: val_loss improved from 0.68131 to 0.67842, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.4958 - loss: 0.7155 - val_accuracy: 0.6935 - val_loss: 0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5294 - loss: 0.6982\n",
      "Epoch 11: val_loss improved from 0.67842 to 0.67464, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5294 - loss: 0.6983 - val_accuracy: 0.6290 - val_loss: 0.6746 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5327 - loss: 0.7018\n",
      "Epoch 12: val_loss did not improve from 0.67464\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.5325 - loss: 0.7018 - val_accuracy: 0.7177 - val_loss: 0.6763 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4918 - loss: 0.7066\n",
      "Epoch 13: val_loss did not improve from 0.67464\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.4920 - loss: 0.7066 - val_accuracy: 0.7661 - val_loss: 0.6760 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5031 - loss: 0.7014\n",
      "Epoch 14: val_loss did not improve from 0.67464\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.5031 - loss: 0.7014 - val_accuracy: 0.7742 - val_loss: 0.6749 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5096 - loss: 0.6946\n",
      "Epoch 15: val_loss did not improve from 0.67464\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.5097 - loss: 0.6946 - val_accuracy: 0.7742 - val_loss: 0.6752 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5120 - loss: 0.6969\n",
      "Epoch 16: val_loss improved from 0.67464 to 0.67401, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5120 - loss: 0.6968 - val_accuracy: 0.7742 - val_loss: 0.6740 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5217 - loss: 0.6915\n",
      "Epoch 17: val_loss improved from 0.67401 to 0.67079, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5218 - loss: 0.6915 - val_accuracy: 0.7661 - val_loss: 0.6708 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m126/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5201 - loss: 0.6940\n",
      "Epoch 18: val_loss improved from 0.67079 to 0.66915, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5201 - loss: 0.6940 - val_accuracy: 0.7581 - val_loss: 0.6691 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5415 - loss: 0.6888\n",
      "Epoch 19: val_loss improved from 0.66915 to 0.66841, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5416 - loss: 0.6888 - val_accuracy: 0.7661 - val_loss: 0.6684 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5928 - loss: 0.6752\n",
      "Epoch 20: val_loss did not improve from 0.66841\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.5927 - loss: 0.6752 - val_accuracy: 0.7661 - val_loss: 0.6702 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5793 - loss: 0.6811\n",
      "Epoch 21: val_loss improved from 0.66841 to 0.66499, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5793 - loss: 0.6810 - val_accuracy: 0.7581 - val_loss: 0.6650 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5748 - loss: 0.6801\n",
      "Epoch 22: val_loss improved from 0.66499 to 0.66063, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5746 - loss: 0.6801 - val_accuracy: 0.6935 - val_loss: 0.6606 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5616 - loss: 0.6827\n",
      "Epoch 23: val_loss did not improve from 0.66063\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5616 - loss: 0.6827 - val_accuracy: 0.7419 - val_loss: 0.6615 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5752 - loss: 0.6787\n",
      "Epoch 24: val_loss did not improve from 0.66063\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.5751 - loss: 0.6787 - val_accuracy: 0.7419 - val_loss: 0.6658 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5796 - loss: 0.6806\n",
      "Epoch 25: val_loss did not improve from 0.66063\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.5796 - loss: 0.6806 - val_accuracy: 0.7581 - val_loss: 0.6621 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5285 - loss: 0.6907\n",
      "Epoch 26: val_loss did not improve from 0.66063\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.5287 - loss: 0.6906 - val_accuracy: 0.7661 - val_loss: 0.6635 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5786 - loss: 0.6792\n",
      "Epoch 27: val_loss improved from 0.66063 to 0.65891, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.5787 - loss: 0.6792 - val_accuracy: 0.7581 - val_loss: 0.6589 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5658 - loss: 0.6787\n",
      "Epoch 28: val_loss did not improve from 0.65891\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5657 - loss: 0.6788 - val_accuracy: 0.7581 - val_loss: 0.6611 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5798 - loss: 0.6760\n",
      "Epoch 29: val_loss improved from 0.65891 to 0.65782, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.5799 - loss: 0.6760 - val_accuracy: 0.7661 - val_loss: 0.6578 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5572 - loss: 0.6773\n",
      "Epoch 30: val_loss improved from 0.65782 to 0.65774, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.5573 - loss: 0.6772 - val_accuracy: 0.7661 - val_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5709 - loss: 0.6778\n",
      "Epoch 31: val_loss did not improve from 0.65774\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5708 - loss: 0.6778 - val_accuracy: 0.7581 - val_loss: 0.6581 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5505 - loss: 0.6872\n",
      "Epoch 32: val_loss improved from 0.65774 to 0.65478, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5506 - loss: 0.6871 - val_accuracy: 0.7661 - val_loss: 0.6548 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5905 - loss: 0.6773\n",
      "Epoch 33: val_loss did not improve from 0.65478\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.5904 - loss: 0.6773 - val_accuracy: 0.7661 - val_loss: 0.6552 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5993 - loss: 0.6722\n",
      "Epoch 34: val_loss improved from 0.65478 to 0.65364, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5991 - loss: 0.6722 - val_accuracy: 0.7661 - val_loss: 0.6536 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5601 - loss: 0.6779\n",
      "Epoch 35: val_loss did not improve from 0.65364\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5601 - loss: 0.6779 - val_accuracy: 0.7581 - val_loss: 0.6549 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5782 - loss: 0.6685\n",
      "Epoch 36: val_loss improved from 0.65364 to 0.65165, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.5782 - loss: 0.6685 - val_accuracy: 0.7661 - val_loss: 0.6517 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5766 - loss: 0.6724\n",
      "Epoch 37: val_loss improved from 0.65165 to 0.65145, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5768 - loss: 0.6724 - val_accuracy: 0.7661 - val_loss: 0.6515 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5846 - loss: 0.6783\n",
      "Epoch 38: val_loss improved from 0.65145 to 0.65134, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5848 - loss: 0.6783 - val_accuracy: 0.7661 - val_loss: 0.6513 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5948 - loss: 0.6755\n",
      "Epoch 39: val_loss did not improve from 0.65134\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5948 - loss: 0.6755 - val_accuracy: 0.7742 - val_loss: 0.6544 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5952 - loss: 0.6735\n",
      "Epoch 40: val_loss improved from 0.65134 to 0.64819, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.5951 - loss: 0.6735 - val_accuracy: 0.7661 - val_loss: 0.6482 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5786 - loss: 0.6784\n",
      "Epoch 41: val_loss did not improve from 0.64819\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5788 - loss: 0.6784 - val_accuracy: 0.7581 - val_loss: 0.6506 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6091 - loss: 0.6674\n",
      "Epoch 42: val_loss improved from 0.64819 to 0.64715, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.6091 - loss: 0.6674 - val_accuracy: 0.7661 - val_loss: 0.6471 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6147 - loss: 0.6675\n",
      "Epoch 43: val_loss improved from 0.64715 to 0.64673, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.6146 - loss: 0.6675 - val_accuracy: 0.7661 - val_loss: 0.6467 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5659 - loss: 0.6752\n",
      "Epoch 44: val_loss improved from 0.64673 to 0.64620, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.5661 - loss: 0.6752 - val_accuracy: 0.7661 - val_loss: 0.6462 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6143 - loss: 0.6695\n",
      "Epoch 45: val_loss did not improve from 0.64620\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.6143 - loss: 0.6695 - val_accuracy: 0.7742 - val_loss: 0.6468 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5521 - loss: 0.6769\n",
      "Epoch 46: val_loss improved from 0.64620 to 0.64110, saving model to results\\MobileNetV3Large_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.5524 - loss: 0.6768 - val_accuracy: 0.7500 - val_loss: 0.6411 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5692 - loss: 0.6750\n",
      "Epoch 47: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5694 - loss: 0.6749 - val_accuracy: 0.7661 - val_loss: 0.6439 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6463 - loss: 0.6577\n",
      "Epoch 48: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.6463 - loss: 0.6578 - val_accuracy: 0.7661 - val_loss: 0.6419 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6233 - loss: 0.6714\n",
      "Epoch 49: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.6231 - loss: 0.6714 - val_accuracy: 0.7742 - val_loss: 0.6437 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5673 - loss: 0.6712\n",
      "Epoch 50: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5675 - loss: 0.6712 - val_accuracy: 0.7742 - val_loss: 0.6430 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 51/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5044 - loss: 1.0043\n",
      "Epoch 51: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.5048 - loss: 1.0031 - val_accuracy: 0.7097 - val_loss: 0.6579 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6396 - loss: 0.6943\n",
      "Epoch 52: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6394 - loss: 0.6944 - val_accuracy: 0.4113 - val_loss: 0.6870 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6068 - loss: 0.7359\n",
      "Epoch 53: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6069 - loss: 0.7357 - val_accuracy: 0.4113 - val_loss: 0.7427 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6178 - loss: 0.6989\n",
      "Epoch 54: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6180 - loss: 0.6986 - val_accuracy: 0.4113 - val_loss: 0.8187 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6433 - loss: 0.6508\n",
      "Epoch 55: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6433 - loss: 0.6508 - val_accuracy: 0.4113 - val_loss: 0.9030 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6684 - loss: 0.6143\n",
      "Epoch 56: val_loss did not improve from 0.64110\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6683 - loss: 0.6144 - val_accuracy: 0.4113 - val_loss: 0.9994 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7098 - loss: 0.5568\n",
      "Epoch 57: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.7097 - loss: 0.5570 - val_accuracy: 0.4113 - val_loss: 1.0932 - learning_rate: 2.0000e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7048 - loss: 0.5814\n",
      "Epoch 58: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.7048 - loss: 0.5814 - val_accuracy: 0.4113 - val_loss: 1.1442 - learning_rate: 2.0000e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6812 - loss: 0.5803\n",
      "Epoch 59: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.6811 - loss: 0.5804 - val_accuracy: 0.4113 - val_loss: 1.1404 - learning_rate: 2.0000e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6976 - loss: 0.5808\n",
      "Epoch 60: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6976 - loss: 0.5808 - val_accuracy: 0.4113 - val_loss: 1.0757 - learning_rate: 2.0000e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6692 - loss: 0.5860\n",
      "Epoch 61: val_loss did not improve from 0.64110\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.6694 - loss: 0.5858 - val_accuracy: 0.4113 - val_loss: 1.0109 - learning_rate: 2.0000e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6804 - loss: 0.5930\n",
      "Epoch 62: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6804 - loss: 0.5930 - val_accuracy: 0.4113 - val_loss: 0.9623 - learning_rate: 4.0000e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7049 - loss: 0.5461\n",
      "Epoch 63: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.7048 - loss: 0.5462 - val_accuracy: 0.4113 - val_loss: 0.9531 - learning_rate: 4.0000e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6792 - loss: 0.5834\n",
      "Epoch 64: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.6793 - loss: 0.5835 - val_accuracy: 0.4113 - val_loss: 0.9609 - learning_rate: 4.0000e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6641 - loss: 0.6172\n",
      "Epoch 65: val_loss did not improve from 0.64110\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.6642 - loss: 0.6171 - val_accuracy: 0.4113 - val_loss: 0.9643 - learning_rate: 4.0000e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7009 - loss: 0.5731\n",
      "Epoch 66: val_loss did not improve from 0.64110\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.7008 - loss: 0.5733 - val_accuracy: 0.3710 - val_loss: 0.9533 - learning_rate: 4.0000e-07\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- MobileNetV3Large_full_monty_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 261ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.89      0.33      0.48       103\n",
      "Shoot and Fruit Borer       0.67      0.97      0.79       145\n",
      "\n",
      "             accuracy                           0.71       248\n",
      "            macro avg       0.78      0.65      0.64       248\n",
      "         weighted avg       0.76      0.71      0.66       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for MobileNetV3Large_full_monty_bs8 is complete. Total time: 00:11:37 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"MobileNetV3Large\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0352c042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: EfficientNetB0_from_scratch_bs16 ---\n",
      "Mode: from_scratch, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - accuracy: 0.5615 - loss: 0.7385\n",
      "Epoch 1: val_loss improved from inf to 0.68612, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 833ms/step - accuracy: 0.5617 - loss: 0.7381 - val_accuracy: 0.5887 - val_loss: 0.6861 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.6320 - loss: 0.6685\n",
      "Epoch 2: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 734ms/step - accuracy: 0.6320 - loss: 0.6685 - val_accuracy: 0.5887 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - accuracy: 0.7206 - loss: 0.5800\n",
      "Epoch 3: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 726ms/step - accuracy: 0.7207 - loss: 0.5797 - val_accuracy: 0.5887 - val_loss: 0.8691 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699ms/step - accuracy: 0.7765 - loss: 0.5028\n",
      "Epoch 4: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 717ms/step - accuracy: 0.7765 - loss: 0.5029 - val_accuracy: 0.5887 - val_loss: 1.5652 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - accuracy: 0.7791 - loss: 0.4973\n",
      "Epoch 5: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 723ms/step - accuracy: 0.7791 - loss: 0.4972 - val_accuracy: 0.5887 - val_loss: 1.8149 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.7985 - loss: 0.4804\n",
      "Epoch 6: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 715ms/step - accuracy: 0.7988 - loss: 0.4798 - val_accuracy: 0.5887 - val_loss: 2.5430 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.8144 - loss: 0.4116\n",
      "Epoch 7: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 709ms/step - accuracy: 0.8146 - loss: 0.4116 - val_accuracy: 0.5887 - val_loss: 2.6728 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8289 - loss: 0.4178\n",
      "Epoch 8: val_loss did not improve from 0.68612\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 711ms/step - accuracy: 0.8288 - loss: 0.4176 - val_accuracy: 0.5887 - val_loss: 2.3085 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.8039 - loss: 0.4352\n",
      "Epoch 9: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 707ms/step - accuracy: 0.8043 - loss: 0.4344 - val_accuracy: 0.5887 - val_loss: 2.2324 - learning_rate: 2.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687ms/step - accuracy: 0.8440 - loss: 0.3818\n",
      "Epoch 10: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 704ms/step - accuracy: 0.8441 - loss: 0.3817 - val_accuracy: 0.5887 - val_loss: 2.3739 - learning_rate: 2.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8630 - loss: 0.3613\n",
      "Epoch 11: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 710ms/step - accuracy: 0.8628 - loss: 0.3614 - val_accuracy: 0.6129 - val_loss: 1.5881 - learning_rate: 2.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8300 - loss: 0.3880\n",
      "Epoch 12: val_loss did not improve from 0.68612\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8301 - loss: 0.3880 - val_accuracy: 0.6935 - val_loss: 0.9916 - learning_rate: 2.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.8495 - loss: 0.3589\n",
      "Epoch 13: val_loss improved from 0.68612 to 0.44082, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 717ms/step - accuracy: 0.8495 - loss: 0.3590 - val_accuracy: 0.7903 - val_loss: 0.4408 - learning_rate: 2.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8419 - loss: 0.3700\n",
      "Epoch 14: val_loss improved from 0.44082 to 0.32290, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 725ms/step - accuracy: 0.8419 - loss: 0.3700 - val_accuracy: 0.8548 - val_loss: 0.3229 - learning_rate: 2.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699ms/step - accuracy: 0.8504 - loss: 0.3593\n",
      "Epoch 15: val_loss improved from 0.32290 to 0.29592, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 728ms/step - accuracy: 0.8503 - loss: 0.3596 - val_accuracy: 0.8952 - val_loss: 0.2959 - learning_rate: 2.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8399 - loss: 0.3593\n",
      "Epoch 16: val_loss improved from 0.29592 to 0.29067, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 724ms/step - accuracy: 0.8401 - loss: 0.3592 - val_accuracy: 0.8952 - val_loss: 0.2907 - learning_rate: 2.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.8388 - loss: 0.3812\n",
      "Epoch 17: val_loss improved from 0.29067 to 0.28200, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 727ms/step - accuracy: 0.8390 - loss: 0.3809 - val_accuracy: 0.8871 - val_loss: 0.2820 - learning_rate: 2.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step - accuracy: 0.8458 - loss: 0.3565\n",
      "Epoch 18: val_loss improved from 0.28200 to 0.27569, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 730ms/step - accuracy: 0.8458 - loss: 0.3568 - val_accuracy: 0.8871 - val_loss: 0.2757 - learning_rate: 2.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8266 - loss: 0.3806\n",
      "Epoch 19: val_loss improved from 0.27569 to 0.27053, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 722ms/step - accuracy: 0.8269 - loss: 0.3805 - val_accuracy: 0.8952 - val_loss: 0.2705 - learning_rate: 2.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8380 - loss: 0.3691\n",
      "Epoch 20: val_loss did not improve from 0.27053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8381 - loss: 0.3691 - val_accuracy: 0.8790 - val_loss: 0.2864 - learning_rate: 2.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8443 - loss: 0.3705\n",
      "Epoch 21: val_loss did not improve from 0.27053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8444 - loss: 0.3705 - val_accuracy: 0.8790 - val_loss: 0.2714 - learning_rate: 2.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8656 - loss: 0.3317\n",
      "Epoch 22: val_loss did not improve from 0.27053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8653 - loss: 0.3320 - val_accuracy: 0.8871 - val_loss: 0.2709 - learning_rate: 2.0000e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8638 - loss: 0.3344\n",
      "Epoch 23: val_loss did not improve from 0.27053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 711ms/step - accuracy: 0.8636 - loss: 0.3347 - val_accuracy: 0.8710 - val_loss: 0.2826 - learning_rate: 2.0000e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8581 - loss: 0.3554\n",
      "Epoch 24: val_loss improved from 0.27053 to 0.26947, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 724ms/step - accuracy: 0.8582 - loss: 0.3551 - val_accuracy: 0.8952 - val_loss: 0.2695 - learning_rate: 2.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8720 - loss: 0.3332\n",
      "Epoch 25: val_loss did not improve from 0.26947\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8718 - loss: 0.3336 - val_accuracy: 0.8952 - val_loss: 0.2725 - learning_rate: 2.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.8524 - loss: 0.3295\n",
      "Epoch 26: val_loss did not improve from 0.26947\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 708ms/step - accuracy: 0.8525 - loss: 0.3298 - val_accuracy: 0.8871 - val_loss: 0.2703 - learning_rate: 2.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8804 - loss: 0.3284\n",
      "Epoch 27: val_loss improved from 0.26947 to 0.26795, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 720ms/step - accuracy: 0.8803 - loss: 0.3283 - val_accuracy: 0.8871 - val_loss: 0.2680 - learning_rate: 2.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8742 - loss: 0.3153\n",
      "Epoch 28: val_loss did not improve from 0.26795\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8741 - loss: 0.3156 - val_accuracy: 0.8790 - val_loss: 0.2834 - learning_rate: 2.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.8766 - loss: 0.3015\n",
      "Epoch 29: val_loss did not improve from 0.26795\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 708ms/step - accuracy: 0.8766 - loss: 0.3018 - val_accuracy: 0.8871 - val_loss: 0.2844 - learning_rate: 2.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8689 - loss: 0.3261\n",
      "Epoch 30: val_loss improved from 0.26795 to 0.26249, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 724ms/step - accuracy: 0.8690 - loss: 0.3262 - val_accuracy: 0.8871 - val_loss: 0.2625 - learning_rate: 2.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step - accuracy: 0.8696 - loss: 0.3057\n",
      "Epoch 31: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 719ms/step - accuracy: 0.8695 - loss: 0.3064 - val_accuracy: 0.8790 - val_loss: 0.2799 - learning_rate: 2.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8503 - loss: 0.3536\n",
      "Epoch 32: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8503 - loss: 0.3536 - val_accuracy: 0.8871 - val_loss: 0.2695 - learning_rate: 2.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8442 - loss: 0.3573\n",
      "Epoch 33: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8444 - loss: 0.3569 - val_accuracy: 0.8952 - val_loss: 0.2705 - learning_rate: 2.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8612 - loss: 0.3265\n",
      "Epoch 34: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8612 - loss: 0.3267 - val_accuracy: 0.8952 - val_loss: 0.2693 - learning_rate: 2.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8772 - loss: 0.3024\n",
      "Epoch 35: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8772 - loss: 0.3023 - val_accuracy: 0.8952 - val_loss: 0.2736 - learning_rate: 2.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8825 - loss: 0.2862\n",
      "Epoch 36: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8823 - loss: 0.2866 - val_accuracy: 0.8952 - val_loss: 0.2753 - learning_rate: 2.0000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.8551 - loss: 0.3426\n",
      "Epoch 37: val_loss did not improve from 0.26249\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 718ms/step - accuracy: 0.8552 - loss: 0.3426 - val_accuracy: 0.8871 - val_loss: 0.2643 - learning_rate: 2.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8835 - loss: 0.3204\n",
      "Epoch 38: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8835 - loss: 0.3205 - val_accuracy: 0.8871 - val_loss: 0.2640 - learning_rate: 4.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8339 - loss: 0.3604\n",
      "Epoch 39: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8342 - loss: 0.3601 - val_accuracy: 0.8871 - val_loss: 0.2653 - learning_rate: 4.0000e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8574 - loss: 0.3303\n",
      "Epoch 40: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8572 - loss: 0.3306 - val_accuracy: 0.8871 - val_loss: 0.2639 - learning_rate: 4.0000e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8721 - loss: 0.3086\n",
      "Epoch 41: val_loss did not improve from 0.26249\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8721 - loss: 0.3085 - val_accuracy: 0.8871 - val_loss: 0.2636 - learning_rate: 4.0000e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8852 - loss: 0.2925\n",
      "Epoch 42: val_loss improved from 0.26249 to 0.26225, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 723ms/step - accuracy: 0.8849 - loss: 0.2928 - val_accuracy: 0.8871 - val_loss: 0.2622 - learning_rate: 4.0000e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - accuracy: 0.8751 - loss: 0.2845\n",
      "Epoch 43: val_loss did not improve from 0.26225\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 716ms/step - accuracy: 0.8751 - loss: 0.2847 - val_accuracy: 0.8871 - val_loss: 0.2655 - learning_rate: 4.0000e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - accuracy: 0.8710 - loss: 0.3393\n",
      "Epoch 44: val_loss did not improve from 0.26225\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 716ms/step - accuracy: 0.8711 - loss: 0.3389 - val_accuracy: 0.8871 - val_loss: 0.2629 - learning_rate: 4.0000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8797 - loss: 0.3052\n",
      "Epoch 45: val_loss did not improve from 0.26225\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8797 - loss: 0.3053 - val_accuracy: 0.8871 - val_loss: 0.2647 - learning_rate: 4.0000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8849 - loss: 0.3019\n",
      "Epoch 46: val_loss did not improve from 0.26225\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8847 - loss: 0.3022 - val_accuracy: 0.8871 - val_loss: 0.2637 - learning_rate: 4.0000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8461 - loss: 0.3450\n",
      "Epoch 47: val_loss did not improve from 0.26225\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8464 - loss: 0.3446 - val_accuracy: 0.8871 - val_loss: 0.2639 - learning_rate: 4.0000e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8704 - loss: 0.3461\n",
      "Epoch 48: val_loss improved from 0.26225 to 0.26130, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 725ms/step - accuracy: 0.8705 - loss: 0.3456 - val_accuracy: 0.8871 - val_loss: 0.2613 - learning_rate: 4.0000e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.8767 - loss: 0.3118\n",
      "Epoch 49: val_loss did not improve from 0.26130\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 715ms/step - accuracy: 0.8767 - loss: 0.3119 - val_accuracy: 0.8871 - val_loss: 0.2627 - learning_rate: 4.0000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - accuracy: 0.8793 - loss: 0.3129\n",
      "Epoch 50: val_loss did not improve from 0.26130\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 716ms/step - accuracy: 0.8793 - loss: 0.3126 - val_accuracy: 0.8871 - val_loss: 0.2638 - learning_rate: 4.0000e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.8708 - loss: 0.3618\n",
      "Epoch 51: val_loss did not improve from 0.26130\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8709 - loss: 0.3612 - val_accuracy: 0.8871 - val_loss: 0.2617 - learning_rate: 4.0000e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8896 - loss: 0.2876\n",
      "Epoch 52: val_loss improved from 0.26130 to 0.26057, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 723ms/step - accuracy: 0.8895 - loss: 0.2879 - val_accuracy: 0.8871 - val_loss: 0.2606 - learning_rate: 4.0000e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.8888 - loss: 0.2921\n",
      "Epoch 53: val_loss improved from 0.26057 to 0.25825, saving model to results\\EfficientNetB0_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 720ms/step - accuracy: 0.8887 - loss: 0.2923 - val_accuracy: 0.8952 - val_loss: 0.2582 - learning_rate: 4.0000e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.8607 - loss: 0.3696\n",
      "Epoch 54: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 711ms/step - accuracy: 0.8606 - loss: 0.3693 - val_accuracy: 0.8952 - val_loss: 0.2623 - learning_rate: 4.0000e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8691 - loss: 0.3170\n",
      "Epoch 55: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 710ms/step - accuracy: 0.8691 - loss: 0.3170 - val_accuracy: 0.8871 - val_loss: 0.2635 - learning_rate: 4.0000e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.8720 - loss: 0.3340\n",
      "Epoch 56: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 715ms/step - accuracy: 0.8720 - loss: 0.3337 - val_accuracy: 0.8871 - val_loss: 0.2644 - learning_rate: 4.0000e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8645 - loss: 0.3582\n",
      "Epoch 57: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 710ms/step - accuracy: 0.8646 - loss: 0.3576 - val_accuracy: 0.8871 - val_loss: 0.2634 - learning_rate: 4.0000e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.8812 - loss: 0.3012\n",
      "Epoch 58: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 711ms/step - accuracy: 0.8813 - loss: 0.3011 - val_accuracy: 0.8871 - val_loss: 0.2631 - learning_rate: 4.0000e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.9004 - loss: 0.2728\n",
      "Epoch 59: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.9002 - loss: 0.2731 - val_accuracy: 0.8871 - val_loss: 0.2640 - learning_rate: 4.0000e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8754 - loss: 0.3312\n",
      "Epoch 60: val_loss did not improve from 0.25825\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8756 - loss: 0.3309 - val_accuracy: 0.8871 - val_loss: 0.2645 - learning_rate: 4.0000e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8666 - loss: 0.3259\n",
      "Epoch 61: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8667 - loss: 0.3256 - val_accuracy: 0.8871 - val_loss: 0.2636 - learning_rate: 8.0000e-07\n",
      "Epoch 62/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.9063 - loss: 0.2566\n",
      "Epoch 62: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 715ms/step - accuracy: 0.9060 - loss: 0.2574 - val_accuracy: 0.8871 - val_loss: 0.2625 - learning_rate: 8.0000e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.8554 - loss: 0.3287\n",
      "Epoch 63: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 714ms/step - accuracy: 0.8558 - loss: 0.3281 - val_accuracy: 0.8871 - val_loss: 0.2626 - learning_rate: 8.0000e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8843 - loss: 0.3008\n",
      "Epoch 64: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8841 - loss: 0.3009 - val_accuracy: 0.8871 - val_loss: 0.2618 - learning_rate: 8.0000e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.8751 - loss: 0.3426\n",
      "Epoch 65: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 711ms/step - accuracy: 0.8750 - loss: 0.3426 - val_accuracy: 0.8871 - val_loss: 0.2616 - learning_rate: 8.0000e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.8840 - loss: 0.3007\n",
      "Epoch 66: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 710ms/step - accuracy: 0.8839 - loss: 0.3007 - val_accuracy: 0.8871 - val_loss: 0.2634 - learning_rate: 8.0000e-07\n",
      "Epoch 67/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8814 - loss: 0.2851\n",
      "Epoch 67: val_loss did not improve from 0.25825\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 710ms/step - accuracy: 0.8812 - loss: 0.2855 - val_accuracy: 0.8871 - val_loss: 0.2636 - learning_rate: 8.0000e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8528 - loss: 0.3510\n",
      "Epoch 68: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 713ms/step - accuracy: 0.8531 - loss: 0.3504 - val_accuracy: 0.8871 - val_loss: 0.2637 - learning_rate: 1.6000e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.8754 - loss: 0.3040\n",
      "Epoch 69: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 715ms/step - accuracy: 0.8754 - loss: 0.3039 - val_accuracy: 0.8871 - val_loss: 0.2638 - learning_rate: 1.6000e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8774 - loss: 0.3163\n",
      "Epoch 70: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 710ms/step - accuracy: 0.8774 - loss: 0.3164 - val_accuracy: 0.8871 - val_loss: 0.2640 - learning_rate: 1.6000e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.8513 - loss: 0.3446\n",
      "Epoch 71: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 712ms/step - accuracy: 0.8515 - loss: 0.3441 - val_accuracy: 0.8871 - val_loss: 0.2640 - learning_rate: 1.6000e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.8679 - loss: 0.3256\n",
      "Epoch 72: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 711ms/step - accuracy: 0.8678 - loss: 0.3255 - val_accuracy: 0.8871 - val_loss: 0.2649 - learning_rate: 1.6000e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.8724 - loss: 0.3124\n",
      "Epoch 73: val_loss did not improve from 0.25825\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 710ms/step - accuracy: 0.8724 - loss: 0.3124 - val_accuracy: 0.8871 - val_loss: 0.2655 - learning_rate: 1.6000e-07\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- EfficientNetB0_from_scratch_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 455ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.86      0.86      0.86       103\n",
      "Shoot and Fruit Borer       0.90      0.90      0.90       145\n",
      "\n",
      "             accuracy                           0.89       248\n",
      "            macro avg       0.88      0.88      0.88       248\n",
      "         weighted avg       0.89      0.89      0.89       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for EfficientNetB0_from_scratch_bs16 is complete. Total time: 00:56:22 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"EfficientNetB0\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554c83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: EfficientNetB0_transfer_learning_bs16 ---\n",
      "Mode: transfer_learning, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 235ms/step - accuracy: 0.4756 - loss: 0.7283 - val_accuracy: 0.4113 - val_loss: 0.6957\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.4757 - loss: 0.7212 - val_accuracy: 0.5887 - val_loss: 0.6886\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.4875 - loss: 0.7132 - val_accuracy: 0.4113 - val_loss: 0.6984\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.5233 - loss: 0.7050 - val_accuracy: 0.4113 - val_loss: 0.6971\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.5130 - loss: 0.7104 - val_accuracy: 0.5887 - val_loss: 0.6924\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.4559 - loss: 0.7274 - val_accuracy: 0.5887 - val_loss: 0.6876\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step - accuracy: 0.4765 - loss: 0.7252 - val_accuracy: 0.4113 - val_loss: 0.6938\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.5048 - loss: 0.7146 - val_accuracy: 0.5887 - val_loss: 0.6896\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.5057 - loss: 0.7141 - val_accuracy: 0.4113 - val_loss: 0.6956\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.4910 - loss: 0.7123 - val_accuracy: 0.5887 - val_loss: 0.6931\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.5364 - loss: 0.7003 - val_accuracy: 0.5887 - val_loss: 0.6901\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.4826 - loss: 0.7095 - val_accuracy: 0.4113 - val_loss: 0.6956\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 190ms/step - accuracy: 0.5136 - loss: 0.7074 - val_accuracy: 0.5887 - val_loss: 0.6872\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.4893 - loss: 0.7191 - val_accuracy: 0.4113 - val_loss: 0.7002\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.4931 - loss: 0.7129 - val_accuracy: 0.5887 - val_loss: 0.6901\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step - accuracy: 0.4989 - loss: 0.7069 - val_accuracy: 0.4113 - val_loss: 0.6950\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.4851 - loss: 0.7098 - val_accuracy: 0.4113 - val_loss: 0.6962\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.4971 - loss: 0.7037 - val_accuracy: 0.4113 - val_loss: 0.6942\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.4918 - loss: 0.7123 - val_accuracy: 0.5887 - val_loss: 0.6900\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 186ms/step - accuracy: 0.4997 - loss: 0.7041 - val_accuracy: 0.5887 - val_loss: 0.6899\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 186ms/step - accuracy: 0.5272 - loss: 0.7015 - val_accuracy: 0.4113 - val_loss: 0.7020\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.4938 - loss: 0.7101 - val_accuracy: 0.4113 - val_loss: 0.6981\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.4883 - loss: 0.7097 - val_accuracy: 0.5887 - val_loss: 0.6868\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.5119 - loss: 0.7101 - val_accuracy: 0.5887 - val_loss: 0.6881\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.4640 - loss: 0.7178 - val_accuracy: 0.5887 - val_loss: 0.6895\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.4797 - loss: 0.7094 - val_accuracy: 0.5887 - val_loss: 0.6897\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 190ms/step - accuracy: 0.4558 - loss: 0.7185 - val_accuracy: 0.4113 - val_loss: 0.6966\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 190ms/step - accuracy: 0.4758 - loss: 0.7109 - val_accuracy: 0.4113 - val_loss: 0.6974\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.5214 - loss: 0.6958 - val_accuracy: 0.5887 - val_loss: 0.6847\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.5155 - loss: 0.6998 - val_accuracy: 0.4113 - val_loss: 0.6935\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.5257 - loss: 0.6938 - val_accuracy: 0.5887 - val_loss: 0.6866\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.4932 - loss: 0.7058 - val_accuracy: 0.4113 - val_loss: 0.6950\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.5229 - loss: 0.6953 - val_accuracy: 0.5887 - val_loss: 0.6895\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.4858 - loss: 0.7117 - val_accuracy: 0.4113 - val_loss: 0.6947\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.4824 - loss: 0.7037 - val_accuracy: 0.4113 - val_loss: 0.7020\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.4976 - loss: 0.7031 - val_accuracy: 0.5887 - val_loss: 0.6888\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.5122 - loss: 0.6979 - val_accuracy: 0.5887 - val_loss: 0.6884\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 186ms/step - accuracy: 0.5226 - loss: 0.6959 - val_accuracy: 0.5887 - val_loss: 0.6918\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.4875 - loss: 0.7071 - val_accuracy: 0.4113 - val_loss: 0.6949\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.4962 - loss: 0.7055 - val_accuracy: 0.5887 - val_loss: 0.6890\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.5066 - loss: 0.7011 - val_accuracy: 0.4113 - val_loss: 0.6963\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.5101 - loss: 0.6970 - val_accuracy: 0.5887 - val_loss: 0.6884\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.4763 - loss: 0.7210 - val_accuracy: 0.4113 - val_loss: 0.6972\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 184ms/step - accuracy: 0.5257 - loss: 0.6985 - val_accuracy: 0.4113 - val_loss: 0.6970\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- EfficientNetB0_transfer_learning_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 460ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.00      0.00      0.00       103\n",
      "Shoot and Fruit Borer       0.58      1.00      0.74       145\n",
      "\n",
      "             accuracy                           0.58       248\n",
      "            macro avg       0.29      0.50      0.37       248\n",
      "         weighted avg       0.34      0.58      0.43       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment for EfficientNetB0_transfer_learning_bs16 is complete. Total time: 00:08:58 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"EfficientNetB0\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5af6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: EfficientNetB0_fine_tune_bs16 ---\n",
      "Mode: fine_tune, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 559ms/step - accuracy: 0.5173 - loss: 0.7050 - val_accuracy: 0.4113 - val_loss: 0.6970\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 516ms/step - accuracy: 0.4982 - loss: 0.7113 - val_accuracy: 0.4113 - val_loss: 0.6973\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 516ms/step - accuracy: 0.5093 - loss: 0.7061 - val_accuracy: 0.3952 - val_loss: 0.6932\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 520ms/step - accuracy: 0.4843 - loss: 0.7246 - val_accuracy: 0.4113 - val_loss: 0.6998\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 521ms/step - accuracy: 0.4964 - loss: 0.7208 - val_accuracy: 0.5887 - val_loss: 0.6823\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 521ms/step - accuracy: 0.5094 - loss: 0.7129 - val_accuracy: 0.4113 - val_loss: 0.6952\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 529ms/step - accuracy: 0.5039 - loss: 0.7057 - val_accuracy: 0.5887 - val_loss: 0.6911\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 534ms/step - accuracy: 0.4851 - loss: 0.7055 - val_accuracy: 0.4113 - val_loss: 0.6934\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 542ms/step - accuracy: 0.4728 - loss: 0.7162 - val_accuracy: 0.4113 - val_loss: 0.6993\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 539ms/step - accuracy: 0.5019 - loss: 0.7176 - val_accuracy: 0.4113 - val_loss: 0.6965\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 542ms/step - accuracy: 0.5247 - loss: 0.7019 - val_accuracy: 0.5887 - val_loss: 0.6875\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 544ms/step - accuracy: 0.4785 - loss: 0.7090 - val_accuracy: 0.4113 - val_loss: 0.6953\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 551ms/step - accuracy: 0.4934 - loss: 0.7040 - val_accuracy: 0.4113 - val_loss: 0.6957\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 554ms/step - accuracy: 0.5032 - loss: 0.7077 - val_accuracy: 0.4113 - val_loss: 0.6976\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 560ms/step - accuracy: 0.4869 - loss: 0.7094 - val_accuracy: 0.5887 - val_loss: 0.6872\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 559ms/step - accuracy: 0.5182 - loss: 0.6965 - val_accuracy: 0.5887 - val_loss: 0.6903\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 558ms/step - accuracy: 0.5193 - loss: 0.6941 - val_accuracy: 0.5887 - val_loss: 0.6902\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 558ms/step - accuracy: 0.5178 - loss: 0.7043 - val_accuracy: 0.4113 - val_loss: 0.6952\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 564ms/step - accuracy: 0.5124 - loss: 0.7054 - val_accuracy: 0.5887 - val_loss: 0.6878\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 563ms/step - accuracy: 0.4835 - loss: 0.7132 - val_accuracy: 0.5887 - val_loss: 0.6834\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- EfficientNetB0_fine_tune_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 806ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.00      0.00      0.00       103\n",
      "Shoot and Fruit Borer       0.58      1.00      0.74       145\n",
      "\n",
      "             accuracy                           0.58       248\n",
      "            macro avg       0.29      0.50      0.37       248\n",
      "         weighted avg       0.34      0.58      0.43       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment for EfficientNetB0_fine_tune_bs16 is complete. Total time: 00:11:46 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"EfficientNetB0\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ed7688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: EfficientNetB0_full_monty_bs16 ---\n",
      "Mode: full_monty, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.4900 - loss: 0.7202\n",
      "Epoch 1: val_loss improved from inf to 0.69053, saving model to results\\EfficientNetB0_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - accuracy: 0.4900 - loss: 0.7202 - val_accuracy: 0.5887 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.4969 - loss: 0.7101\n",
      "Epoch 2: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.4969 - loss: 0.7101 - val_accuracy: 0.4113 - val_loss: 0.6986 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.4559 - loss: 0.7303\n",
      "Epoch 3: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.4560 - loss: 0.7303 - val_accuracy: 0.3629 - val_loss: 0.6934 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5131 - loss: 0.7096\n",
      "Epoch 4: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.5131 - loss: 0.7096 - val_accuracy: 0.4113 - val_loss: 0.6948 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4908 - loss: 0.7197\n",
      "Epoch 5: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - accuracy: 0.4910 - loss: 0.7197 - val_accuracy: 0.4516 - val_loss: 0.6932 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4669 - loss: 0.7202\n",
      "Epoch 6: val_loss did not improve from 0.69053\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.4672 - loss: 0.7202 - val_accuracy: 0.4113 - val_loss: 0.7076 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5036 - loss: 0.7092\n",
      "Epoch 7: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.5035 - loss: 0.7092 - val_accuracy: 0.4113 - val_loss: 0.7028 - learning_rate: 2.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4978 - loss: 0.7082\n",
      "Epoch 8: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.4978 - loss: 0.7083 - val_accuracy: 0.4113 - val_loss: 0.6975 - learning_rate: 2.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4985 - loss: 0.7071\n",
      "Epoch 9: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.4985 - loss: 0.7071 - val_accuracy: 0.4113 - val_loss: 0.6946 - learning_rate: 2.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5155 - loss: 0.7073\n",
      "Epoch 10: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.5153 - loss: 0.7073 - val_accuracy: 0.4113 - val_loss: 0.6940 - learning_rate: 2.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5218 - loss: 0.6975\n",
      "Epoch 11: val_loss did not improve from 0.69053\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.5214 - loss: 0.6976 - val_accuracy: 0.4113 - val_loss: 0.6954 - learning_rate: 2.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5195 - loss: 0.7011\n",
      "Epoch 12: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.5197 - loss: 0.7011 - val_accuracy: 0.4113 - val_loss: 0.6947 - learning_rate: 4.0000e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4757 - loss: 0.7206\n",
      "Epoch 13: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.4758 - loss: 0.7206 - val_accuracy: 0.4113 - val_loss: 0.6946 - learning_rate: 4.0000e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4796 - loss: 0.7119\n",
      "Epoch 14: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.4797 - loss: 0.7119 - val_accuracy: 0.4113 - val_loss: 0.6946 - learning_rate: 4.0000e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4749 - loss: 0.7090\n",
      "Epoch 15: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.4753 - loss: 0.7090 - val_accuracy: 0.4113 - val_loss: 0.6946 - learning_rate: 4.0000e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.4844 - loss: 0.7187\n",
      "Epoch 16: val_loss did not improve from 0.69053\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.4845 - loss: 0.7186 - val_accuracy: 0.4113 - val_loss: 0.6946 - learning_rate: 4.0000e-06\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 17/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.5567 - loss: 0.6978\n",
      "Epoch 17: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 330ms/step - accuracy: 0.5566 - loss: 0.6979 - val_accuracy: 0.4113 - val_loss: 0.7080 - learning_rate: 1.0000e-05\n",
      "Epoch 18/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.5886 - loss: 0.6575\n",
      "Epoch 18: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 290ms/step - accuracy: 0.5887 - loss: 0.6576 - val_accuracy: 0.4113 - val_loss: 0.7296 - learning_rate: 1.0000e-05\n",
      "Epoch 19/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.5960 - loss: 0.6584\n",
      "Epoch 19: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.5959 - loss: 0.6585 - val_accuracy: 0.4113 - val_loss: 0.7195 - learning_rate: 1.0000e-05\n",
      "Epoch 20/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.6044 - loss: 0.6571\n",
      "Epoch 20: val_loss did not improve from 0.69053\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 289ms/step - accuracy: 0.6047 - loss: 0.6569 - val_accuracy: 0.4113 - val_loss: 0.6949 - learning_rate: 1.0000e-05\n",
      "Epoch 21/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6370 - loss: 0.6224\n",
      "Epoch 21: val_loss improved from 0.69053 to 0.66736, saving model to results\\EfficientNetB0_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - accuracy: 0.6372 - loss: 0.6222 - val_accuracy: 0.6532 - val_loss: 0.6674 - learning_rate: 1.0000e-05\n",
      "Epoch 22/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6443 - loss: 0.6140\n",
      "Epoch 22: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.6445 - loss: 0.6139 - val_accuracy: 0.6290 - val_loss: 0.6698 - learning_rate: 1.0000e-05\n",
      "Epoch 23/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.6298 - loss: 0.6033\n",
      "Epoch 23: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.6300 - loss: 0.6032 - val_accuracy: 0.4274 - val_loss: 0.7046 - learning_rate: 1.0000e-05\n",
      "Epoch 24/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6653 - loss: 0.5976\n",
      "Epoch 24: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.6655 - loss: 0.5975 - val_accuracy: 0.4677 - val_loss: 0.7006 - learning_rate: 1.0000e-05\n",
      "Epoch 25/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6612 - loss: 0.5661\n",
      "Epoch 25: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.6611 - loss: 0.5664 - val_accuracy: 0.4274 - val_loss: 0.7630 - learning_rate: 1.0000e-05\n",
      "Epoch 26/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.6608 - loss: 0.5693\n",
      "Epoch 26: val_loss did not improve from 0.66736\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.6611 - loss: 0.5693 - val_accuracy: 0.4274 - val_loss: 0.8020 - learning_rate: 1.0000e-05\n",
      "Epoch 27/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6515 - loss: 0.5852\n",
      "Epoch 27: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.6516 - loss: 0.5851 - val_accuracy: 0.4274 - val_loss: 0.7808 - learning_rate: 2.0000e-06\n",
      "Epoch 28/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6975 - loss: 0.5640\n",
      "Epoch 28: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.6974 - loss: 0.5640 - val_accuracy: 0.5403 - val_loss: 0.6981 - learning_rate: 2.0000e-06\n",
      "Epoch 29/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7134 - loss: 0.5494\n",
      "Epoch 29: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.7132 - loss: 0.5496 - val_accuracy: 0.5403 - val_loss: 0.7139 - learning_rate: 2.0000e-06\n",
      "Epoch 30/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6765 - loss: 0.5718\n",
      "Epoch 30: val_loss did not improve from 0.66736\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.6769 - loss: 0.5715 - val_accuracy: 0.5403 - val_loss: 0.7095 - learning_rate: 2.0000e-06\n",
      "Epoch 31/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6486 - loss: 0.6027\n",
      "Epoch 31: val_loss did not improve from 0.66736\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.6489 - loss: 0.6026 - val_accuracy: 0.5887 - val_loss: 0.6751 - learning_rate: 2.0000e-06\n",
      "Epoch 32/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6712 - loss: 0.6011\n",
      "Epoch 32: val_loss improved from 0.66736 to 0.65108, saving model to results\\EfficientNetB0_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - accuracy: 0.6714 - loss: 0.6008 - val_accuracy: 0.5968 - val_loss: 0.6511 - learning_rate: 4.0000e-07\n",
      "Epoch 33/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.7024 - loss: 0.5553\n",
      "Epoch 33: val_loss improved from 0.65108 to 0.64939, saving model to results\\EfficientNetB0_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - accuracy: 0.7025 - loss: 0.5552 - val_accuracy: 0.6048 - val_loss: 0.6494 - learning_rate: 4.0000e-07\n",
      "Epoch 34/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6944 - loss: 0.5448\n",
      "Epoch 34: val_loss improved from 0.64939 to 0.64391, saving model to results\\EfficientNetB0_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 296ms/step - accuracy: 0.6944 - loss: 0.5449 - val_accuracy: 0.6129 - val_loss: 0.6439 - learning_rate: 4.0000e-07\n",
      "Epoch 35/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6864 - loss: 0.5675\n",
      "Epoch 35: val_loss did not improve from 0.64391\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.6863 - loss: 0.5675 - val_accuracy: 0.6048 - val_loss: 0.6477 - learning_rate: 4.0000e-07\n",
      "Epoch 36/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.6897 - loss: 0.5623\n",
      "Epoch 36: val_loss did not improve from 0.64391\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 0.6899 - loss: 0.5622 - val_accuracy: 0.5887 - val_loss: 0.6638 - learning_rate: 4.0000e-07\n",
      "Epoch 37/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.6902 - loss: 0.5732\n",
      "Epoch 37: val_loss did not improve from 0.64391\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.6901 - loss: 0.5732 - val_accuracy: 0.5887 - val_loss: 0.6677 - learning_rate: 4.0000e-07\n",
      "Epoch 38/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6840 - loss: 0.5618\n",
      "Epoch 38: val_loss did not improve from 0.64391\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.6840 - loss: 0.5618 - val_accuracy: 0.5968 - val_loss: 0.6589 - learning_rate: 4.0000e-07\n",
      "Epoch 39/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.7115 - loss: 0.5518\n",
      "Epoch 39: val_loss did not improve from 0.64391\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 0.7116 - loss: 0.5517 - val_accuracy: 0.6129 - val_loss: 0.6449 - learning_rate: 4.0000e-07\n",
      "Epoch 40/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.7331 - loss: 0.5203\n",
      "Epoch 40: val_loss improved from 0.64391 to 0.63372, saving model to results\\EfficientNetB0_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 0.7328 - loss: 0.5206 - val_accuracy: 0.6129 - val_loss: 0.6337 - learning_rate: 8.0000e-08\n",
      "Epoch 41/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.6881 - loss: 0.5433\n",
      "Epoch 41: val_loss did not improve from 0.63372\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 0.6881 - loss: 0.5434 - val_accuracy: 0.6048 - val_loss: 0.6502 - learning_rate: 8.0000e-08\n",
      "Epoch 42/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.7258 - loss: 0.5422\n",
      "Epoch 42: val_loss did not improve from 0.63372\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 0.7256 - loss: 0.5423 - val_accuracy: 0.6129 - val_loss: 0.6471 - learning_rate: 8.0000e-08\n",
      "Epoch 43/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6948 - loss: 0.5726\n",
      "Epoch 43: val_loss did not improve from 0.63372\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.6947 - loss: 0.5724 - val_accuracy: 0.6129 - val_loss: 0.6421 - learning_rate: 8.0000e-08\n",
      "Epoch 44/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6874 - loss: 0.5476\n",
      "Epoch 44: val_loss improved from 0.63372 to 0.63295, saving model to results\\EfficientNetB0_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 297ms/step - accuracy: 0.6872 - loss: 0.5478 - val_accuracy: 0.6129 - val_loss: 0.6329 - learning_rate: 8.0000e-08\n",
      "Epoch 45/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7145 - loss: 0.5422\n",
      "Epoch 45: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.7145 - loss: 0.5421 - val_accuracy: 0.6129 - val_loss: 0.6470 - learning_rate: 8.0000e-08\n",
      "Epoch 46/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7012 - loss: 0.5382\n",
      "Epoch 46: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.7011 - loss: 0.5385 - val_accuracy: 0.6129 - val_loss: 0.6486 - learning_rate: 8.0000e-08\n",
      "Epoch 47/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6882 - loss: 0.5550\n",
      "Epoch 47: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.6883 - loss: 0.5550 - val_accuracy: 0.5968 - val_loss: 0.6554 - learning_rate: 8.0000e-08\n",
      "Epoch 48/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6867 - loss: 0.5784\n",
      "Epoch 48: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.6871 - loss: 0.5780 - val_accuracy: 0.6129 - val_loss: 0.6475 - learning_rate: 8.0000e-08\n",
      "Epoch 49/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.6908 - loss: 0.5579\n",
      "Epoch 49: val_loss did not improve from 0.63295\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.5999999902760466e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.6908 - loss: 0.5578 - val_accuracy: 0.6129 - val_loss: 0.6454 - learning_rate: 8.0000e-08\n",
      "Epoch 50/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7118 - loss: 0.5509\n",
      "Epoch 50: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.7117 - loss: 0.5509 - val_accuracy: 0.5968 - val_loss: 0.6507 - learning_rate: 1.6000e-08\n",
      "Epoch 51/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.7240 - loss: 0.5231\n",
      "Epoch 51: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.7240 - loss: 0.5232 - val_accuracy: 0.6048 - val_loss: 0.6483 - learning_rate: 1.6000e-08\n",
      "Epoch 52/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7129 - loss: 0.5385\n",
      "Epoch 52: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.7127 - loss: 0.5387 - val_accuracy: 0.5968 - val_loss: 0.6534 - learning_rate: 1.6000e-08\n",
      "Epoch 53/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7094 - loss: 0.5282\n",
      "Epoch 53: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.7096 - loss: 0.5283 - val_accuracy: 0.5968 - val_loss: 0.6587 - learning_rate: 1.6000e-08\n",
      "Epoch 54/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7216 - loss: 0.5236\n",
      "Epoch 54: val_loss did not improve from 0.63295\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.1999999094978194e-09.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.7213 - loss: 0.5240 - val_accuracy: 0.5887 - val_loss: 0.6553 - learning_rate: 1.6000e-08\n",
      "Epoch 55/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7054 - loss: 0.5360\n",
      "Epoch 55: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.7052 - loss: 0.5361 - val_accuracy: 0.5887 - val_loss: 0.6573 - learning_rate: 3.2000e-09\n",
      "Epoch 56/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.6689 - loss: 0.5724\n",
      "Epoch 56: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.6690 - loss: 0.5724 - val_accuracy: 0.6129 - val_loss: 0.6488 - learning_rate: 3.2000e-09\n",
      "Epoch 57/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7029 - loss: 0.5553\n",
      "Epoch 57: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - accuracy: 0.7029 - loss: 0.5554 - val_accuracy: 0.6129 - val_loss: 0.6448 - learning_rate: 3.2000e-09\n",
      "Epoch 58/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.7107 - loss: 0.5414\n",
      "Epoch 58: val_loss did not improve from 0.63295\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.7106 - loss: 0.5415 - val_accuracy: 0.6048 - val_loss: 0.6534 - learning_rate: 3.2000e-09\n",
      "Epoch 59/66\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.6801 - loss: 0.5585\n",
      "Epoch 59: val_loss did not improve from 0.63295\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.399999641359955e-10.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.6804 - loss: 0.5583 - val_accuracy: 0.5887 - val_loss: 0.6576 - learning_rate: 3.2000e-09\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- EfficientNetB0_full_monty_bs16 Final Test Set Evaluation ---\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B68D4E5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 412ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.54      0.98      0.69       103\n",
      "Shoot and Fruit Borer       0.97      0.40      0.57       145\n",
      "\n",
      "             accuracy                           0.64       248\n",
      "            macro avg       0.75      0.69      0.63       248\n",
      "         weighted avg       0.79      0.64      0.62       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for EfficientNetB0_full_monty_bs16 is complete. Total time: 00:16:13 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"EfficientNetB0\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9010c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: EfficientNetB7_from_scratch_bs16 ---\n",
      "Mode: from_scratch, Batch Size: 16, LR: 0.0001, Input: 600x600\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_600x600_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132s/step - accuracy: 0.5690 - loss: 0.7128  \n",
      "Epoch 1: val_loss improved from inf to 0.69374, saving model to results\\EfficientNetB7_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8689s\u001b[0m 134s/step - accuracy: 0.5693 - loss: 0.7131 - val_accuracy: 0.4113 - val_loss: 0.6937 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134s/step - accuracy: 0.5878 - loss: 0.6914  \n",
      "Epoch 2: val_loss did not improve from 0.69374\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8675s\u001b[0m 135s/step - accuracy: 0.5877 - loss: 0.6913 - val_accuracy: 0.5887 - val_loss: 0.7652 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132s/step - accuracy: 0.6627 - loss: 0.6481  \n",
      "Epoch 3: val_loss did not improve from 0.69374\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8515s\u001b[0m 133s/step - accuracy: 0.6628 - loss: 0.6481 - val_accuracy: 0.4113 - val_loss: 0.6944 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132s/step - accuracy: 0.6489 - loss: 0.6598  \n",
      "Epoch 4: val_loss did not improve from 0.69374\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8545s\u001b[0m 133s/step - accuracy: 0.6492 - loss: 0.6593 - val_accuracy: 0.5887 - val_loss: 2.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131s/step - accuracy: 0.7092 - loss: 0.5742  \n",
      "Epoch 5: val_loss did not improve from 0.69374\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8479s\u001b[0m 132s/step - accuracy: 0.7095 - loss: 0.5740 - val_accuracy: 0.5887 - val_loss: 3.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132s/step - accuracy: 0.7989 - loss: 0.4853  \n",
      "Epoch 6: val_loss did not improve from 0.69374\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8509s\u001b[0m 133s/step - accuracy: 0.7985 - loss: 0.4858 - val_accuracy: 0.5887 - val_loss: 1.5172 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136s/step - accuracy: 0.7473 - loss: 0.5131  \n",
      "Epoch 7: val_loss did not improve from 0.69374\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8814s\u001b[0m 137s/step - accuracy: 0.7472 - loss: 0.5132 - val_accuracy: 0.5887 - val_loss: 1.6776 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m29/64\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:16:37\u001b[0m 131s/step - accuracy: 0.7611 - loss: 0.5269"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"EfficientNetB7\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf587b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"EfficientNetB7\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff82ad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionV3_from_scratch_bs8 ---\n",
      "Mode: from_scratch, Batch Size: 8, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.5876 - loss: 0.7744\n",
      "Epoch 1: val_loss improved from inf to 0.98280, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 620ms/step - accuracy: 0.5885 - loss: 0.7733 - val_accuracy: 0.4113 - val_loss: 0.9828 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.7727 - loss: 0.5022\n",
      "Epoch 2: val_loss did not improve from 0.98280\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 558ms/step - accuracy: 0.7727 - loss: 0.5023 - val_accuracy: 0.5887 - val_loss: 1.0540 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - accuracy: 0.8166 - loss: 0.4423\n",
      "Epoch 3: val_loss improved from 0.98280 to 0.80066, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 574ms/step - accuracy: 0.8164 - loss: 0.4428 - val_accuracy: 0.6129 - val_loss: 0.8007 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.7608 - loss: 0.5239\n",
      "Epoch 4: val_loss improved from 0.80066 to 0.39785, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 573ms/step - accuracy: 0.7609 - loss: 0.5239 - val_accuracy: 0.8306 - val_loss: 0.3979 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.8554 - loss: 0.3638\n",
      "Epoch 5: val_loss improved from 0.39785 to 0.35581, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 569ms/step - accuracy: 0.8552 - loss: 0.3641 - val_accuracy: 0.8468 - val_loss: 0.3558 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.8505 - loss: 0.3553\n",
      "Epoch 6: val_loss did not improve from 0.35581\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 555ms/step - accuracy: 0.8505 - loss: 0.3555 - val_accuracy: 0.7984 - val_loss: 0.5985 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.8655 - loss: 0.3368\n",
      "Epoch 7: val_loss improved from 0.35581 to 0.22545, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 568ms/step - accuracy: 0.8654 - loss: 0.3370 - val_accuracy: 0.9194 - val_loss: 0.2254 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.8714 - loss: 0.3250\n",
      "Epoch 8: val_loss improved from 0.22545 to 0.22181, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 568ms/step - accuracy: 0.8714 - loss: 0.3251 - val_accuracy: 0.8952 - val_loss: 0.2218 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.8670 - loss: 0.3279\n",
      "Epoch 9: val_loss did not improve from 0.22181\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 557ms/step - accuracy: 0.8670 - loss: 0.3278 - val_accuracy: 0.8306 - val_loss: 0.5434 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.8701 - loss: 0.2990\n",
      "Epoch 10: val_loss did not improve from 0.22181\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 558ms/step - accuracy: 0.8700 - loss: 0.2993 - val_accuracy: 0.8952 - val_loss: 0.2981 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.8392 - loss: 0.3573\n",
      "Epoch 11: val_loss did not improve from 0.22181\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 557ms/step - accuracy: 0.8393 - loss: 0.3572 - val_accuracy: 0.8871 - val_loss: 0.6190 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.8963 - loss: 0.2664\n",
      "Epoch 12: val_loss did not improve from 0.22181\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 556ms/step - accuracy: 0.8963 - loss: 0.2665 - val_accuracy: 0.9032 - val_loss: 0.2292 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.8896 - loss: 0.2770\n",
      "Epoch 13: val_loss improved from 0.22181 to 0.20400, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 571ms/step - accuracy: 0.8895 - loss: 0.2771 - val_accuracy: 0.9274 - val_loss: 0.2040 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.8770 - loss: 0.2857\n",
      "Epoch 14: val_loss did not improve from 0.20400\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 557ms/step - accuracy: 0.8770 - loss: 0.2859 - val_accuracy: 0.9274 - val_loss: 0.2159 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.8860 - loss: 0.3025\n",
      "Epoch 15: val_loss improved from 0.20400 to 0.17097, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 573ms/step - accuracy: 0.8860 - loss: 0.3024 - val_accuracy: 0.9435 - val_loss: 0.1710 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9048 - loss: 0.2607\n",
      "Epoch 16: val_loss improved from 0.17097 to 0.12862, saving model to results\\InceptionV3_from_scratch_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 593ms/step - accuracy: 0.9048 - loss: 0.2608 - val_accuracy: 0.9597 - val_loss: 0.1286 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.8790 - loss: 0.3102\n",
      "Epoch 17: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 606ms/step - accuracy: 0.8790 - loss: 0.3102 - val_accuracy: 0.8871 - val_loss: 0.3155 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.8963 - loss: 0.2662\n",
      "Epoch 18: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 578ms/step - accuracy: 0.8963 - loss: 0.2662 - val_accuracy: 0.9194 - val_loss: 0.2750 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.9122 - loss: 0.2243\n",
      "Epoch 19: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 556ms/step - accuracy: 0.9123 - loss: 0.2242 - val_accuracy: 0.9032 - val_loss: 0.2701 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.9178 - loss: 0.2124\n",
      "Epoch 20: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 553ms/step - accuracy: 0.9177 - loss: 0.2127 - val_accuracy: 0.9032 - val_loss: 0.2671 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.9524 - loss: 0.1625\n",
      "Epoch 21: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 553ms/step - accuracy: 0.9523 - loss: 0.1625 - val_accuracy: 0.8387 - val_loss: 0.6472 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.9248 - loss: 0.1967\n",
      "Epoch 22: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 553ms/step - accuracy: 0.9248 - loss: 0.1969 - val_accuracy: 0.8710 - val_loss: 0.3048 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.9115 - loss: 0.2300\n",
      "Epoch 23: val_loss did not improve from 0.12862\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 553ms/step - accuracy: 0.9114 - loss: 0.2301 - val_accuracy: 0.9274 - val_loss: 0.2207 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9382 - loss: 0.1728\n",
      "Epoch 24: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 580ms/step - accuracy: 0.9382 - loss: 0.1727 - val_accuracy: 0.9516 - val_loss: 0.1598 - learning_rate: 2.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.9474 - loss: 0.1421\n",
      "Epoch 25: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 603ms/step - accuracy: 0.9475 - loss: 0.1421 - val_accuracy: 0.9435 - val_loss: 0.1503 - learning_rate: 2.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.9492 - loss: 0.1446\n",
      "Epoch 26: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 602ms/step - accuracy: 0.9492 - loss: 0.1446 - val_accuracy: 0.9435 - val_loss: 0.1721 - learning_rate: 2.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.9638 - loss: 0.1274\n",
      "Epoch 27: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 601ms/step - accuracy: 0.9638 - loss: 0.1274 - val_accuracy: 0.9274 - val_loss: 0.1731 - learning_rate: 2.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.9594 - loss: 0.1386\n",
      "Epoch 28: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 601ms/step - accuracy: 0.9594 - loss: 0.1385 - val_accuracy: 0.9435 - val_loss: 0.1505 - learning_rate: 2.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9441 - loss: 0.1468\n",
      "Epoch 29: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 609ms/step - accuracy: 0.9442 - loss: 0.1466 - val_accuracy: 0.9355 - val_loss: 0.1800 - learning_rate: 2.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.9566 - loss: 0.1071\n",
      "Epoch 30: val_loss did not improve from 0.12862\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 602ms/step - accuracy: 0.9566 - loss: 0.1073 - val_accuracy: 0.9435 - val_loss: 0.1474 - learning_rate: 2.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.9659 - loss: 0.0923\n",
      "Epoch 31: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 603ms/step - accuracy: 0.9659 - loss: 0.0922 - val_accuracy: 0.9435 - val_loss: 0.1341 - learning_rate: 4.0000e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.9659 - loss: 0.0922\n",
      "Epoch 32: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 600ms/step - accuracy: 0.9659 - loss: 0.0922 - val_accuracy: 0.9355 - val_loss: 0.1494 - learning_rate: 4.0000e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.9711 - loss: 0.0968\n",
      "Epoch 33: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 606ms/step - accuracy: 0.9711 - loss: 0.0967 - val_accuracy: 0.9435 - val_loss: 0.1405 - learning_rate: 4.0000e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9619 - loss: 0.1133\n",
      "Epoch 34: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 612ms/step - accuracy: 0.9619 - loss: 0.1131 - val_accuracy: 0.9435 - val_loss: 0.1517 - learning_rate: 4.0000e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9721 - loss: 0.0706\n",
      "Epoch 35: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 611ms/step - accuracy: 0.9722 - loss: 0.0706 - val_accuracy: 0.9435 - val_loss: 0.1505 - learning_rate: 4.0000e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9682 - loss: 0.0825\n",
      "Epoch 36: val_loss did not improve from 0.12862\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 609ms/step - accuracy: 0.9682 - loss: 0.0825 - val_accuracy: 0.9355 - val_loss: 0.1491 - learning_rate: 4.0000e-06\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionV3_from_scratch_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 699ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.96      0.88      0.92       103\n",
      "Shoot and Fruit Borer       0.92      0.97      0.95       145\n",
      "\n",
      "             accuracy                           0.94       248\n",
      "            macro avg       0.94      0.93      0.93       248\n",
      "         weighted avg       0.94      0.94      0.94       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionV3_from_scratch_bs8 is complete. Total time: 00:44:49 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionV3\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9bd4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionV3_transfer_learning_bs8 ---\n",
      "Mode: transfer_learning, Batch Size: 8, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 207ms/step - accuracy: 0.5543 - loss: 0.7270 - val_accuracy: 0.7016 - val_loss: 0.5914\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.6875 - loss: 0.6038 - val_accuracy: 0.7581 - val_loss: 0.5282\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.7313 - loss: 0.5545 - val_accuracy: 0.8065 - val_loss: 0.4898\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.7630 - loss: 0.5194 - val_accuracy: 0.8226 - val_loss: 0.4646\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.7980 - loss: 0.4455 - val_accuracy: 0.8548 - val_loss: 0.4259\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.7957 - loss: 0.4462 - val_accuracy: 0.7984 - val_loss: 0.4378\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.8197 - loss: 0.4161 - val_accuracy: 0.8548 - val_loss: 0.4049\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.8615 - loss: 0.3605 - val_accuracy: 0.8548 - val_loss: 0.3896\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.8487 - loss: 0.3614 - val_accuracy: 0.8387 - val_loss: 0.3905\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.8538 - loss: 0.3670 - val_accuracy: 0.8790 - val_loss: 0.3673\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.8517 - loss: 0.3505 - val_accuracy: 0.8790 - val_loss: 0.3491\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.8714 - loss: 0.3263 - val_accuracy: 0.8871 - val_loss: 0.3313\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8724 - loss: 0.3207 - val_accuracy: 0.8710 - val_loss: 0.3615\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8887 - loss: 0.2952 - val_accuracy: 0.8629 - val_loss: 0.3409\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8579 - loss: 0.3375 - val_accuracy: 0.8710 - val_loss: 0.3455\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9004 - loss: 0.2816 - val_accuracy: 0.8710 - val_loss: 0.3295\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.8981 - loss: 0.2841 - val_accuracy: 0.8871 - val_loss: 0.3272\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8878 - loss: 0.2947 - val_accuracy: 0.8790 - val_loss: 0.3309\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.8854 - loss: 0.3066 - val_accuracy: 0.9032 - val_loss: 0.2944\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9067 - loss: 0.2515 - val_accuracy: 0.9032 - val_loss: 0.2995\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.9025 - loss: 0.2530 - val_accuracy: 0.8952 - val_loss: 0.3061\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8975 - loss: 0.2539 - val_accuracy: 0.8952 - val_loss: 0.2821\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8920 - loss: 0.2744 - val_accuracy: 0.8952 - val_loss: 0.2881\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9144 - loss: 0.2650 - val_accuracy: 0.8952 - val_loss: 0.2707\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9079 - loss: 0.2625 - val_accuracy: 0.8952 - val_loss: 0.2911\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9128 - loss: 0.2473 - val_accuracy: 0.8871 - val_loss: 0.3023\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9016 - loss: 0.2468 - val_accuracy: 0.8952 - val_loss: 0.2791\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9096 - loss: 0.2283 - val_accuracy: 0.8952 - val_loss: 0.2714\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.8923 - loss: 0.2456 - val_accuracy: 0.9032 - val_loss: 0.2600\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8988 - loss: 0.2519 - val_accuracy: 0.9032 - val_loss: 0.2620\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9092 - loss: 0.2212 - val_accuracy: 0.9032 - val_loss: 0.2519\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.9088 - loss: 0.2216 - val_accuracy: 0.8871 - val_loss: 0.2757\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9156 - loss: 0.2486 - val_accuracy: 0.8952 - val_loss: 0.2602\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.9271 - loss: 0.2315 - val_accuracy: 0.9113 - val_loss: 0.2459\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9249 - loss: 0.2066 - val_accuracy: 0.9113 - val_loss: 0.2394\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.9012 - loss: 0.2498 - val_accuracy: 0.9032 - val_loss: 0.2563\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9097 - loss: 0.2232 - val_accuracy: 0.8952 - val_loss: 0.2618\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9162 - loss: 0.2201 - val_accuracy: 0.9032 - val_loss: 0.2477\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9261 - loss: 0.2156 - val_accuracy: 0.9032 - val_loss: 0.2573\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9228 - loss: 0.2157 - val_accuracy: 0.9194 - val_loss: 0.2241\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9143 - loss: 0.2225 - val_accuracy: 0.9113 - val_loss: 0.2229\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9149 - loss: 0.2247 - val_accuracy: 0.9032 - val_loss: 0.2431\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9304 - loss: 0.2159 - val_accuracy: 0.9113 - val_loss: 0.2361\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.9458 - loss: 0.1895 - val_accuracy: 0.9113 - val_loss: 0.2274\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9425 - loss: 0.1851 - val_accuracy: 0.9113 - val_loss: 0.2268\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.9307 - loss: 0.2154 - val_accuracy: 0.9113 - val_loss: 0.2302\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9303 - loss: 0.2059 - val_accuracy: 0.9113 - val_loss: 0.2309\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9152 - loss: 0.2132 - val_accuracy: 0.9274 - val_loss: 0.2186\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.9240 - loss: 0.1980 - val_accuracy: 0.9113 - val_loss: 0.2219\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 183ms/step - accuracy: 0.9181 - loss: 0.2211 - val_accuracy: 0.9113 - val_loss: 0.2196\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionV3_transfer_learning_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 695ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.86      0.89      0.88       103\n",
      "Shoot and Fruit Borer       0.92      0.90      0.91       145\n",
      "\n",
      "             accuracy                           0.90       248\n",
      "            macro avg       0.89      0.89      0.89       248\n",
      "         weighted avg       0.90      0.90      0.90       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionV3_transfer_learning_bs8 is complete. Total time: 00:19:32 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionV3\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa27188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionV3_fine_tune_bs8 ---\n",
      "Mode: fine_tune, Batch Size: 8, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - accuracy: 0.5008 - loss: 0.7881 - val_accuracy: 0.7258 - val_loss: 0.5911\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 508ms/step - accuracy: 0.6653 - loss: 0.6136 - val_accuracy: 0.6774 - val_loss: 0.6096\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.6946 - loss: 0.5858 - val_accuracy: 0.8306 - val_loss: 0.5115\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.7561 - loss: 0.5214 - val_accuracy: 0.8306 - val_loss: 0.4603\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.7770 - loss: 0.4743 - val_accuracy: 0.6935 - val_loss: 0.5402\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.7728 - loss: 0.4777 - val_accuracy: 0.7419 - val_loss: 0.5081\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.8469 - loss: 0.4020 - val_accuracy: 0.8145 - val_loss: 0.4367\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.8082 - loss: 0.4312 - val_accuracy: 0.8145 - val_loss: 0.4247\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.8486 - loss: 0.3698 - val_accuracy: 0.8710 - val_loss: 0.3649\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.8446 - loss: 0.3442 - val_accuracy: 0.8145 - val_loss: 0.4101\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 512ms/step - accuracy: 0.8819 - loss: 0.3372 - val_accuracy: 0.8629 - val_loss: 0.3725\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.8490 - loss: 0.3625 - val_accuracy: 0.8790 - val_loss: 0.3454\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.8756 - loss: 0.3043 - val_accuracy: 0.8629 - val_loss: 0.3602\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.8727 - loss: 0.3100 - val_accuracy: 0.8790 - val_loss: 0.3309\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.8662 - loss: 0.3222 - val_accuracy: 0.8790 - val_loss: 0.3284\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 519ms/step - accuracy: 0.8998 - loss: 0.2920 - val_accuracy: 0.8629 - val_loss: 0.3365\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 516ms/step - accuracy: 0.8899 - loss: 0.2925 - val_accuracy: 0.8952 - val_loss: 0.2987\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.9050 - loss: 0.2788 - val_accuracy: 0.8629 - val_loss: 0.3165\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.8909 - loss: 0.2655 - val_accuracy: 0.9274 - val_loss: 0.2809\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.8700 - loss: 0.2737 - val_accuracy: 0.8629 - val_loss: 0.3181\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.8905 - loss: 0.2776 - val_accuracy: 0.9113 - val_loss: 0.2804\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.8999 - loss: 0.2492 - val_accuracy: 0.9194 - val_loss: 0.2759\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 508ms/step - accuracy: 0.8713 - loss: 0.2768 - val_accuracy: 0.8871 - val_loss: 0.2857\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9014 - loss: 0.2469 - val_accuracy: 0.9032 - val_loss: 0.2732\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 513ms/step - accuracy: 0.8903 - loss: 0.2689 - val_accuracy: 0.9113 - val_loss: 0.2682\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9023 - loss: 0.2691 - val_accuracy: 0.9113 - val_loss: 0.2701\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.9206 - loss: 0.2259 - val_accuracy: 0.9032 - val_loss: 0.2719\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 512ms/step - accuracy: 0.9183 - loss: 0.2369 - val_accuracy: 0.9355 - val_loss: 0.2487\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.9049 - loss: 0.2315 - val_accuracy: 0.9113 - val_loss: 0.2639\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.9181 - loss: 0.2300 - val_accuracy: 0.9032 - val_loss: 0.2627\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9191 - loss: 0.2093 - val_accuracy: 0.9113 - val_loss: 0.2466\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 518ms/step - accuracy: 0.8946 - loss: 0.2482 - val_accuracy: 0.9032 - val_loss: 0.2604\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 512ms/step - accuracy: 0.9158 - loss: 0.2323 - val_accuracy: 0.8710 - val_loss: 0.2783\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9268 - loss: 0.2131 - val_accuracy: 0.8710 - val_loss: 0.2757\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 512ms/step - accuracy: 0.9218 - loss: 0.2220 - val_accuracy: 0.8952 - val_loss: 0.2629\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9232 - loss: 0.2109 - val_accuracy: 0.8871 - val_loss: 0.2643\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.9168 - loss: 0.2136 - val_accuracy: 0.9032 - val_loss: 0.2521\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 512ms/step - accuracy: 0.9142 - loss: 0.2397 - val_accuracy: 0.9113 - val_loss: 0.2387\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.9210 - loss: 0.2009 - val_accuracy: 0.9274 - val_loss: 0.2278\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 512ms/step - accuracy: 0.9133 - loss: 0.2218 - val_accuracy: 0.8952 - val_loss: 0.2522\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.9270 - loss: 0.2246 - val_accuracy: 0.9435 - val_loss: 0.2198\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9276 - loss: 0.2219 - val_accuracy: 0.9113 - val_loss: 0.2429\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.9219 - loss: 0.2231 - val_accuracy: 0.9113 - val_loss: 0.2374\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9353 - loss: 0.2009 - val_accuracy: 0.9355 - val_loss: 0.2203\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.9219 - loss: 0.2147 - val_accuracy: 0.9194 - val_loss: 0.2244\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9345 - loss: 0.1975 - val_accuracy: 0.9355 - val_loss: 0.2219\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 510ms/step - accuracy: 0.9129 - loss: 0.2219 - val_accuracy: 0.9032 - val_loss: 0.2421\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 511ms/step - accuracy: 0.9434 - loss: 0.1731 - val_accuracy: 0.9032 - val_loss: 0.2419\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 509ms/step - accuracy: 0.9263 - loss: 0.2130 - val_accuracy: 0.9355 - val_loss: 0.2163\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 513ms/step - accuracy: 0.9450 - loss: 0.1728 - val_accuracy: 0.9355 - val_loss: 0.2098\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionV3_fine_tune_bs8 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step \n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.87      0.89      0.88       103\n",
      "Shoot and Fruit Borer       0.92      0.90      0.91       145\n",
      "\n",
      "             accuracy                           0.90       248\n",
      "            macro avg       0.90      0.90      0.90       248\n",
      "         weighted avg       0.90      0.90      0.90       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionV3_fine_tune_bs8 is complete. Total time: 00:54:13 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionV3\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff688cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionV3_full_monty_bs8 ---\n",
      "Mode: full_monty, Batch Size: 8, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5123 - loss: 0.7975\n",
      "Epoch 1: val_loss improved from inf to 0.67467, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 179ms/step - accuracy: 0.5124 - loss: 0.7974 - val_accuracy: 0.5968 - val_loss: 0.6747 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6185 - loss: 0.7042\n",
      "Epoch 2: val_loss improved from 0.67467 to 0.61797, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - accuracy: 0.6185 - loss: 0.7042 - val_accuracy: 0.6774 - val_loss: 0.6180 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6614 - loss: 0.6248\n",
      "Epoch 3: val_loss improved from 0.61797 to 0.57085, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - accuracy: 0.6615 - loss: 0.6247 - val_accuracy: 0.6774 - val_loss: 0.5709 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7219 - loss: 0.5667\n",
      "Epoch 4: val_loss did not improve from 0.57085\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 155ms/step - accuracy: 0.7219 - loss: 0.5667 - val_accuracy: 0.7177 - val_loss: 0.5811 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7649 - loss: 0.4970\n",
      "Epoch 5: val_loss improved from 0.57085 to 0.50430, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - accuracy: 0.7648 - loss: 0.4969 - val_accuracy: 0.7500 - val_loss: 0.5043 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7823 - loss: 0.4656\n",
      "Epoch 6: val_loss improved from 0.50430 to 0.48192, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 174ms/step - accuracy: 0.7823 - loss: 0.4656 - val_accuracy: 0.7742 - val_loss: 0.4819 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8056 - loss: 0.4474\n",
      "Epoch 7: val_loss improved from 0.48192 to 0.46353, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.8056 - loss: 0.4473 - val_accuracy: 0.7742 - val_loss: 0.4635 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7895 - loss: 0.4462\n",
      "Epoch 8: val_loss improved from 0.46353 to 0.43729, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 177ms/step - accuracy: 0.7897 - loss: 0.4460 - val_accuracy: 0.7823 - val_loss: 0.4373 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8339 - loss: 0.3967\n",
      "Epoch 9: val_loss improved from 0.43729 to 0.41145, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.8339 - loss: 0.3966 - val_accuracy: 0.7903 - val_loss: 0.4114 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7945 - loss: 0.4208\n",
      "Epoch 10: val_loss did not improve from 0.41145\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - accuracy: 0.7947 - loss: 0.4207 - val_accuracy: 0.8065 - val_loss: 0.4152 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8393 - loss: 0.3762\n",
      "Epoch 11: val_loss improved from 0.41145 to 0.37927, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.8392 - loss: 0.3762 - val_accuracy: 0.8306 - val_loss: 0.3793 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8527 - loss: 0.3469\n",
      "Epoch 12: val_loss did not improve from 0.37927\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - accuracy: 0.8528 - loss: 0.3468 - val_accuracy: 0.8226 - val_loss: 0.3893 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8516 - loss: 0.3545\n",
      "Epoch 13: val_loss improved from 0.37927 to 0.36071, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.8517 - loss: 0.3545 - val_accuracy: 0.8548 - val_loss: 0.3607 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8800 - loss: 0.3031\n",
      "Epoch 14: val_loss did not improve from 0.36071\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - accuracy: 0.8799 - loss: 0.3032 - val_accuracy: 0.8226 - val_loss: 0.3804 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8610 - loss: 0.3360\n",
      "Epoch 15: val_loss did not improve from 0.36071\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - accuracy: 0.8611 - loss: 0.3359 - val_accuracy: 0.8306 - val_loss: 0.3831 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8684 - loss: 0.3051\n",
      "Epoch 16: val_loss did not improve from 0.36071\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - accuracy: 0.8685 - loss: 0.3051 - val_accuracy: 0.8468 - val_loss: 0.3619 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8976 - loss: 0.2817\n",
      "Epoch 17: val_loss improved from 0.36071 to 0.34887, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.8975 - loss: 0.2818 - val_accuracy: 0.8548 - val_loss: 0.3489 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8664 - loss: 0.3164\n",
      "Epoch 18: val_loss improved from 0.34887 to 0.31351, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.8664 - loss: 0.3163 - val_accuracy: 0.8952 - val_loss: 0.3135 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8588 - loss: 0.3055\n",
      "Epoch 19: val_loss improved from 0.31351 to 0.30737, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.8589 - loss: 0.3054 - val_accuracy: 0.8952 - val_loss: 0.3074 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8725 - loss: 0.3155\n",
      "Epoch 20: val_loss did not improve from 0.30737\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - accuracy: 0.8726 - loss: 0.3153 - val_accuracy: 0.8952 - val_loss: 0.3102 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8828 - loss: 0.3169\n",
      "Epoch 21: val_loss improved from 0.30737 to 0.30558, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.8829 - loss: 0.3166 - val_accuracy: 0.8952 - val_loss: 0.3056 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9140 - loss: 0.2388\n",
      "Epoch 22: val_loss improved from 0.30558 to 0.30453, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.9139 - loss: 0.2390 - val_accuracy: 0.8871 - val_loss: 0.3045 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8877 - loss: 0.2728\n",
      "Epoch 23: val_loss improved from 0.30453 to 0.29059, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 175ms/step - accuracy: 0.8876 - loss: 0.2728 - val_accuracy: 0.8952 - val_loss: 0.2906 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9148 - loss: 0.2275\n",
      "Epoch 24: val_loss did not improve from 0.29059\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 169ms/step - accuracy: 0.9146 - loss: 0.2277 - val_accuracy: 0.8710 - val_loss: 0.3233 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8938 - loss: 0.2674\n",
      "Epoch 25: val_loss improved from 0.29059 to 0.28288, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 177ms/step - accuracy: 0.8938 - loss: 0.2674 - val_accuracy: 0.8952 - val_loss: 0.2829 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9041 - loss: 0.2424\n",
      "Epoch 26: val_loss did not improve from 0.28288\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 170ms/step - accuracy: 0.9041 - loss: 0.2425 - val_accuracy: 0.8871 - val_loss: 0.2884 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8910 - loss: 0.2890\n",
      "Epoch 27: val_loss did not improve from 0.28288\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - accuracy: 0.8911 - loss: 0.2889 - val_accuracy: 0.8871 - val_loss: 0.2904 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9059 - loss: 0.2565\n",
      "Epoch 28: val_loss improved from 0.28288 to 0.28095, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.9059 - loss: 0.2565 - val_accuracy: 0.8871 - val_loss: 0.2810 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8974 - loss: 0.2571\n",
      "Epoch 29: val_loss improved from 0.28095 to 0.27099, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.8974 - loss: 0.2571 - val_accuracy: 0.8871 - val_loss: 0.2710 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8956 - loss: 0.2316\n",
      "Epoch 30: val_loss did not improve from 0.27099\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 169ms/step - accuracy: 0.8956 - loss: 0.2317 - val_accuracy: 0.8871 - val_loss: 0.2833 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9085 - loss: 0.2503\n",
      "Epoch 31: val_loss did not improve from 0.27099\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - accuracy: 0.9084 - loss: 0.2504 - val_accuracy: 0.8871 - val_loss: 0.2881 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8988 - loss: 0.2625\n",
      "Epoch 32: val_loss did not improve from 0.27099\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 170ms/step - accuracy: 0.8989 - loss: 0.2624 - val_accuracy: 0.8871 - val_loss: 0.2725 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9021 - loss: 0.2328\n",
      "Epoch 33: val_loss did not improve from 0.27099\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - accuracy: 0.9022 - loss: 0.2327 - val_accuracy: 0.8871 - val_loss: 0.2714 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8933 - loss: 0.2675\n",
      "Epoch 34: val_loss improved from 0.27099 to 0.25221, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.8933 - loss: 0.2674 - val_accuracy: 0.8871 - val_loss: 0.2522 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8947 - loss: 0.2325\n",
      "Epoch 35: val_loss did not improve from 0.25221\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - accuracy: 0.8948 - loss: 0.2324 - val_accuracy: 0.8952 - val_loss: 0.2642 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9072 - loss: 0.2476\n",
      "Epoch 36: val_loss did not improve from 0.25221\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 169ms/step - accuracy: 0.9073 - loss: 0.2474 - val_accuracy: 0.8871 - val_loss: 0.2825 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9085 - loss: 0.2384\n",
      "Epoch 37: val_loss did not improve from 0.25221\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 169ms/step - accuracy: 0.9085 - loss: 0.2383 - val_accuracy: 0.8952 - val_loss: 0.2604 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9322 - loss: 0.2313\n",
      "Epoch 38: val_loss did not improve from 0.25221\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 170ms/step - accuracy: 0.9322 - loss: 0.2313 - val_accuracy: 0.8871 - val_loss: 0.2632 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9111 - loss: 0.2228\n",
      "Epoch 39: val_loss did not improve from 0.25221\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 170ms/step - accuracy: 0.9111 - loss: 0.2228 - val_accuracy: 0.8952 - val_loss: 0.2619 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9122 - loss: 0.2118\n",
      "Epoch 40: val_loss did not improve from 0.25221\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 171ms/step - accuracy: 0.9122 - loss: 0.2118 - val_accuracy: 0.8952 - val_loss: 0.2540 - learning_rate: 2.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9386 - loss: 0.2054\n",
      "Epoch 41: val_loss did not improve from 0.25221\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - accuracy: 0.9385 - loss: 0.2056 - val_accuracy: 0.8952 - val_loss: 0.2525 - learning_rate: 2.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9221 - loss: 0.1904\n",
      "Epoch 42: val_loss did not improve from 0.25221\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 170ms/step - accuracy: 0.9221 - loss: 0.1905 - val_accuracy: 0.8952 - val_loss: 0.2557 - learning_rate: 2.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9218 - loss: 0.2073\n",
      "Epoch 43: val_loss improved from 0.25221 to 0.25217, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.9217 - loss: 0.2075 - val_accuracy: 0.8952 - val_loss: 0.2522 - learning_rate: 2.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9219 - loss: 0.2376\n",
      "Epoch 44: val_loss improved from 0.25217 to 0.25054, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.9219 - loss: 0.2375 - val_accuracy: 0.8952 - val_loss: 0.2505 - learning_rate: 2.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8974 - loss: 0.2253\n",
      "Epoch 45: val_loss did not improve from 0.25054\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 170ms/step - accuracy: 0.8975 - loss: 0.2252 - val_accuracy: 0.8952 - val_loss: 0.2530 - learning_rate: 2.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9165 - loss: 0.2254\n",
      "Epoch 46: val_loss improved from 0.25054 to 0.24659, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.9165 - loss: 0.2253 - val_accuracy: 0.8871 - val_loss: 0.2466 - learning_rate: 2.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9119 - loss: 0.2514\n",
      "Epoch 47: val_loss did not improve from 0.24659\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - accuracy: 0.9120 - loss: 0.2512 - val_accuracy: 0.8952 - val_loss: 0.2484 - learning_rate: 2.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9181 - loss: 0.2137\n",
      "Epoch 48: val_loss did not improve from 0.24659\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 169ms/step - accuracy: 0.9181 - loss: 0.2139 - val_accuracy: 0.8952 - val_loss: 0.2570 - learning_rate: 2.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9198 - loss: 0.2117\n",
      "Epoch 49: val_loss did not improve from 0.24659\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 171ms/step - accuracy: 0.9198 - loss: 0.2117 - val_accuracy: 0.8952 - val_loss: 0.2466 - learning_rate: 2.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9203 - loss: 0.2128\n",
      "Epoch 50: val_loss did not improve from 0.24659\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.9203 - loss: 0.2129 - val_accuracy: 0.8952 - val_loss: 0.2556 - learning_rate: 2.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 51/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8237 - loss: 0.3903\n",
      "Epoch 51: val_loss improved from 0.24659 to 0.15196, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 419ms/step - accuracy: 0.8239 - loss: 0.3901 - val_accuracy: 0.9516 - val_loss: 0.1520 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9112 - loss: 0.2345\n",
      "Epoch 52: val_loss improved from 0.15196 to 0.11030, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 355ms/step - accuracy: 0.9113 - loss: 0.2344 - val_accuracy: 0.9516 - val_loss: 0.1103 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.9186 - loss: 0.2052\n",
      "Epoch 53: val_loss improved from 0.11030 to 0.09361, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 356ms/step - accuracy: 0.9186 - loss: 0.2052 - val_accuracy: 0.9516 - val_loss: 0.0936 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9098 - loss: 0.2140\n",
      "Epoch 54: val_loss improved from 0.09361 to 0.07061, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 363ms/step - accuracy: 0.9099 - loss: 0.2139 - val_accuracy: 0.9758 - val_loss: 0.0706 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9541 - loss: 0.1252\n",
      "Epoch 55: val_loss improved from 0.07061 to 0.06255, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 357ms/step - accuracy: 0.9540 - loss: 0.1252 - val_accuracy: 0.9839 - val_loss: 0.0626 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9442 - loss: 0.1569\n",
      "Epoch 56: val_loss improved from 0.06255 to 0.05680, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 364ms/step - accuracy: 0.9442 - loss: 0.1568 - val_accuracy: 0.9839 - val_loss: 0.0568 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.9552 - loss: 0.1206\n",
      "Epoch 57: val_loss improved from 0.05680 to 0.05673, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 360ms/step - accuracy: 0.9552 - loss: 0.1205 - val_accuracy: 0.9839 - val_loss: 0.0567 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9579 - loss: 0.1061\n",
      "Epoch 58: val_loss improved from 0.05673 to 0.04838, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 364ms/step - accuracy: 0.9578 - loss: 0.1062 - val_accuracy: 0.9839 - val_loss: 0.0484 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9721 - loss: 0.0743\n",
      "Epoch 59: val_loss improved from 0.04838 to 0.03901, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 358ms/step - accuracy: 0.9720 - loss: 0.0745 - val_accuracy: 0.9919 - val_loss: 0.0390 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9557 - loss: 0.1196\n",
      "Epoch 60: val_loss improved from 0.03901 to 0.03578, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 368ms/step - accuracy: 0.9556 - loss: 0.1196 - val_accuracy: 0.9839 - val_loss: 0.0358 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9498 - loss: 0.1249\n",
      "Epoch 61: val_loss did not improve from 0.03578\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 348ms/step - accuracy: 0.9498 - loss: 0.1249 - val_accuracy: 0.9919 - val_loss: 0.0364 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9732 - loss: 0.0871\n",
      "Epoch 62: val_loss did not improve from 0.03578\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 349ms/step - accuracy: 0.9731 - loss: 0.0872 - val_accuracy: 0.9839 - val_loss: 0.0393 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9761 - loss: 0.0758\n",
      "Epoch 63: val_loss did not improve from 0.03578\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 351ms/step - accuracy: 0.9761 - loss: 0.0758 - val_accuracy: 0.9839 - val_loss: 0.0425 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9634 - loss: 0.0897\n",
      "Epoch 64: val_loss did not improve from 0.03578\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 351ms/step - accuracy: 0.9633 - loss: 0.0898 - val_accuracy: 0.9839 - val_loss: 0.0420 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9817 - loss: 0.0673\n",
      "Epoch 65: val_loss improved from 0.03578 to 0.02402, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 365ms/step - accuracy: 0.9816 - loss: 0.0674 - val_accuracy: 0.9919 - val_loss: 0.0240 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9702 - loss: 0.0804\n",
      "Epoch 66: val_loss improved from 0.02402 to 0.02249, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 367ms/step - accuracy: 0.9702 - loss: 0.0804 - val_accuracy: 0.9919 - val_loss: 0.0225 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9857 - loss: 0.0481\n",
      "Epoch 67: val_loss did not improve from 0.02249\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 352ms/step - accuracy: 0.9856 - loss: 0.0481 - val_accuracy: 1.0000 - val_loss: 0.0225 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9812 - loss: 0.0505\n",
      "Epoch 68: val_loss improved from 0.02249 to 0.02024, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 363ms/step - accuracy: 0.9812 - loss: 0.0505 - val_accuracy: 1.0000 - val_loss: 0.0202 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.9767 - loss: 0.0783\n",
      "Epoch 69: val_loss did not improve from 0.02024\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 347ms/step - accuracy: 0.9766 - loss: 0.0783 - val_accuracy: 0.9919 - val_loss: 0.0250 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9740 - loss: 0.0730\n",
      "Epoch 70: val_loss did not improve from 0.02024\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 348ms/step - accuracy: 0.9740 - loss: 0.0730 - val_accuracy: 1.0000 - val_loss: 0.0225 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9846 - loss: 0.0445\n",
      "Epoch 71: val_loss did not improve from 0.02024\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 348ms/step - accuracy: 0.9846 - loss: 0.0446 - val_accuracy: 0.9919 - val_loss: 0.0223 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9735 - loss: 0.0909\n",
      "Epoch 72: val_loss improved from 0.02024 to 0.01884, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 361ms/step - accuracy: 0.9735 - loss: 0.0908 - val_accuracy: 1.0000 - val_loss: 0.0188 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9874 - loss: 0.0377\n",
      "Epoch 73: val_loss improved from 0.01884 to 0.01559, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 364ms/step - accuracy: 0.9874 - loss: 0.0377 - val_accuracy: 1.0000 - val_loss: 0.0156 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9871 - loss: 0.0427\n",
      "Epoch 74: val_loss improved from 0.01559 to 0.01527, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 364ms/step - accuracy: 0.9871 - loss: 0.0426 - val_accuracy: 1.0000 - val_loss: 0.0153 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9911 - loss: 0.0301\n",
      "Epoch 75: val_loss did not improve from 0.01527\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 349ms/step - accuracy: 0.9910 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9912 - loss: 0.0248\n",
      "Epoch 76: val_loss improved from 0.01527 to 0.01467, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 362ms/step - accuracy: 0.9912 - loss: 0.0248 - val_accuracy: 1.0000 - val_loss: 0.0147 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9958 - loss: 0.0267\n",
      "Epoch 77: val_loss did not improve from 0.01467\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 350ms/step - accuracy: 0.9958 - loss: 0.0267 - val_accuracy: 1.0000 - val_loss: 0.0149 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9929 - loss: 0.0262\n",
      "Epoch 78: val_loss improved from 0.01467 to 0.01225, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 363ms/step - accuracy: 0.9929 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0122 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9866 - loss: 0.0419\n",
      "Epoch 79: val_loss improved from 0.01225 to 0.01083, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 363ms/step - accuracy: 0.9866 - loss: 0.0418 - val_accuracy: 1.0000 - val_loss: 0.0108 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9805 - loss: 0.0439\n",
      "Epoch 80: val_loss did not improve from 0.01083\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 352ms/step - accuracy: 0.9805 - loss: 0.0439 - val_accuracy: 1.0000 - val_loss: 0.0128 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9886 - loss: 0.0309\n",
      "Epoch 81: val_loss did not improve from 0.01083\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 350ms/step - accuracy: 0.9886 - loss: 0.0309 - val_accuracy: 1.0000 - val_loss: 0.0145 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9876 - loss: 0.0222\n",
      "Epoch 82: val_loss did not improve from 0.01083\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 351ms/step - accuracy: 0.9876 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0122 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9921 - loss: 0.0319\n",
      "Epoch 83: val_loss did not improve from 0.01083\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 350ms/step - accuracy: 0.9921 - loss: 0.0320 - val_accuracy: 1.0000 - val_loss: 0.0136 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9846 - loss: 0.0514\n",
      "Epoch 84: val_loss improved from 0.01083 to 0.00878, saving model to results\\InceptionV3_full_monty_bs8\\best_model.keras\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 364ms/step - accuracy: 0.9846 - loss: 0.0513 - val_accuracy: 1.0000 - val_loss: 0.0088 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9967 - loss: 0.0134\n",
      "Epoch 85: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 354ms/step - accuracy: 0.9967 - loss: 0.0135 - val_accuracy: 0.9919 - val_loss: 0.0128 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9825 - loss: 0.0373\n",
      "Epoch 86: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 352ms/step - accuracy: 0.9826 - loss: 0.0373 - val_accuracy: 1.0000 - val_loss: 0.0116 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9989 - loss: 0.0141\n",
      "Epoch 87: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 353ms/step - accuracy: 0.9989 - loss: 0.0142 - val_accuracy: 0.9919 - val_loss: 0.0126 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9963 - loss: 0.0159\n",
      "Epoch 88: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 352ms/step - accuracy: 0.9962 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0094 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9923 - loss: 0.0179\n",
      "Epoch 89: val_loss did not improve from 0.00878\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 353ms/step - accuracy: 0.9922 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 0.0112 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9977 - loss: 0.0150\n",
      "Epoch 90: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 354ms/step - accuracy: 0.9977 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 0.0104 - learning_rate: 2.0000e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9945 - loss: 0.0197\n",
      "Epoch 91: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 355ms/step - accuracy: 0.9945 - loss: 0.0198 - val_accuracy: 1.0000 - val_loss: 0.0108 - learning_rate: 2.0000e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9954 - loss: 0.0156\n",
      "Epoch 92: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 355ms/step - accuracy: 0.9954 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0107 - learning_rate: 2.0000e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9984 - loss: 0.0106\n",
      "Epoch 93: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 354ms/step - accuracy: 0.9984 - loss: 0.0107 - val_accuracy: 0.9919 - val_loss: 0.0114 - learning_rate: 2.0000e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9984 - loss: 0.0092\n",
      "Epoch 94: val_loss did not improve from 0.00878\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 353ms/step - accuracy: 0.9984 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0100 - learning_rate: 2.0000e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9882 - loss: 0.0588\n",
      "Epoch 95: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 355ms/step - accuracy: 0.9883 - loss: 0.0586 - val_accuracy: 1.0000 - val_loss: 0.0105 - learning_rate: 4.0000e-07\n",
      "Epoch 96/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9945 - loss: 0.0123\n",
      "Epoch 96: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 355ms/step - accuracy: 0.9945 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0104 - learning_rate: 4.0000e-07\n",
      "Epoch 97/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9954 - loss: 0.0203\n",
      "Epoch 97: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 354ms/step - accuracy: 0.9954 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0103 - learning_rate: 4.0000e-07\n",
      "Epoch 98/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.9910 - loss: 0.0315\n",
      "Epoch 98: val_loss did not improve from 0.00878\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 355ms/step - accuracy: 0.9911 - loss: 0.0314 - val_accuracy: 1.0000 - val_loss: 0.0107 - learning_rate: 4.0000e-07\n",
      "Epoch 99/100\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9951 - loss: 0.0159\n",
      "Epoch 99: val_loss did not improve from 0.00878\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 354ms/step - accuracy: 0.9951 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0112 - learning_rate: 4.0000e-07\n",
      "Epoch 99: early stopping\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionV3_full_monty_bs8 Final Test Set Evaluation ---\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B7EFEAA2A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 706ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.98      0.96      0.97       103\n",
      "Shoot and Fruit Borer       0.97      0.99      0.98       145\n",
      "\n",
      "             accuracy                           0.98       248\n",
      "            macro avg       0.98      0.97      0.98       248\n",
      "         weighted avg       0.98      0.98      0.98       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionV3_full_monty_bs8 is complete. Total time: 00:55:39 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionV3\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4340dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionResNetV2_from_scratch_bs16 ---\n",
      "Mode: from_scratch, Batch Size: 16, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "WARNING:tensorflow:From c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7541 - loss: 0.5366\n",
      "Epoch 1: val_loss improved from inf to 1.01766, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 3s/step - accuracy: 0.7549 - loss: 0.5355 - val_accuracy: 0.5887 - val_loss: 1.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8539 - loss: 0.3881\n",
      "Epoch 2: val_loss did not improve from 1.01766\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - accuracy: 0.8538 - loss: 0.3881 - val_accuracy: 0.5887 - val_loss: 2.4534 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8755 - loss: 0.3640\n",
      "Epoch 3: val_loss did not improve from 1.01766\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.8754 - loss: 0.3639 - val_accuracy: 0.5887 - val_loss: 2.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8781 - loss: 0.2795\n",
      "Epoch 4: val_loss did not improve from 1.01766\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.8779 - loss: 0.2800 - val_accuracy: 0.5887 - val_loss: 3.3577 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8729 - loss: 0.2995\n",
      "Epoch 5: val_loss did not improve from 1.01766\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.8730 - loss: 0.2993 - val_accuracy: 0.5887 - val_loss: 1.2530 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8763 - loss: 0.3103\n",
      "Epoch 6: val_loss did not improve from 1.01766\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.8765 - loss: 0.3101 - val_accuracy: 0.6129 - val_loss: 1.2457 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8826 - loss: 0.3045\n",
      "Epoch 7: val_loss improved from 1.01766 to 0.65989, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3s/step - accuracy: 0.8827 - loss: 0.3040 - val_accuracy: 0.7258 - val_loss: 0.6599 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8927 - loss: 0.2840\n",
      "Epoch 8: val_loss improved from 0.65989 to 0.33834, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.8928 - loss: 0.2836 - val_accuracy: 0.8468 - val_loss: 0.3383 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8958 - loss: 0.2469\n",
      "Epoch 9: val_loss improved from 0.33834 to 0.23936, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3s/step - accuracy: 0.8960 - loss: 0.2468 - val_accuracy: 0.9274 - val_loss: 0.2394 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9160 - loss: 0.2280\n",
      "Epoch 10: val_loss did not improve from 0.23936\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.9160 - loss: 0.2279 - val_accuracy: 0.8629 - val_loss: 0.4771 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9433 - loss: 0.1569\n",
      "Epoch 11: val_loss improved from 0.23936 to 0.16722, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3s/step - accuracy: 0.9429 - loss: 0.1575 - val_accuracy: 0.9355 - val_loss: 0.1672 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9232 - loss: 0.2204\n",
      "Epoch 12: val_loss did not improve from 0.16722\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9232 - loss: 0.2203 - val_accuracy: 0.8387 - val_loss: 0.4452 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9086 - loss: 0.2308\n",
      "Epoch 13: val_loss did not improve from 0.16722\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9086 - loss: 0.2307 - val_accuracy: 0.9435 - val_loss: 0.3938 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9141 - loss: 0.2031\n",
      "Epoch 14: val_loss did not improve from 0.16722\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.9142 - loss: 0.2030 - val_accuracy: 0.9516 - val_loss: 0.2231 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9415 - loss: 0.1366\n",
      "Epoch 15: val_loss did not improve from 0.16722\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.9417 - loss: 0.1364 - val_accuracy: 0.9435 - val_loss: 0.2806 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9440 - loss: 0.1472\n",
      "Epoch 16: val_loss did not improve from 0.16722\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9439 - loss: 0.1474 - val_accuracy: 0.9194 - val_loss: 0.2500 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9547 - loss: 0.1496\n",
      "Epoch 17: val_loss improved from 0.16722 to 0.14330, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3s/step - accuracy: 0.9546 - loss: 0.1497 - val_accuracy: 0.9516 - val_loss: 0.1433 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9496 - loss: 0.1430\n",
      "Epoch 18: val_loss did not improve from 0.14330\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9495 - loss: 0.1434 - val_accuracy: 0.9032 - val_loss: 0.4101 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9491 - loss: 0.1119\n",
      "Epoch 19: val_loss did not improve from 0.14330\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9490 - loss: 0.1122 - val_accuracy: 0.9516 - val_loss: 0.1444 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9586 - loss: 0.0944\n",
      "Epoch 20: val_loss did not improve from 0.14330\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9585 - loss: 0.0946 - val_accuracy: 0.8226 - val_loss: 0.8286 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9673 - loss: 0.1104\n",
      "Epoch 21: val_loss improved from 0.14330 to 0.13225, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3s/step - accuracy: 0.9673 - loss: 0.1104 - val_accuracy: 0.9435 - val_loss: 0.1322 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9601 - loss: 0.1162\n",
      "Epoch 22: val_loss improved from 0.13225 to 0.12820, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3s/step - accuracy: 0.9601 - loss: 0.1161 - val_accuracy: 0.9516 - val_loss: 0.1282 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9440 - loss: 0.1636\n",
      "Epoch 23: val_loss did not improve from 0.12820\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9439 - loss: 0.1636 - val_accuracy: 0.9355 - val_loss: 0.1523 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9330 - loss: 0.1627\n",
      "Epoch 24: val_loss improved from 0.12820 to 0.11655, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9332 - loss: 0.1621 - val_accuracy: 0.9274 - val_loss: 0.1166 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9625 - loss: 0.0985\n",
      "Epoch 25: val_loss improved from 0.11655 to 0.06097, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3s/step - accuracy: 0.9625 - loss: 0.0986 - val_accuracy: 0.9839 - val_loss: 0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9731 - loss: 0.0823\n",
      "Epoch 26: val_loss did not improve from 0.06097\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9732 - loss: 0.0820 - val_accuracy: 0.9516 - val_loss: 0.1608 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9522 - loss: 0.1058\n",
      "Epoch 27: val_loss did not improve from 0.06097\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9523 - loss: 0.1057 - val_accuracy: 0.9435 - val_loss: 0.1872 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9736 - loss: 0.0736\n",
      "Epoch 28: val_loss did not improve from 0.06097\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9736 - loss: 0.0737 - val_accuracy: 0.9435 - val_loss: 0.1831 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9740 - loss: 0.0624\n",
      "Epoch 29: val_loss did not improve from 0.06097\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9740 - loss: 0.0626 - val_accuracy: 0.9355 - val_loss: 0.1572 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9588 - loss: 0.1378\n",
      "Epoch 30: val_loss improved from 0.06097 to 0.06086, saving model to results\\InceptionResNetV2_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3s/step - accuracy: 0.9590 - loss: 0.1371 - val_accuracy: 0.9758 - val_loss: 0.0609 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9752 - loss: 0.0704\n",
      "Epoch 31: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9751 - loss: 0.0706 - val_accuracy: 0.9274 - val_loss: 0.2076 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9721 - loss: 0.0687\n",
      "Epoch 32: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9720 - loss: 0.0689 - val_accuracy: 0.9355 - val_loss: 0.1400 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9744 - loss: 0.0703\n",
      "Epoch 33: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9743 - loss: 0.0705 - val_accuracy: 0.9435 - val_loss: 0.1551 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9834 - loss: 0.0665\n",
      "Epoch 34: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9833 - loss: 0.0666 - val_accuracy: 0.9758 - val_loss: 0.1022 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9793 - loss: 0.0725\n",
      "Epoch 35: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9794 - loss: 0.0722 - val_accuracy: 0.9597 - val_loss: 0.0879 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9887 - loss: 0.0408\n",
      "Epoch 36: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9885 - loss: 0.0411 - val_accuracy: 0.9758 - val_loss: 0.1080 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9833 - loss: 0.0585\n",
      "Epoch 37: val_loss did not improve from 0.06086\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9832 - loss: 0.0586 - val_accuracy: 0.9758 - val_loss: 0.0936 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9855 - loss: 0.0390\n",
      "Epoch 38: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9855 - loss: 0.0391 - val_accuracy: 0.9758 - val_loss: 0.0953 - learning_rate: 2.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9908 - loss: 0.0250\n",
      "Epoch 39: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9908 - loss: 0.0250 - val_accuracy: 0.9677 - val_loss: 0.1142 - learning_rate: 2.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9893 - loss: 0.0363\n",
      "Epoch 40: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9893 - loss: 0.0362 - val_accuracy: 0.9516 - val_loss: 0.1288 - learning_rate: 2.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9939 - loss: 0.0190\n",
      "Epoch 41: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9939 - loss: 0.0191 - val_accuracy: 0.9597 - val_loss: 0.1219 - learning_rate: 2.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9926 - loss: 0.0247\n",
      "Epoch 42: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9925 - loss: 0.0247 - val_accuracy: 0.9516 - val_loss: 0.1216 - learning_rate: 2.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9947 - loss: 0.0297\n",
      "Epoch 43: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9947 - loss: 0.0296 - val_accuracy: 0.9597 - val_loss: 0.1346 - learning_rate: 2.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9933 - loss: 0.0326\n",
      "Epoch 44: val_loss did not improve from 0.06086\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9933 - loss: 0.0324 - val_accuracy: 0.9677 - val_loss: 0.1085 - learning_rate: 2.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9957 - loss: 0.0201\n",
      "Epoch 45: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3s/step - accuracy: 0.9957 - loss: 0.0201 - val_accuracy: 0.9677 - val_loss: 0.1153 - learning_rate: 4.0000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9954 - loss: 0.0186\n",
      "Epoch 46: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - accuracy: 0.9954 - loss: 0.0185 - val_accuracy: 0.9758 - val_loss: 0.1181 - learning_rate: 4.0000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9971 - loss: 0.0170\n",
      "Epoch 47: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9971 - loss: 0.0170 - val_accuracy: 0.9758 - val_loss: 0.1214 - learning_rate: 4.0000e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9941 - loss: 0.0163\n",
      "Epoch 48: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9941 - loss: 0.0163 - val_accuracy: 0.9758 - val_loss: 0.1195 - learning_rate: 4.0000e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9961 - loss: 0.0109\n",
      "Epoch 49: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.9961 - loss: 0.0109 - val_accuracy: 0.9758 - val_loss: 0.1211 - learning_rate: 4.0000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9946 - loss: 0.0149\n",
      "Epoch 50: val_loss did not improve from 0.06086\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.9946 - loss: 0.0149 - val_accuracy: 0.9677 - val_loss: 0.1246 - learning_rate: 4.0000e-06\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionResNetV2_from_scratch_bs16 Final Test Set Evaluation ---\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002A38545A660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.96      0.96      0.96       103\n",
      "Shoot and Fruit Borer       0.97      0.97      0.97       145\n",
      "\n",
      "             accuracy                           0.97       248\n",
      "            macro avg       0.97      0.97      0.97       248\n",
      "         weighted avg       0.97      0.97      0.97       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionResNetV2_from_scratch_bs16 is complete. Total time: 02:52:20 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionResNetV2\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9615bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionResNetV2_transfer_learning_bs16 ---\n",
      "Mode: transfer_learning, Batch Size: 16, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.4940 - loss: 0.8416 - val_accuracy: 0.4919 - val_loss: 0.7430\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.5459 - loss: 0.7733 - val_accuracy: 0.5565 - val_loss: 0.7124\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.5993 - loss: 0.7218 - val_accuracy: 0.5645 - val_loss: 0.7117\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.6530 - loss: 0.6650 - val_accuracy: 0.6371 - val_loss: 0.6499\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.6572 - loss: 0.6378 - val_accuracy: 0.6694 - val_loss: 0.6273\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.7173 - loss: 0.5912 - val_accuracy: 0.6855 - val_loss: 0.5874\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.7168 - loss: 0.5411 - val_accuracy: 0.6855 - val_loss: 0.5900\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.7220 - loss: 0.5268 - val_accuracy: 0.6935 - val_loss: 0.5591\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.7603 - loss: 0.4889 - val_accuracy: 0.7177 - val_loss: 0.5633\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.7813 - loss: 0.5016 - val_accuracy: 0.7177 - val_loss: 0.5352\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.7459 - loss: 0.5048 - val_accuracy: 0.7097 - val_loss: 0.5166\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8014 - loss: 0.4538 - val_accuracy: 0.7258 - val_loss: 0.5212\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8147 - loss: 0.4335 - val_accuracy: 0.7258 - val_loss: 0.5005\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.7896 - loss: 0.4623 - val_accuracy: 0.7581 - val_loss: 0.4661\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.7925 - loss: 0.4312 - val_accuracy: 0.7339 - val_loss: 0.5063\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.7971 - loss: 0.4424 - val_accuracy: 0.7419 - val_loss: 0.5033\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8367 - loss: 0.3999 - val_accuracy: 0.7419 - val_loss: 0.4807\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8619 - loss: 0.3673 - val_accuracy: 0.7581 - val_loss: 0.4619\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8148 - loss: 0.3950 - val_accuracy: 0.7581 - val_loss: 0.4574\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8357 - loss: 0.3967 - val_accuracy: 0.7742 - val_loss: 0.4419\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8258 - loss: 0.4012 - val_accuracy: 0.7661 - val_loss: 0.4416\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8313 - loss: 0.3743 - val_accuracy: 0.7823 - val_loss: 0.4450\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.8457 - loss: 0.3547 - val_accuracy: 0.7500 - val_loss: 0.4713\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8463 - loss: 0.3981 - val_accuracy: 0.7903 - val_loss: 0.4294\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8413 - loss: 0.3675 - val_accuracy: 0.7903 - val_loss: 0.4310\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8233 - loss: 0.3838 - val_accuracy: 0.7903 - val_loss: 0.4226\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.8383 - loss: 0.3820 - val_accuracy: 0.7742 - val_loss: 0.4400\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8519 - loss: 0.3767 - val_accuracy: 0.8226 - val_loss: 0.4048\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8520 - loss: 0.3594 - val_accuracy: 0.8065 - val_loss: 0.4197\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.8507 - loss: 0.3506 - val_accuracy: 0.8065 - val_loss: 0.4101\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.8784 - loss: 0.3112 - val_accuracy: 0.8226 - val_loss: 0.3992\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8558 - loss: 0.3384 - val_accuracy: 0.8306 - val_loss: 0.3859\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8601 - loss: 0.3217 - val_accuracy: 0.8226 - val_loss: 0.3926\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8613 - loss: 0.3137 - val_accuracy: 0.8306 - val_loss: 0.3918\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8784 - loss: 0.3363 - val_accuracy: 0.8226 - val_loss: 0.3930\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8585 - loss: 0.3250 - val_accuracy: 0.8306 - val_loss: 0.3872\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8518 - loss: 0.3282 - val_accuracy: 0.8226 - val_loss: 0.3981\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8684 - loss: 0.3066 - val_accuracy: 0.8468 - val_loss: 0.3723\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8801 - loss: 0.3298 - val_accuracy: 0.8468 - val_loss: 0.3800\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8661 - loss: 0.3130 - val_accuracy: 0.8468 - val_loss: 0.3646\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8820 - loss: 0.3233 - val_accuracy: 0.8468 - val_loss: 0.3664\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8816 - loss: 0.2930 - val_accuracy: 0.8468 - val_loss: 0.3592\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8527 - loss: 0.3471 - val_accuracy: 0.8226 - val_loss: 0.3793\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8771 - loss: 0.2814 - val_accuracy: 0.8468 - val_loss: 0.3574\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8835 - loss: 0.2899 - val_accuracy: 0.8226 - val_loss: 0.3758\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8793 - loss: 0.2967 - val_accuracy: 0.8468 - val_loss: 0.3441\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8659 - loss: 0.3015 - val_accuracy: 0.8468 - val_loss: 0.3559\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8898 - loss: 0.2791 - val_accuracy: 0.8468 - val_loss: 0.3511\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8958 - loss: 0.2788 - val_accuracy: 0.8468 - val_loss: 0.3357\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.9059 - loss: 0.2617 - val_accuracy: 0.8468 - val_loss: 0.3427\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionResNetV2_transfer_learning_bs16 Final Test Set Evaluation ---\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002A38545B1A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.75      0.93      0.83       103\n",
      "Shoot and Fruit Borer       0.94      0.78      0.85       145\n",
      "\n",
      "             accuracy                           0.84       248\n",
      "            macro avg       0.85      0.86      0.84       248\n",
      "         weighted avg       0.86      0.84      0.84       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionResNetV2_transfer_learning_bs16 is complete. Total time: 01:05:02 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionResNetV2\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bfd063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionResNetV2_fine_tune_bs16 ---\n",
      "Mode: fine_tune, Batch Size: 16, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.8546 - val_accuracy: 0.6048 - val_loss: 0.6312\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.5719 - loss: 0.7529 - val_accuracy: 0.6532 - val_loss: 0.6040\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.6329 - loss: 0.6738 - val_accuracy: 0.6855 - val_loss: 0.5842\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.6450 - loss: 0.6550 - val_accuracy: 0.7177 - val_loss: 0.5587\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.6818 - loss: 0.6082 - val_accuracy: 0.7016 - val_loss: 0.5331\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.6895 - loss: 0.5832 - val_accuracy: 0.7097 - val_loss: 0.5068\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.7117 - loss: 0.5555 - val_accuracy: 0.7500 - val_loss: 0.5264\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.7470 - loss: 0.5235 - val_accuracy: 0.7581 - val_loss: 0.4992\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.7925 - loss: 0.4774 - val_accuracy: 0.7661 - val_loss: 0.4946\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.7740 - loss: 0.4746 - val_accuracy: 0.7742 - val_loss: 0.4656\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.8187 - loss: 0.4439 - val_accuracy: 0.7339 - val_loss: 0.4914\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8197 - loss: 0.4189 - val_accuracy: 0.7742 - val_loss: 0.4639\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.7919 - loss: 0.4553 - val_accuracy: 0.7823 - val_loss: 0.4552\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.8091 - loss: 0.4483 - val_accuracy: 0.8145 - val_loss: 0.4374\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.8241 - loss: 0.4135 - val_accuracy: 0.8145 - val_loss: 0.4322\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.8523 - loss: 0.3832 - val_accuracy: 0.7742 - val_loss: 0.4504\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8538 - loss: 0.3732 - val_accuracy: 0.7903 - val_loss: 0.4318\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.8369 - loss: 0.3992 - val_accuracy: 0.7823 - val_loss: 0.4332\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.8595 - loss: 0.3720 - val_accuracy: 0.8387 - val_loss: 0.4144\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8149 - loss: 0.4041 - val_accuracy: 0.7984 - val_loss: 0.4250\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8370 - loss: 0.3907 - val_accuracy: 0.8306 - val_loss: 0.4097\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.8578 - loss: 0.3464 - val_accuracy: 0.8306 - val_loss: 0.4077\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8460 - loss: 0.3606 - val_accuracy: 0.8065 - val_loss: 0.4134\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8471 - loss: 0.3673 - val_accuracy: 0.8629 - val_loss: 0.3847\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8596 - loss: 0.3344 - val_accuracy: 0.8629 - val_loss: 0.3880\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8730 - loss: 0.3169 - val_accuracy: 0.8629 - val_loss: 0.3819\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8354 - loss: 0.3607 - val_accuracy: 0.8629 - val_loss: 0.3824\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8690 - loss: 0.3183 - val_accuracy: 0.8629 - val_loss: 0.3778\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8715 - loss: 0.3226 - val_accuracy: 0.8387 - val_loss: 0.3923\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8489 - loss: 0.3419 - val_accuracy: 0.8387 - val_loss: 0.3880\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.8673 - loss: 0.3366 - val_accuracy: 0.8548 - val_loss: 0.3739\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8670 - loss: 0.3225 - val_accuracy: 0.8468 - val_loss: 0.3764\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8640 - loss: 0.3080 - val_accuracy: 0.8387 - val_loss: 0.3819\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8849 - loss: 0.3126 - val_accuracy: 0.8548 - val_loss: 0.3728\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8604 - loss: 0.3374 - val_accuracy: 0.8548 - val_loss: 0.3637\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8515 - loss: 0.3347 - val_accuracy: 0.8065 - val_loss: 0.3897\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.9044 - loss: 0.2691 - val_accuracy: 0.8468 - val_loss: 0.3652\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8664 - loss: 0.3132 - val_accuracy: 0.8548 - val_loss: 0.3587\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.8708 - loss: 0.3166 - val_accuracy: 0.8468 - val_loss: 0.3732\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8809 - loss: 0.3107 - val_accuracy: 0.8548 - val_loss: 0.3484\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.8719 - loss: 0.3008 - val_accuracy: 0.8548 - val_loss: 0.3407\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8680 - loss: 0.2976 - val_accuracy: 0.8548 - val_loss: 0.3374\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.8816 - loss: 0.2910 - val_accuracy: 0.8468 - val_loss: 0.3331\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8788 - loss: 0.2982 - val_accuracy: 0.8548 - val_loss: 0.3372\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8439 - loss: 0.3171 - val_accuracy: 0.8468 - val_loss: 0.3518\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8768 - loss: 0.2991 - val_accuracy: 0.8468 - val_loss: 0.3496\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.8713 - loss: 0.3092 - val_accuracy: 0.8548 - val_loss: 0.3252\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.8677 - loss: 0.3072 - val_accuracy: 0.8548 - val_loss: 0.3433\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.8717 - loss: 0.2908 - val_accuracy: 0.8629 - val_loss: 0.3300\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.8728 - loss: 0.2948 - val_accuracy: 0.8548 - val_loss: 0.3357\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionResNetV2_fine_tune_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.74      0.95      0.83       103\n",
      "Shoot and Fruit Borer       0.96      0.76      0.85       145\n",
      "\n",
      "             accuracy                           0.84       248\n",
      "            macro avg       0.85      0.86      0.84       248\n",
      "         weighted avg       0.87      0.84      0.84       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionResNetV2_fine_tune_bs16 is complete. Total time: 01:40:33 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionResNetV2\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29149f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: InceptionResNetV2_full_monty_bs16 ---\n",
      "Mode: full_monty, Batch Size: 16, LR: 0.0001, Input: 299x299\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_299x299_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "WARNING:tensorflow:From c:\\Users\\dr-basab\\Desktop\\Research Projects\\ADLMODCT\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step - accuracy: 0.5214 - loss: 0.7977\n",
      "Epoch 1: val_loss improved from inf to 0.65781, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.5214 - loss: 0.7975 - val_accuracy: 0.5968 - val_loss: 0.6578 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step - accuracy: 0.5607 - loss: 0.7417\n",
      "Epoch 2: val_loss improved from 0.65781 to 0.62041, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 947ms/step - accuracy: 0.5609 - loss: 0.7414 - val_accuracy: 0.6532 - val_loss: 0.6204 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812ms/step - accuracy: 0.6024 - loss: 0.7001\n",
      "Epoch 3: val_loss improved from 0.62041 to 0.59287, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 946ms/step - accuracy: 0.6028 - loss: 0.6996 - val_accuracy: 0.6855 - val_loss: 0.5929 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.6609 - loss: 0.6148\n",
      "Epoch 4: val_loss improved from 0.59287 to 0.57228, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 973ms/step - accuracy: 0.6609 - loss: 0.6147 - val_accuracy: 0.7177 - val_loss: 0.5723 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.6509 - loss: 0.6110\n",
      "Epoch 5: val_loss improved from 0.57228 to 0.55553, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 994ms/step - accuracy: 0.6512 - loss: 0.6108 - val_accuracy: 0.6935 - val_loss: 0.5555 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878ms/step - accuracy: 0.6807 - loss: 0.6016\n",
      "Epoch 6: val_loss improved from 0.55553 to 0.53714, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6809 - loss: 0.6012 - val_accuracy: 0.7016 - val_loss: 0.5371 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862ms/step - accuracy: 0.7294 - loss: 0.5425\n",
      "Epoch 7: val_loss did not improve from 0.53714\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 966ms/step - accuracy: 0.7293 - loss: 0.5424 - val_accuracy: 0.6855 - val_loss: 0.5456 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870ms/step - accuracy: 0.7765 - loss: 0.4983\n",
      "Epoch 8: val_loss improved from 0.53714 to 0.51463, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.7761 - loss: 0.4985 - val_accuracy: 0.7016 - val_loss: 0.5146 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870ms/step - accuracy: 0.7548 - loss: 0.5152\n",
      "Epoch 9: val_loss improved from 0.51463 to 0.49803, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.7550 - loss: 0.5149 - val_accuracy: 0.7016 - val_loss: 0.4980 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884ms/step - accuracy: 0.7916 - loss: 0.4641\n",
      "Epoch 10: val_loss improved from 0.49803 to 0.49370, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.7913 - loss: 0.4644 - val_accuracy: 0.7097 - val_loss: 0.4937 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888ms/step - accuracy: 0.7862 - loss: 0.4480\n",
      "Epoch 11: val_loss improved from 0.49370 to 0.48138, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.7863 - loss: 0.4480 - val_accuracy: 0.7339 - val_loss: 0.4814 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877ms/step - accuracy: 0.7631 - loss: 0.4761\n",
      "Epoch 12: val_loss did not improve from 0.48138\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 984ms/step - accuracy: 0.7632 - loss: 0.4760 - val_accuracy: 0.7177 - val_loss: 0.4926 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881ms/step - accuracy: 0.8089 - loss: 0.4121\n",
      "Epoch 13: val_loss improved from 0.48138 to 0.47528, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8088 - loss: 0.4122 - val_accuracy: 0.7177 - val_loss: 0.4753 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906ms/step - accuracy: 0.8162 - loss: 0.4285\n",
      "Epoch 14: val_loss improved from 0.47528 to 0.47082, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8164 - loss: 0.4283 - val_accuracy: 0.7177 - val_loss: 0.4708 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903ms/step - accuracy: 0.8055 - loss: 0.4335\n",
      "Epoch 15: val_loss did not improve from 0.47082\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8053 - loss: 0.4335 - val_accuracy: 0.7339 - val_loss: 0.4824 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907ms/step - accuracy: 0.7904 - loss: 0.4429\n",
      "Epoch 16: val_loss improved from 0.47082 to 0.45615, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7907 - loss: 0.4429 - val_accuracy: 0.7258 - val_loss: 0.4562 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908ms/step - accuracy: 0.8113 - loss: 0.4273\n",
      "Epoch 17: val_loss improved from 0.45615 to 0.45128, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8116 - loss: 0.4270 - val_accuracy: 0.7339 - val_loss: 0.4513 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919ms/step - accuracy: 0.8392 - loss: 0.3821\n",
      "Epoch 18: val_loss improved from 0.45128 to 0.44435, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.8392 - loss: 0.3822 - val_accuracy: 0.7661 - val_loss: 0.4443 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911ms/step - accuracy: 0.8414 - loss: 0.3887\n",
      "Epoch 19: val_loss did not improve from 0.44435\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8412 - loss: 0.3887 - val_accuracy: 0.7581 - val_loss: 0.4467 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914ms/step - accuracy: 0.8312 - loss: 0.3862\n",
      "Epoch 20: val_loss improved from 0.44435 to 0.44131, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8313 - loss: 0.3862 - val_accuracy: 0.7742 - val_loss: 0.4413 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946ms/step - accuracy: 0.8447 - loss: 0.4066\n",
      "Epoch 21: val_loss improved from 0.44131 to 0.42638, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.8446 - loss: 0.4064 - val_accuracy: 0.7903 - val_loss: 0.4264 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911ms/step - accuracy: 0.8301 - loss: 0.3638\n",
      "Epoch 22: val_loss did not improve from 0.42638\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8304 - loss: 0.3637 - val_accuracy: 0.7742 - val_loss: 0.4365 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906ms/step - accuracy: 0.8415 - loss: 0.3803\n",
      "Epoch 23: val_loss improved from 0.42638 to 0.42578, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8416 - loss: 0.3800 - val_accuracy: 0.7903 - val_loss: 0.4258 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924ms/step - accuracy: 0.8516 - loss: 0.3583\n",
      "Epoch 24: val_loss improved from 0.42578 to 0.41082, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8516 - loss: 0.3583 - val_accuracy: 0.7903 - val_loss: 0.4108 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907ms/step - accuracy: 0.8491 - loss: 0.3543\n",
      "Epoch 25: val_loss improved from 0.41082 to 0.40355, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8492 - loss: 0.3541 - val_accuracy: 0.7984 - val_loss: 0.4035 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919ms/step - accuracy: 0.8446 - loss: 0.3521\n",
      "Epoch 26: val_loss did not improve from 0.40355\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8446 - loss: 0.3522 - val_accuracy: 0.7984 - val_loss: 0.4145 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919ms/step - accuracy: 0.8467 - loss: 0.3399\n",
      "Epoch 27: val_loss improved from 0.40355 to 0.39469, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8468 - loss: 0.3400 - val_accuracy: 0.8065 - val_loss: 0.3947 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908ms/step - accuracy: 0.8729 - loss: 0.3178\n",
      "Epoch 28: val_loss improved from 0.39469 to 0.39122, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8728 - loss: 0.3179 - val_accuracy: 0.8145 - val_loss: 0.3912 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940ms/step - accuracy: 0.8513 - loss: 0.3596\n",
      "Epoch 29: val_loss improved from 0.39122 to 0.37779, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.8510 - loss: 0.3598 - val_accuracy: 0.8145 - val_loss: 0.3778 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927ms/step - accuracy: 0.8225 - loss: 0.3858\n",
      "Epoch 30: val_loss did not improve from 0.37779\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8229 - loss: 0.3852 - val_accuracy: 0.8145 - val_loss: 0.3881 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935ms/step - accuracy: 0.8724 - loss: 0.3297\n",
      "Epoch 31: val_loss did not improve from 0.37779\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8725 - loss: 0.3295 - val_accuracy: 0.8226 - val_loss: 0.3784 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929ms/step - accuracy: 0.8546 - loss: 0.3270\n",
      "Epoch 32: val_loss did not improve from 0.37779\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8546 - loss: 0.3271 - val_accuracy: 0.8145 - val_loss: 0.3831 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932ms/step - accuracy: 0.8646 - loss: 0.3089\n",
      "Epoch 33: val_loss did not improve from 0.37779\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8646 - loss: 0.3091 - val_accuracy: 0.8306 - val_loss: 0.3799 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933ms/step - accuracy: 0.8661 - loss: 0.3064\n",
      "Epoch 34: val_loss improved from 0.37779 to 0.37773, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.8662 - loss: 0.3064 - val_accuracy: 0.8306 - val_loss: 0.3777 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933ms/step - accuracy: 0.8725 - loss: 0.3115\n",
      "Epoch 35: val_loss improved from 0.37773 to 0.37608, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.8724 - loss: 0.3116 - val_accuracy: 0.8306 - val_loss: 0.3761 - learning_rate: 2.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925ms/step - accuracy: 0.8539 - loss: 0.3535\n",
      "Epoch 36: val_loss improved from 0.37608 to 0.37199, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.8540 - loss: 0.3533 - val_accuracy: 0.8306 - val_loss: 0.3720 - learning_rate: 2.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940ms/step - accuracy: 0.8733 - loss: 0.3268\n",
      "Epoch 37: val_loss did not improve from 0.37199\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8735 - loss: 0.3265 - val_accuracy: 0.8306 - val_loss: 0.3761 - learning_rate: 2.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939ms/step - accuracy: 0.8869 - loss: 0.2968\n",
      "Epoch 38: val_loss did not improve from 0.37199\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8869 - loss: 0.2970 - val_accuracy: 0.8306 - val_loss: 0.3775 - learning_rate: 2.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941ms/step - accuracy: 0.8745 - loss: 0.3148\n",
      "Epoch 39: val_loss improved from 0.37199 to 0.37114, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.8743 - loss: 0.3150 - val_accuracy: 0.8306 - val_loss: 0.3711 - learning_rate: 2.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920ms/step - accuracy: 0.8831 - loss: 0.2969\n",
      "Epoch 40: val_loss did not improve from 0.37114\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8830 - loss: 0.2970 - val_accuracy: 0.8306 - val_loss: 0.3719 - learning_rate: 2.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920ms/step - accuracy: 0.8757 - loss: 0.2879\n",
      "Epoch 41: val_loss did not improve from 0.37114\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8757 - loss: 0.2881 - val_accuracy: 0.8306 - val_loss: 0.3754 - learning_rate: 2.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922ms/step - accuracy: 0.8879 - loss: 0.2882\n",
      "Epoch 42: val_loss did not improve from 0.37114\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8878 - loss: 0.2885 - val_accuracy: 0.8306 - val_loss: 0.3725 - learning_rate: 2.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913ms/step - accuracy: 0.8795 - loss: 0.3141\n",
      "Epoch 43: val_loss improved from 0.37114 to 0.37098, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8796 - loss: 0.3139 - val_accuracy: 0.8306 - val_loss: 0.3710 - learning_rate: 2.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934ms/step - accuracy: 0.8489 - loss: 0.3527\n",
      "Epoch 44: val_loss improved from 0.37098 to 0.37027, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.8490 - loss: 0.3523 - val_accuracy: 0.8306 - val_loss: 0.3703 - learning_rate: 2.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919ms/step - accuracy: 0.8759 - loss: 0.3189\n",
      "Epoch 45: val_loss did not improve from 0.37027\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8758 - loss: 0.3189 - val_accuracy: 0.8306 - val_loss: 0.3708 - learning_rate: 2.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920ms/step - accuracy: 0.8877 - loss: 0.3078\n",
      "Epoch 46: val_loss improved from 0.37027 to 0.36722, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8873 - loss: 0.3081 - val_accuracy: 0.8306 - val_loss: 0.3672 - learning_rate: 2.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909ms/step - accuracy: 0.8507 - loss: 0.3176\n",
      "Epoch 47: val_loss did not improve from 0.36722\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8508 - loss: 0.3173 - val_accuracy: 0.8306 - val_loss: 0.3680 - learning_rate: 2.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911ms/step - accuracy: 0.8736 - loss: 0.3199\n",
      "Epoch 48: val_loss did not improve from 0.36722\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8737 - loss: 0.3196 - val_accuracy: 0.8306 - val_loss: 0.3676 - learning_rate: 2.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916ms/step - accuracy: 0.8699 - loss: 0.3232\n",
      "Epoch 49: val_loss improved from 0.36722 to 0.36643, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8700 - loss: 0.3230 - val_accuracy: 0.8387 - val_loss: 0.3664 - learning_rate: 2.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914ms/step - accuracy: 0.8668 - loss: 0.3098\n",
      "Epoch 50: val_loss did not improve from 0.36643\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8670 - loss: 0.3097 - val_accuracy: 0.8306 - val_loss: 0.3689 - learning_rate: 2.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 51/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8441 - loss: 0.3682\n",
      "Epoch 51: val_loss improved from 0.36643 to 0.21032, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.8445 - loss: 0.3675 - val_accuracy: 0.9113 - val_loss: 0.2103 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9208 - loss: 0.2065\n",
      "Epoch 52: val_loss improved from 0.21032 to 0.14249, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.9207 - loss: 0.2065 - val_accuracy: 0.9435 - val_loss: 0.1425 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9410 - loss: 0.1626\n",
      "Epoch 53: val_loss improved from 0.14249 to 0.10601, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9411 - loss: 0.1623 - val_accuracy: 0.9597 - val_loss: 0.1060 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9659 - loss: 0.0990\n",
      "Epoch 54: val_loss improved from 0.10601 to 0.09450, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 0.9659 - loss: 0.0990 - val_accuracy: 0.9597 - val_loss: 0.0945 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9627 - loss: 0.1025\n",
      "Epoch 55: val_loss improved from 0.09450 to 0.07670, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.9627 - loss: 0.1026 - val_accuracy: 0.9677 - val_loss: 0.0767 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9803 - loss: 0.0620\n",
      "Epoch 56: val_loss improved from 0.07670 to 0.06973, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.9803 - loss: 0.0620 - val_accuracy: 0.9839 - val_loss: 0.0697 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9771 - loss: 0.0665\n",
      "Epoch 57: val_loss did not improve from 0.06973\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.9771 - loss: 0.0664 - val_accuracy: 0.9758 - val_loss: 0.0774 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9759 - loss: 0.0655\n",
      "Epoch 58: val_loss improved from 0.06973 to 0.06880, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.9760 - loss: 0.0653 - val_accuracy: 0.9758 - val_loss: 0.0688 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9877 - loss: 0.0333\n",
      "Epoch 59: val_loss improved from 0.06880 to 0.05615, saving model to results\\InceptionResNetV2_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.9877 - loss: 0.0334 - val_accuracy: 0.9839 - val_loss: 0.0562 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9821 - loss: 0.0518\n",
      "Epoch 60: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9821 - loss: 0.0517 - val_accuracy: 0.9839 - val_loss: 0.0576 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9764 - loss: 0.0631\n",
      "Epoch 61: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0629 - val_accuracy: 0.9839 - val_loss: 0.0645 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9878 - loss: 0.0363\n",
      "Epoch 62: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9877 - loss: 0.0364 - val_accuracy: 0.9839 - val_loss: 0.0606 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9970 - loss: 0.0172\n",
      "Epoch 63: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.9970 - loss: 0.0173 - val_accuracy: 0.9839 - val_loss: 0.0576 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9914 - loss: 0.0262\n",
      "Epoch 64: val_loss did not improve from 0.05615\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.9914 - loss: 0.0262 - val_accuracy: 0.9758 - val_loss: 0.0631 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9943 - loss: 0.0190\n",
      "Epoch 65: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.9943 - loss: 0.0191 - val_accuracy: 0.9758 - val_loss: 0.0631 - learning_rate: 2.0000e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9931 - loss: 0.0254\n",
      "Epoch 66: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9931 - loss: 0.0253 - val_accuracy: 0.9758 - val_loss: 0.0630 - learning_rate: 2.0000e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9906 - loss: 0.0254\n",
      "Epoch 67: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9907 - loss: 0.0253 - val_accuracy: 0.9758 - val_loss: 0.0638 - learning_rate: 2.0000e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9947 - loss: 0.0187\n",
      "Epoch 68: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.9947 - loss: 0.0188 - val_accuracy: 0.9758 - val_loss: 0.0659 - learning_rate: 2.0000e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9878 - loss: 0.0301\n",
      "Epoch 69: val_loss did not improve from 0.05615\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9879 - loss: 0.0300 - val_accuracy: 0.9758 - val_loss: 0.0659 - learning_rate: 2.0000e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9933 - loss: 0.0142\n",
      "Epoch 70: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9934 - loss: 0.0143 - val_accuracy: 0.9758 - val_loss: 0.0657 - learning_rate: 4.0000e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9994 - loss: 0.0104\n",
      "Epoch 71: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9994 - loss: 0.0105 - val_accuracy: 0.9758 - val_loss: 0.0671 - learning_rate: 4.0000e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9896 - loss: 0.0366\n",
      "Epoch 72: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 0.0364 - val_accuracy: 0.9758 - val_loss: 0.0669 - learning_rate: 4.0000e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9933 - loss: 0.0214\n",
      "Epoch 73: val_loss did not improve from 0.05615\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9934 - loss: 0.0214 - val_accuracy: 0.9758 - val_loss: 0.0674 - learning_rate: 4.0000e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9973 - loss: 0.0141\n",
      "Epoch 74: val_loss did not improve from 0.05615\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.9972 - loss: 0.0141 - val_accuracy: 0.9758 - val_loss: 0.0673 - learning_rate: 4.0000e-07\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- InceptionResNetV2_full_monty_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.96      0.96      0.96       103\n",
      "Shoot and Fruit Borer       0.97      0.97      0.97       145\n",
      "\n",
      "             accuracy                           0.97       248\n",
      "            macro avg       0.97      0.97      0.97       248\n",
      "         weighted avg       0.97      0.97      0.97       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for InceptionResNetV2_full_monty_bs16 is complete. Total time: 01:55:43 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"InceptionResNetV2\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a767361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG16_from_scratch_bs16 ---\n",
      "Mode: from_scratch, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4953 - loss: 0.6937\n",
      "Epoch 1: val_loss improved from inf to 0.67520, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.4957 - loss: 0.6938 - val_accuracy: 0.5968 - val_loss: 0.6752 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5736 - loss: 0.6836\n",
      "Epoch 2: val_loss improved from 0.67520 to 0.49016, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.5741 - loss: 0.6832 - val_accuracy: 0.7500 - val_loss: 0.4902 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7383 - loss: 0.5484\n",
      "Epoch 3: val_loss improved from 0.49016 to 0.41527, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.7380 - loss: 0.5487 - val_accuracy: 0.8145 - val_loss: 0.4153 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7517 - loss: 0.4915\n",
      "Epoch 4: val_loss improved from 0.41527 to 0.31206, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7520 - loss: 0.4916 - val_accuracy: 0.9032 - val_loss: 0.3121 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7907 - loss: 0.4597\n",
      "Epoch 5: val_loss did not improve from 0.31206\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7906 - loss: 0.4597 - val_accuracy: 0.8145 - val_loss: 0.3662 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7998 - loss: 0.4547\n",
      "Epoch 6: val_loss did not improve from 0.31206\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7997 - loss: 0.4550 - val_accuracy: 0.8790 - val_loss: 0.3728 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8209 - loss: 0.4250\n",
      "Epoch 7: val_loss did not improve from 0.31206\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.8209 - loss: 0.4251 - val_accuracy: 0.7258 - val_loss: 0.4940 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7979 - loss: 0.4475\n",
      "Epoch 8: val_loss improved from 0.31206 to 0.28936, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7983 - loss: 0.4472 - val_accuracy: 0.9113 - val_loss: 0.2894 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8494 - loss: 0.4004\n",
      "Epoch 9: val_loss did not improve from 0.28936\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.8492 - loss: 0.4005 - val_accuracy: 0.8468 - val_loss: 0.3779 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8291 - loss: 0.4210\n",
      "Epoch 10: val_loss did not improve from 0.28936\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.8291 - loss: 0.4210 - val_accuracy: 0.9194 - val_loss: 0.3159 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8615 - loss: 0.3637\n",
      "Epoch 11: val_loss did not improve from 0.28936\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.8611 - loss: 0.3642 - val_accuracy: 0.9032 - val_loss: 0.3095 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8233 - loss: 0.4228\n",
      "Epoch 12: val_loss did not improve from 0.28936\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.8234 - loss: 0.4226 - val_accuracy: 0.8629 - val_loss: 0.2953 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8324 - loss: 0.4290\n",
      "Epoch 13: val_loss improved from 0.28936 to 0.28326, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.8326 - loss: 0.4285 - val_accuracy: 0.8871 - val_loss: 0.2833 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8701 - loss: 0.3511\n",
      "Epoch 14: val_loss did not improve from 0.28326\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8695 - loss: 0.3518 - val_accuracy: 0.8306 - val_loss: 0.3766 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8543 - loss: 0.3494\n",
      "Epoch 15: val_loss improved from 0.28326 to 0.28040, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.8540 - loss: 0.3501 - val_accuracy: 0.9113 - val_loss: 0.2804 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8653 - loss: 0.3615\n",
      "Epoch 16: val_loss did not improve from 0.28040\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8651 - loss: 0.3617 - val_accuracy: 0.8790 - val_loss: 0.3506 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8405 - loss: 0.3745\n",
      "Epoch 17: val_loss did not improve from 0.28040\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.8407 - loss: 0.3742 - val_accuracy: 0.9032 - val_loss: 0.2932 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8544 - loss: 0.3786\n",
      "Epoch 18: val_loss did not improve from 0.28040\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8544 - loss: 0.3784 - val_accuracy: 0.8871 - val_loss: 0.3076 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8805 - loss: 0.3329\n",
      "Epoch 19: val_loss did not improve from 0.28040\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8804 - loss: 0.3329 - val_accuracy: 0.8145 - val_loss: 0.4049 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8297 - loss: 0.3685\n",
      "Epoch 20: val_loss did not improve from 0.28040\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8299 - loss: 0.3684 - val_accuracy: 0.9032 - val_loss: 0.2864 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8751 - loss: 0.3229\n",
      "Epoch 21: val_loss improved from 0.28040 to 0.27794, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8752 - loss: 0.3227 - val_accuracy: 0.8871 - val_loss: 0.2779 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8505 - loss: 0.3400\n",
      "Epoch 22: val_loss did not improve from 0.27794\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8507 - loss: 0.3398 - val_accuracy: 0.8790 - val_loss: 0.3603 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8696 - loss: 0.3306\n",
      "Epoch 23: val_loss did not improve from 0.27794\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.8696 - loss: 0.3305 - val_accuracy: 0.8710 - val_loss: 0.2976 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8550 - loss: 0.3431\n",
      "Epoch 24: val_loss did not improve from 0.27794\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.8552 - loss: 0.3427 - val_accuracy: 0.8952 - val_loss: 0.3496 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8471 - loss: 0.3732\n",
      "Epoch 25: val_loss improved from 0.27794 to 0.26436, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.8473 - loss: 0.3726 - val_accuracy: 0.9113 - val_loss: 0.2644 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8740 - loss: 0.3246\n",
      "Epoch 26: val_loss did not improve from 0.26436\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8740 - loss: 0.3243 - val_accuracy: 0.8952 - val_loss: 0.2662 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8329 - loss: 0.3586\n",
      "Epoch 27: val_loss improved from 0.26436 to 0.26406, saving model to results\\VGG16_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.8336 - loss: 0.3579 - val_accuracy: 0.9032 - val_loss: 0.2641 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8870 - loss: 0.3062\n",
      "Epoch 28: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8869 - loss: 0.3063 - val_accuracy: 0.8952 - val_loss: 0.2703 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8652 - loss: 0.3315\n",
      "Epoch 29: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8654 - loss: 0.3314 - val_accuracy: 0.8952 - val_loss: 0.2945 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8753 - loss: 0.3158\n",
      "Epoch 30: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8754 - loss: 0.3155 - val_accuracy: 0.9113 - val_loss: 0.2726 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8678 - loss: 0.3271\n",
      "Epoch 31: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8678 - loss: 0.3269 - val_accuracy: 0.9113 - val_loss: 0.2659 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8887 - loss: 0.2844\n",
      "Epoch 32: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.8885 - loss: 0.2847 - val_accuracy: 0.8952 - val_loss: 0.3082 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9069 - loss: 0.2442\n",
      "Epoch 33: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9066 - loss: 0.2448 - val_accuracy: 0.8790 - val_loss: 0.2806 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8665 - loss: 0.3215\n",
      "Epoch 34: val_loss did not improve from 0.26406\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8665 - loss: 0.3213 - val_accuracy: 0.8871 - val_loss: 0.2720 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9109 - loss: 0.2338\n",
      "Epoch 35: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9107 - loss: 0.2341 - val_accuracy: 0.8952 - val_loss: 0.2770 - learning_rate: 2.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9090 - loss: 0.2527\n",
      "Epoch 36: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9090 - loss: 0.2527 - val_accuracy: 0.8871 - val_loss: 0.3103 - learning_rate: 2.0000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9086 - loss: 0.2298\n",
      "Epoch 37: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.9086 - loss: 0.2299 - val_accuracy: 0.8871 - val_loss: 0.2877 - learning_rate: 2.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9239 - loss: 0.2144\n",
      "Epoch 38: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9238 - loss: 0.2148 - val_accuracy: 0.8952 - val_loss: 0.2841 - learning_rate: 2.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9054 - loss: 0.2438\n",
      "Epoch 39: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9052 - loss: 0.2439 - val_accuracy: 0.8952 - val_loss: 0.2981 - learning_rate: 2.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9075 - loss: 0.2422\n",
      "Epoch 40: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9073 - loss: 0.2424 - val_accuracy: 0.8871 - val_loss: 0.2920 - learning_rate: 2.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9209 - loss: 0.2433\n",
      "Epoch 41: val_loss did not improve from 0.26406\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.9209 - loss: 0.2430 - val_accuracy: 0.8871 - val_loss: 0.3119 - learning_rate: 2.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9170 - loss: 0.2069\n",
      "Epoch 42: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.9170 - loss: 0.2070 - val_accuracy: 0.8952 - val_loss: 0.3129 - learning_rate: 4.0000e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9177 - loss: 0.2001\n",
      "Epoch 43: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9176 - loss: 0.2004 - val_accuracy: 0.9032 - val_loss: 0.3134 - learning_rate: 4.0000e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8988 - loss: 0.2323\n",
      "Epoch 44: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.8989 - loss: 0.2321 - val_accuracy: 0.8952 - val_loss: 0.3045 - learning_rate: 4.0000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9202 - loss: 0.2075\n",
      "Epoch 45: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.9201 - loss: 0.2077 - val_accuracy: 0.9032 - val_loss: 0.3199 - learning_rate: 4.0000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8945 - loss: 0.2865\n",
      "Epoch 46: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.8948 - loss: 0.2854 - val_accuracy: 0.8952 - val_loss: 0.3140 - learning_rate: 4.0000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9252 - loss: 0.1821\n",
      "Epoch 47: val_loss did not improve from 0.26406\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9252 - loss: 0.1824 - val_accuracy: 0.9032 - val_loss: 0.3182 - learning_rate: 4.0000e-06\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG16_from_scratch_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 751ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.86      0.90      0.88       103\n",
      "Shoot and Fruit Borer       0.93      0.90      0.91       145\n",
      "\n",
      "             accuracy                           0.90       248\n",
      "            macro avg       0.89      0.90      0.90       248\n",
      "         weighted avg       0.90      0.90      0.90       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG16_from_scratch_bs16 is complete. Total time: 01:09:54 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG16\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f00682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG16_transfer_learning_bs16 ---\n",
      "Mode: transfer_learning, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 435ms/step - accuracy: 0.4924 - loss: 1.0555 - val_accuracy: 0.4113 - val_loss: 0.8182\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.5290 - loss: 0.9395 - val_accuracy: 0.3871 - val_loss: 0.7613\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.4750 - loss: 1.0172 - val_accuracy: 0.4516 - val_loss: 0.7235\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.4841 - loss: 0.9584 - val_accuracy: 0.4839 - val_loss: 0.7008\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - accuracy: 0.4888 - loss: 0.8865 - val_accuracy: 0.5645 - val_loss: 0.6854\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.5414 - loss: 0.8160 - val_accuracy: 0.6210 - val_loss: 0.6728\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.5609 - loss: 0.7609 - val_accuracy: 0.6371 - val_loss: 0.6587\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.5409 - loss: 0.7876 - val_accuracy: 0.7097 - val_loss: 0.6442\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.5176 - loss: 0.7898 - val_accuracy: 0.7339 - val_loss: 0.6334\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.5626 - loss: 0.7227 - val_accuracy: 0.7500 - val_loss: 0.6219\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.5736 - loss: 0.7277 - val_accuracy: 0.7742 - val_loss: 0.6098\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.5782 - loss: 0.6839 - val_accuracy: 0.7581 - val_loss: 0.6031\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.5754 - loss: 0.6971 - val_accuracy: 0.7903 - val_loss: 0.5919\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.6291 - loss: 0.6408 - val_accuracy: 0.7903 - val_loss: 0.5832\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 445ms/step - accuracy: 0.6050 - loss: 0.6544 - val_accuracy: 0.7823 - val_loss: 0.5794\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.6032 - loss: 0.6508 - val_accuracy: 0.8065 - val_loss: 0.5713\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.6477 - loss: 0.6108 - val_accuracy: 0.8226 - val_loss: 0.5607\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.6532 - loss: 0.6170 - val_accuracy: 0.8306 - val_loss: 0.5542\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 446ms/step - accuracy: 0.6877 - loss: 0.5965 - val_accuracy: 0.8387 - val_loss: 0.5472\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 446ms/step - accuracy: 0.6423 - loss: 0.6156 - val_accuracy: 0.8387 - val_loss: 0.5411\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 451ms/step - accuracy: 0.7260 - loss: 0.5585 - val_accuracy: 0.8387 - val_loss: 0.5345\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7330 - loss: 0.5624 - val_accuracy: 0.8468 - val_loss: 0.5268\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7284 - loss: 0.5618 - val_accuracy: 0.8710 - val_loss: 0.5186\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7240 - loss: 0.5629 - val_accuracy: 0.8710 - val_loss: 0.5124\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.6929 - loss: 0.5782 - val_accuracy: 0.8790 - val_loss: 0.5075\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.7194 - loss: 0.5563 - val_accuracy: 0.8548 - val_loss: 0.5049\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7337 - loss: 0.5446 - val_accuracy: 0.8871 - val_loss: 0.4975\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7468 - loss: 0.5348 - val_accuracy: 0.8871 - val_loss: 0.4926\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.7617 - loss: 0.5387 - val_accuracy: 0.8790 - val_loss: 0.4882\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 487ms/step - accuracy: 0.7711 - loss: 0.5297 - val_accuracy: 0.8790 - val_loss: 0.4839\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.7568 - loss: 0.5292 - val_accuracy: 0.8790 - val_loss: 0.4781\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - accuracy: 0.7386 - loss: 0.5234 - val_accuracy: 0.8710 - val_loss: 0.4730\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.7633 - loss: 0.5281 - val_accuracy: 0.8790 - val_loss: 0.4703\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 453ms/step - accuracy: 0.7950 - loss: 0.4961 - val_accuracy: 0.8790 - val_loss: 0.4668\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.7518 - loss: 0.5216 - val_accuracy: 0.8790 - val_loss: 0.4636\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 446ms/step - accuracy: 0.7742 - loss: 0.5004 - val_accuracy: 0.8790 - val_loss: 0.4588\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 442ms/step - accuracy: 0.7809 - loss: 0.5055 - val_accuracy: 0.8710 - val_loss: 0.4530\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7663 - loss: 0.5025 - val_accuracy: 0.8790 - val_loss: 0.4515\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7814 - loss: 0.5000 - val_accuracy: 0.8710 - val_loss: 0.4467\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.7674 - loss: 0.5110 - val_accuracy: 0.8790 - val_loss: 0.4439\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.7741 - loss: 0.4919 - val_accuracy: 0.8790 - val_loss: 0.4378\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.7756 - loss: 0.4978 - val_accuracy: 0.8710 - val_loss: 0.4364\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - accuracy: 0.7989 - loss: 0.4637 - val_accuracy: 0.8871 - val_loss: 0.4350\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 446ms/step - accuracy: 0.8033 - loss: 0.4694 - val_accuracy: 0.8790 - val_loss: 0.4308\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 442ms/step - accuracy: 0.7926 - loss: 0.4966 - val_accuracy: 0.8871 - val_loss: 0.4285\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 442ms/step - accuracy: 0.8215 - loss: 0.4565 - val_accuracy: 0.8790 - val_loss: 0.4237\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 445ms/step - accuracy: 0.8013 - loss: 0.4790 - val_accuracy: 0.8790 - val_loss: 0.4205\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - accuracy: 0.8016 - loss: 0.4717 - val_accuracy: 0.8871 - val_loss: 0.4180\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 444ms/step - accuracy: 0.8020 - loss: 0.4675 - val_accuracy: 0.8871 - val_loss: 0.4170\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 446ms/step - accuracy: 0.7891 - loss: 0.4818 - val_accuracy: 0.8871 - val_loss: 0.4149\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG16_transfer_learning_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 751ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.81      0.89      0.85       103\n",
      "Shoot and Fruit Borer       0.92      0.86      0.89       145\n",
      "\n",
      "             accuracy                           0.87       248\n",
      "            macro avg       0.87      0.87      0.87       248\n",
      "         weighted avg       0.88      0.87      0.87       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG16_transfer_learning_bs16 is complete. Total time: 00:23:49 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG16\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "317ef3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG16_fine_tune_bs16 ---\n",
      "Mode: fine_tune, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 458ms/step - accuracy: 0.4823 - loss: 0.8056 - val_accuracy: 0.4274 - val_loss: 0.7429\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.4819 - loss: 0.7636 - val_accuracy: 0.4597 - val_loss: 0.7070\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 470ms/step - accuracy: 0.4947 - loss: 0.7420 - val_accuracy: 0.5403 - val_loss: 0.6866\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.4888 - loss: 0.7373 - val_accuracy: 0.6129 - val_loss: 0.6689\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - accuracy: 0.5132 - loss: 0.7132 - val_accuracy: 0.6532 - val_loss: 0.6603\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.4928 - loss: 0.7093 - val_accuracy: 0.7097 - val_loss: 0.6492\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.5660 - loss: 0.6922 - val_accuracy: 0.7742 - val_loss: 0.6339\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.5906 - loss: 0.6701 - val_accuracy: 0.7903 - val_loss: 0.6248\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.6107 - loss: 0.6574 - val_accuracy: 0.7903 - val_loss: 0.6122\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.6322 - loss: 0.6491 - val_accuracy: 0.7903 - val_loss: 0.6048\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 467ms/step - accuracy: 0.6523 - loss: 0.6445 - val_accuracy: 0.8065 - val_loss: 0.5975\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.6346 - loss: 0.6353 - val_accuracy: 0.8145 - val_loss: 0.5850\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 467ms/step - accuracy: 0.6574 - loss: 0.6333 - val_accuracy: 0.8226 - val_loss: 0.5780\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 461ms/step - accuracy: 0.6646 - loss: 0.6191 - val_accuracy: 0.8306 - val_loss: 0.5689\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.6918 - loss: 0.6115 - val_accuracy: 0.8468 - val_loss: 0.5611\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.6775 - loss: 0.6159 - val_accuracy: 0.8306 - val_loss: 0.5508\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.6853 - loss: 0.5949 - val_accuracy: 0.8548 - val_loss: 0.5483\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 461ms/step - accuracy: 0.6864 - loss: 0.6071 - val_accuracy: 0.8548 - val_loss: 0.5418\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7230 - loss: 0.5832 - val_accuracy: 0.8548 - val_loss: 0.5343\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7193 - loss: 0.5812 - val_accuracy: 0.8629 - val_loss: 0.5269\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.7108 - loss: 0.5797 - val_accuracy: 0.8548 - val_loss: 0.5226\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7575 - loss: 0.5575 - val_accuracy: 0.8629 - val_loss: 0.5153\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - accuracy: 0.7550 - loss: 0.5607 - val_accuracy: 0.8629 - val_loss: 0.5094\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.7555 - loss: 0.5492 - val_accuracy: 0.8629 - val_loss: 0.5036\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.7719 - loss: 0.5380 - val_accuracy: 0.8710 - val_loss: 0.4970\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7694 - loss: 0.5394 - val_accuracy: 0.8548 - val_loss: 0.4958\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.7663 - loss: 0.5409 - val_accuracy: 0.8710 - val_loss: 0.4893\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 461ms/step - accuracy: 0.7566 - loss: 0.5371 - val_accuracy: 0.8710 - val_loss: 0.4851\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7882 - loss: 0.5326 - val_accuracy: 0.8710 - val_loss: 0.4800\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7494 - loss: 0.5397 - val_accuracy: 0.8790 - val_loss: 0.4736\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - accuracy: 0.7658 - loss: 0.5186 - val_accuracy: 0.8790 - val_loss: 0.4706\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - accuracy: 0.7581 - loss: 0.5214 - val_accuracy: 0.8790 - val_loss: 0.4661\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 471ms/step - accuracy: 0.7978 - loss: 0.5025 - val_accuracy: 0.8871 - val_loss: 0.4631\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.7762 - loss: 0.5112 - val_accuracy: 0.8871 - val_loss: 0.4588\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 468ms/step - accuracy: 0.7813 - loss: 0.5031 - val_accuracy: 0.8871 - val_loss: 0.4549\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7642 - loss: 0.5135 - val_accuracy: 0.8871 - val_loss: 0.4514\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - accuracy: 0.7722 - loss: 0.5125 - val_accuracy: 0.8871 - val_loss: 0.4471\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.7890 - loss: 0.5054 - val_accuracy: 0.8871 - val_loss: 0.4443\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7725 - loss: 0.5059 - val_accuracy: 0.8871 - val_loss: 0.4407\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - accuracy: 0.8040 - loss: 0.4787 - val_accuracy: 0.8871 - val_loss: 0.4365\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 467ms/step - accuracy: 0.8026 - loss: 0.4944 - val_accuracy: 0.8790 - val_loss: 0.4350\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.7850 - loss: 0.4950 - val_accuracy: 0.8871 - val_loss: 0.4322\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 467ms/step - accuracy: 0.8133 - loss: 0.4818 - val_accuracy: 0.8871 - val_loss: 0.4290\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.7963 - loss: 0.4850 - val_accuracy: 0.8790 - val_loss: 0.4266\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.8044 - loss: 0.4712 - val_accuracy: 0.8710 - val_loss: 0.4224\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7865 - loss: 0.4878 - val_accuracy: 0.8871 - val_loss: 0.4199\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.7832 - loss: 0.4790 - val_accuracy: 0.8871 - val_loss: 0.4176\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.8182 - loss: 0.4652 - val_accuracy: 0.8871 - val_loss: 0.4149\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 461ms/step - accuracy: 0.8229 - loss: 0.4630 - val_accuracy: 0.8871 - val_loss: 0.4135\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - accuracy: 0.8001 - loss: 0.4798 - val_accuracy: 0.8871 - val_loss: 0.4100\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG16_fine_tune_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 744ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.81      0.86      0.84       103\n",
      "Shoot and Fruit Borer       0.90      0.86      0.88       145\n",
      "\n",
      "             accuracy                           0.86       248\n",
      "            macro avg       0.85      0.86      0.86       248\n",
      "         weighted avg       0.86      0.86      0.86       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG16_fine_tune_bs16 is complete. Total time: 00:24:44 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG16\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcaba98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG16_full_monty_bs16 ---\n",
      "Mode: full_monty, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5181 - loss: 0.9954\n",
      "Epoch 1: val_loss improved from inf to 0.69489, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 446ms/step - accuracy: 0.5178 - loss: 0.9951 - val_accuracy: 0.5887 - val_loss: 0.6949 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.4656 - loss: 0.9078\n",
      "Epoch 2: val_loss improved from 0.69489 to 0.67227, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.4660 - loss: 0.9071 - val_accuracy: 0.5806 - val_loss: 0.6723 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.5207 - loss: 0.7981\n",
      "Epoch 3: val_loss did not improve from 0.67227\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 454ms/step - accuracy: 0.5205 - loss: 0.7980 - val_accuracy: 0.5484 - val_loss: 0.6758 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.4979 - loss: 0.7650\n",
      "Epoch 4: val_loss did not improve from 0.67227\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 466ms/step - accuracy: 0.4982 - loss: 0.7646 - val_accuracy: 0.5887 - val_loss: 0.6745 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.5425 - loss: 0.7318\n",
      "Epoch 5: val_loss improved from 0.67227 to 0.67204, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.5424 - loss: 0.7320 - val_accuracy: 0.5887 - val_loss: 0.6720 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.5068 - loss: 0.7389\n",
      "Epoch 6: val_loss improved from 0.67204 to 0.66385, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.5069 - loss: 0.7387 - val_accuracy: 0.6371 - val_loss: 0.6639 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.5066 - loss: 0.7423\n",
      "Epoch 7: val_loss improved from 0.66385 to 0.64806, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.5069 - loss: 0.7421 - val_accuracy: 0.6613 - val_loss: 0.6481 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.5522 - loss: 0.7035\n",
      "Epoch 8: val_loss improved from 0.64806 to 0.63876, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.5521 - loss: 0.7035 - val_accuracy: 0.6855 - val_loss: 0.6388 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.5591 - loss: 0.6920\n",
      "Epoch 9: val_loss improved from 0.63876 to 0.63195, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.5592 - loss: 0.6918 - val_accuracy: 0.6855 - val_loss: 0.6319 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.5900 - loss: 0.6750\n",
      "Epoch 10: val_loss improved from 0.63195 to 0.62065, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.5902 - loss: 0.6748 - val_accuracy: 0.7419 - val_loss: 0.6206 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.5866 - loss: 0.6635\n",
      "Epoch 11: val_loss improved from 0.62065 to 0.60896, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.5868 - loss: 0.6634 - val_accuracy: 0.7581 - val_loss: 0.6090 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.5803 - loss: 0.6423\n",
      "Epoch 12: val_loss improved from 0.60896 to 0.60622, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.5807 - loss: 0.6423 - val_accuracy: 0.7500 - val_loss: 0.6062 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.6191 - loss: 0.6583\n",
      "Epoch 13: val_loss improved from 0.60622 to 0.59191, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.6197 - loss: 0.6580 - val_accuracy: 0.7742 - val_loss: 0.5919 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.6512 - loss: 0.6312\n",
      "Epoch 14: val_loss improved from 0.59191 to 0.58714, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.6511 - loss: 0.6311 - val_accuracy: 0.7742 - val_loss: 0.5871 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.6965 - loss: 0.6031\n",
      "Epoch 15: val_loss improved from 0.58714 to 0.57316, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 465ms/step - accuracy: 0.6962 - loss: 0.6032 - val_accuracy: 0.8065 - val_loss: 0.5732 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.6788 - loss: 0.6052\n",
      "Epoch 16: val_loss improved from 0.57316 to 0.56626, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 458ms/step - accuracy: 0.6789 - loss: 0.6051 - val_accuracy: 0.8065 - val_loss: 0.5663 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.7061 - loss: 0.5963\n",
      "Epoch 17: val_loss improved from 0.56626 to 0.56175, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 458ms/step - accuracy: 0.7060 - loss: 0.5963 - val_accuracy: 0.8065 - val_loss: 0.5618 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.6568 - loss: 0.6112\n",
      "Epoch 18: val_loss improved from 0.56175 to 0.55183, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.6573 - loss: 0.6110 - val_accuracy: 0.8145 - val_loss: 0.5518 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.7281 - loss: 0.5768\n",
      "Epoch 19: val_loss improved from 0.55183 to 0.54937, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 464ms/step - accuracy: 0.7282 - loss: 0.5767 - val_accuracy: 0.8065 - val_loss: 0.5494 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7279 - loss: 0.5640\n",
      "Epoch 20: val_loss improved from 0.54937 to 0.54098, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 458ms/step - accuracy: 0.7279 - loss: 0.5641 - val_accuracy: 0.8145 - val_loss: 0.5410 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7237 - loss: 0.5632\n",
      "Epoch 21: val_loss improved from 0.54098 to 0.53429, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.7235 - loss: 0.5633 - val_accuracy: 0.8226 - val_loss: 0.5343 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7491 - loss: 0.5548\n",
      "Epoch 22: val_loss improved from 0.53429 to 0.52771, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 458ms/step - accuracy: 0.7489 - loss: 0.5549 - val_accuracy: 0.8306 - val_loss: 0.5277 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7396 - loss: 0.5563\n",
      "Epoch 23: val_loss improved from 0.52771 to 0.52026, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.7395 - loss: 0.5563 - val_accuracy: 0.8387 - val_loss: 0.5203 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.7419 - loss: 0.5667\n",
      "Epoch 24: val_loss improved from 0.52026 to 0.51676, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 461ms/step - accuracy: 0.7419 - loss: 0.5666 - val_accuracy: 0.8387 - val_loss: 0.5168 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.7570 - loss: 0.5482\n",
      "Epoch 25: val_loss improved from 0.51676 to 0.50994, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 462ms/step - accuracy: 0.7570 - loss: 0.5482 - val_accuracy: 0.8387 - val_loss: 0.5099 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.7350 - loss: 0.5558\n",
      "Epoch 26: val_loss improved from 0.50994 to 0.50712, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.7354 - loss: 0.5556 - val_accuracy: 0.8387 - val_loss: 0.5071 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7705 - loss: 0.5265\n",
      "Epoch 27: val_loss improved from 0.50712 to 0.50124, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.7702 - loss: 0.5268 - val_accuracy: 0.8387 - val_loss: 0.5012 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.7884 - loss: 0.5304\n",
      "Epoch 28: val_loss improved from 0.50124 to 0.49366, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 456ms/step - accuracy: 0.7884 - loss: 0.5304 - val_accuracy: 0.8387 - val_loss: 0.4937 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.7570 - loss: 0.5314\n",
      "Epoch 29: val_loss improved from 0.49366 to 0.49032, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.7570 - loss: 0.5313 - val_accuracy: 0.8387 - val_loss: 0.4903 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7795 - loss: 0.5105\n",
      "Epoch 30: val_loss improved from 0.49032 to 0.48522, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.7795 - loss: 0.5106 - val_accuracy: 0.8387 - val_loss: 0.4852 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7763 - loss: 0.5287\n",
      "Epoch 31: val_loss improved from 0.48522 to 0.48108, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 458ms/step - accuracy: 0.7763 - loss: 0.5286 - val_accuracy: 0.8387 - val_loss: 0.4811 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.7849 - loss: 0.5220\n",
      "Epoch 32: val_loss improved from 0.48108 to 0.47796, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 456ms/step - accuracy: 0.7848 - loss: 0.5220 - val_accuracy: 0.8387 - val_loss: 0.4780 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.8064 - loss: 0.5076\n",
      "Epoch 33: val_loss improved from 0.47796 to 0.47077, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 461ms/step - accuracy: 0.8061 - loss: 0.5076 - val_accuracy: 0.8468 - val_loss: 0.4708 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7758 - loss: 0.5142\n",
      "Epoch 34: val_loss improved from 0.47077 to 0.46482, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.7760 - loss: 0.5141 - val_accuracy: 0.8468 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.7972 - loss: 0.4875\n",
      "Epoch 35: val_loss improved from 0.46482 to 0.46103, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.7972 - loss: 0.4877 - val_accuracy: 0.8468 - val_loss: 0.4610 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7860 - loss: 0.5171\n",
      "Epoch 36: val_loss improved from 0.46103 to 0.45937, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 460ms/step - accuracy: 0.7861 - loss: 0.5169 - val_accuracy: 0.8468 - val_loss: 0.4594 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7807 - loss: 0.5098\n",
      "Epoch 37: val_loss improved from 0.45937 to 0.45576, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.7809 - loss: 0.5096 - val_accuracy: 0.8468 - val_loss: 0.4558 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.8086 - loss: 0.4795\n",
      "Epoch 38: val_loss improved from 0.45576 to 0.45307, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.8084 - loss: 0.4796 - val_accuracy: 0.8468 - val_loss: 0.4531 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.7912 - loss: 0.4890\n",
      "Epoch 39: val_loss improved from 0.45307 to 0.44882, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 463ms/step - accuracy: 0.7912 - loss: 0.4889 - val_accuracy: 0.8548 - val_loss: 0.4488 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.8051 - loss: 0.5012\n",
      "Epoch 40: val_loss improved from 0.44882 to 0.44565, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 461ms/step - accuracy: 0.8049 - loss: 0.5010 - val_accuracy: 0.8548 - val_loss: 0.4456 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.8256 - loss: 0.4760\n",
      "Epoch 41: val_loss improved from 0.44565 to 0.44031, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 459ms/step - accuracy: 0.8255 - loss: 0.4760 - val_accuracy: 0.8710 - val_loss: 0.4403 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.7887 - loss: 0.4948\n",
      "Epoch 42: val_loss improved from 0.44031 to 0.43561, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 456ms/step - accuracy: 0.7887 - loss: 0.4948 - val_accuracy: 0.8790 - val_loss: 0.4356 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.7909 - loss: 0.4785\n",
      "Epoch 43: val_loss improved from 0.43561 to 0.43333, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 461ms/step - accuracy: 0.7909 - loss: 0.4786 - val_accuracy: 0.8790 - val_loss: 0.4333 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.8066 - loss: 0.4838\n",
      "Epoch 44: val_loss improved from 0.43333 to 0.42893, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 462ms/step - accuracy: 0.8067 - loss: 0.4838 - val_accuracy: 0.8790 - val_loss: 0.4289 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.8298 - loss: 0.4520\n",
      "Epoch 45: val_loss improved from 0.42893 to 0.42622, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.8295 - loss: 0.4523 - val_accuracy: 0.8710 - val_loss: 0.4262 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.8121 - loss: 0.4929\n",
      "Epoch 46: val_loss improved from 0.42622 to 0.42434, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.8121 - loss: 0.4928 - val_accuracy: 0.8790 - val_loss: 0.4243 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7964 - loss: 0.4711\n",
      "Epoch 47: val_loss improved from 0.42434 to 0.42426, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 460ms/step - accuracy: 0.7963 - loss: 0.4712 - val_accuracy: 0.8710 - val_loss: 0.4243 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.8071 - loss: 0.4637\n",
      "Epoch 48: val_loss improved from 0.42426 to 0.42036, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 455ms/step - accuracy: 0.8071 - loss: 0.4637 - val_accuracy: 0.8710 - val_loss: 0.4204 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.8141 - loss: 0.4588\n",
      "Epoch 49: val_loss improved from 0.42036 to 0.41589, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 461ms/step - accuracy: 0.8141 - loss: 0.4588 - val_accuracy: 0.8790 - val_loss: 0.4159 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.8233 - loss: 0.4480\n",
      "Epoch 50: val_loss improved from 0.41589 to 0.41290, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.8233 - loss: 0.4481 - val_accuracy: 0.8790 - val_loss: 0.4129 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 51/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - accuracy: 0.8593 - loss: 0.3760\n",
      "Epoch 51: val_loss improved from 0.41290 to 0.17015, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 809ms/step - accuracy: 0.8596 - loss: 0.3752 - val_accuracy: 0.9435 - val_loss: 0.1702 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.9188 - loss: 0.2408\n",
      "Epoch 52: val_loss improved from 0.17015 to 0.12951, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 816ms/step - accuracy: 0.9189 - loss: 0.2403 - val_accuracy: 0.9435 - val_loss: 0.1295 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.9392 - loss: 0.1654\n",
      "Epoch 53: val_loss improved from 0.12951 to 0.09916, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 812ms/step - accuracy: 0.9393 - loss: 0.1653 - val_accuracy: 0.9597 - val_loss: 0.0992 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.9652 - loss: 0.1146\n",
      "Epoch 54: val_loss improved from 0.09916 to 0.09601, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 815ms/step - accuracy: 0.9652 - loss: 0.1145 - val_accuracy: 0.9597 - val_loss: 0.0960 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - accuracy: 0.9617 - loss: 0.1199\n",
      "Epoch 55: val_loss improved from 0.09601 to 0.09250, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 810ms/step - accuracy: 0.9618 - loss: 0.1198 - val_accuracy: 0.9516 - val_loss: 0.0925 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - accuracy: 0.9526 - loss: 0.1047\n",
      "Epoch 56: val_loss improved from 0.09250 to 0.07885, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 807ms/step - accuracy: 0.9527 - loss: 0.1045 - val_accuracy: 0.9597 - val_loss: 0.0788 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - accuracy: 0.9595 - loss: 0.0894\n",
      "Epoch 57: val_loss did not improve from 0.07885\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 796ms/step - accuracy: 0.9595 - loss: 0.0894 - val_accuracy: 0.9597 - val_loss: 0.0967 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - accuracy: 0.9779 - loss: 0.0657\n",
      "Epoch 58: val_loss did not improve from 0.07885\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 805ms/step - accuracy: 0.9779 - loss: 0.0658 - val_accuracy: 0.9274 - val_loss: 0.2615 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - accuracy: 0.9729 - loss: 0.0823\n",
      "Epoch 59: val_loss improved from 0.07885 to 0.07495, saving model to results\\VGG16_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 817ms/step - accuracy: 0.9729 - loss: 0.0822 - val_accuracy: 0.9597 - val_loss: 0.0749 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - accuracy: 0.9844 - loss: 0.0533\n",
      "Epoch 60: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 796ms/step - accuracy: 0.9844 - loss: 0.0533 - val_accuracy: 0.9516 - val_loss: 0.1055 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.9828 - loss: 0.0580\n",
      "Epoch 61: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 805ms/step - accuracy: 0.9828 - loss: 0.0579 - val_accuracy: 0.9597 - val_loss: 0.0812 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - accuracy: 0.9913 - loss: 0.0367\n",
      "Epoch 62: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 800ms/step - accuracy: 0.9913 - loss: 0.0367 - val_accuracy: 0.9677 - val_loss: 0.1251 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.9765 - loss: 0.0563\n",
      "Epoch 63: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 801ms/step - accuracy: 0.9765 - loss: 0.0564 - val_accuracy: 0.9677 - val_loss: 0.0819 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - accuracy: 0.9864 - loss: 0.0444\n",
      "Epoch 64: val_loss did not improve from 0.07495\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 805ms/step - accuracy: 0.9864 - loss: 0.0443 - val_accuracy: 0.9597 - val_loss: 0.1179 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9848 - loss: 0.0286\n",
      "Epoch 65: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 806ms/step - accuracy: 0.9848 - loss: 0.0288 - val_accuracy: 0.9516 - val_loss: 0.1132 - learning_rate: 2.0000e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - accuracy: 0.9880 - loss: 0.0274\n",
      "Epoch 66: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 800ms/step - accuracy: 0.9880 - loss: 0.0273 - val_accuracy: 0.9516 - val_loss: 0.1291 - learning_rate: 2.0000e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.9906 - loss: 0.0297\n",
      "Epoch 67: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 803ms/step - accuracy: 0.9906 - loss: 0.0297 - val_accuracy: 0.9516 - val_loss: 0.1120 - learning_rate: 2.0000e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - accuracy: 0.9876 - loss: 0.0274\n",
      "Epoch 68: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 799ms/step - accuracy: 0.9876 - loss: 0.0275 - val_accuracy: 0.9516 - val_loss: 0.1118 - learning_rate: 2.0000e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.9907 - loss: 0.0235\n",
      "Epoch 69: val_loss did not improve from 0.07495\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 806ms/step - accuracy: 0.9908 - loss: 0.0234 - val_accuracy: 0.9597 - val_loss: 0.1225 - learning_rate: 2.0000e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.9884 - loss: 0.0297\n",
      "Epoch 70: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 804ms/step - accuracy: 0.9885 - loss: 0.0296 - val_accuracy: 0.9516 - val_loss: 0.1121 - learning_rate: 4.0000e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765ms/step - accuracy: 0.9953 - loss: 0.0153\n",
      "Epoch 71: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 818ms/step - accuracy: 0.9953 - loss: 0.0153 - val_accuracy: 0.9516 - val_loss: 0.1114 - learning_rate: 4.0000e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.9937 - loss: 0.0184\n",
      "Epoch 72: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 827ms/step - accuracy: 0.9936 - loss: 0.0184 - val_accuracy: 0.9516 - val_loss: 0.1086 - learning_rate: 4.0000e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.9947 - loss: 0.0188\n",
      "Epoch 73: val_loss did not improve from 0.07495\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 804ms/step - accuracy: 0.9947 - loss: 0.0188 - val_accuracy: 0.9516 - val_loss: 0.1144 - learning_rate: 4.0000e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.9877 - loss: 0.0248\n",
      "Epoch 74: val_loss did not improve from 0.07495\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 802ms/step - accuracy: 0.9877 - loss: 0.0248 - val_accuracy: 0.9516 - val_loss: 0.1115 - learning_rate: 4.0000e-07\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG16_full_monty_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 722ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.97      0.97      0.97       103\n",
      "Shoot and Fruit Borer       0.98      0.98      0.98       145\n",
      "\n",
      "             accuracy                           0.98       248\n",
      "            macro avg       0.98      0.98      0.98       248\n",
      "         weighted avg       0.98      0.98      0.98       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG16_full_monty_bs16 is complete. Total time: 00:45:12 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG16\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa411ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG19_from_scratch_bs16 ---\n",
      "Mode: from_scratch, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5156 - loss: 0.6945\n",
      "Epoch 1: val_loss improved from inf to 0.62500, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.5156 - loss: 0.6945 - val_accuracy: 0.6371 - val_loss: 0.6250 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5495 - loss: 0.6900\n",
      "Epoch 2: val_loss improved from 0.62500 to 0.58716, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.5500 - loss: 0.6896 - val_accuracy: 0.6532 - val_loss: 0.5872 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6631 - loss: 0.6653\n",
      "Epoch 3: val_loss improved from 0.58716 to 0.54398, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.6631 - loss: 0.6646 - val_accuracy: 0.7097 - val_loss: 0.5440 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6736 - loss: 0.6018\n",
      "Epoch 4: val_loss improved from 0.54398 to 0.45482, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.6738 - loss: 0.6017 - val_accuracy: 0.8306 - val_loss: 0.4548 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7345 - loss: 0.5617\n",
      "Epoch 5: val_loss did not improve from 0.45482\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.7347 - loss: 0.5613 - val_accuracy: 0.7661 - val_loss: 0.4821 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7525 - loss: 0.5355\n",
      "Epoch 6: val_loss improved from 0.45482 to 0.34735, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.7526 - loss: 0.5353 - val_accuracy: 0.8710 - val_loss: 0.3474 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7859 - loss: 0.4803\n",
      "Epoch 7: val_loss did not improve from 0.34735\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.7854 - loss: 0.4807 - val_accuracy: 0.6452 - val_loss: 0.5934 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7573 - loss: 0.5184\n",
      "Epoch 8: val_loss did not improve from 0.34735\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.7577 - loss: 0.5180 - val_accuracy: 0.8306 - val_loss: 0.3810 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8072 - loss: 0.4460\n",
      "Epoch 9: val_loss did not improve from 0.34735\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.8069 - loss: 0.4463 - val_accuracy: 0.8306 - val_loss: 0.4229 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8021 - loss: 0.4471\n",
      "Epoch 10: val_loss improved from 0.34735 to 0.30237, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.8022 - loss: 0.4470 - val_accuracy: 0.8952 - val_loss: 0.3024 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8216 - loss: 0.4329\n",
      "Epoch 11: val_loss did not improve from 0.30237\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8217 - loss: 0.4325 - val_accuracy: 0.7742 - val_loss: 0.4514 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8374 - loss: 0.4066\n",
      "Epoch 12: val_loss did not improve from 0.30237\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8372 - loss: 0.4069 - val_accuracy: 0.9113 - val_loss: 0.3180 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8561 - loss: 0.3579\n",
      "Epoch 13: val_loss did not improve from 0.30237\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8560 - loss: 0.3580 - val_accuracy: 0.8952 - val_loss: 0.3309 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8610 - loss: 0.3747\n",
      "Epoch 14: val_loss improved from 0.30237 to 0.28163, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.8608 - loss: 0.3748 - val_accuracy: 0.8952 - val_loss: 0.2816 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8217 - loss: 0.4064\n",
      "Epoch 15: val_loss did not improve from 0.28163\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8219 - loss: 0.4064 - val_accuracy: 0.9194 - val_loss: 0.2908 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8235 - loss: 0.4121\n",
      "Epoch 16: val_loss improved from 0.28163 to 0.26461, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.8237 - loss: 0.4118 - val_accuracy: 0.9032 - val_loss: 0.2646 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8549 - loss: 0.3674\n",
      "Epoch 17: val_loss did not improve from 0.26461\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8549 - loss: 0.3675 - val_accuracy: 0.9032 - val_loss: 0.3457 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8290 - loss: 0.4181\n",
      "Epoch 18: val_loss did not improve from 0.26461\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8293 - loss: 0.4176 - val_accuracy: 0.9113 - val_loss: 0.2864 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8326 - loss: 0.3976\n",
      "Epoch 19: val_loss did not improve from 0.26461\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8328 - loss: 0.3971 - val_accuracy: 0.9113 - val_loss: 0.2829 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8633 - loss: 0.3630\n",
      "Epoch 20: val_loss did not improve from 0.26461\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8634 - loss: 0.3627 - val_accuracy: 0.9194 - val_loss: 0.2785 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8427 - loss: 0.4213\n",
      "Epoch 21: val_loss did not improve from 0.26461\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8428 - loss: 0.4211 - val_accuracy: 0.8548 - val_loss: 0.3887 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8615 - loss: 0.3560\n",
      "Epoch 22: val_loss did not improve from 0.26461\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8616 - loss: 0.3559 - val_accuracy: 0.9194 - val_loss: 0.2916 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8693 - loss: 0.3477\n",
      "Epoch 23: val_loss did not improve from 0.26461\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8695 - loss: 0.3475 - val_accuracy: 0.9274 - val_loss: 0.2720 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8629 - loss: 0.3420\n",
      "Epoch 24: val_loss did not improve from 0.26461\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8633 - loss: 0.3414 - val_accuracy: 0.9274 - val_loss: 0.2652 - learning_rate: 2.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.3062\n",
      "Epoch 25: val_loss improved from 0.26461 to 0.25664, saving model to results\\VGG19_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.8752 - loss: 0.3060 - val_accuracy: 0.9355 - val_loss: 0.2566 - learning_rate: 2.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8970 - loss: 0.2553\n",
      "Epoch 26: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8968 - loss: 0.2558 - val_accuracy: 0.9274 - val_loss: 0.2628 - learning_rate: 2.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8866 - loss: 0.2809\n",
      "Epoch 27: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8866 - loss: 0.2813 - val_accuracy: 0.9355 - val_loss: 0.2633 - learning_rate: 2.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8952 - loss: 0.2701\n",
      "Epoch 28: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8952 - loss: 0.2704 - val_accuracy: 0.8952 - val_loss: 0.2711 - learning_rate: 2.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9016 - loss: 0.2662\n",
      "Epoch 29: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.9014 - loss: 0.2666 - val_accuracy: 0.9274 - val_loss: 0.2624 - learning_rate: 2.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8974 - loss: 0.2625\n",
      "Epoch 30: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.8971 - loss: 0.2629 - val_accuracy: 0.9274 - val_loss: 0.2603 - learning_rate: 2.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8801 - loss: 0.3171\n",
      "Epoch 31: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8802 - loss: 0.3165 - val_accuracy: 0.9355 - val_loss: 0.2636 - learning_rate: 2.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8910 - loss: 0.2760\n",
      "Epoch 32: val_loss did not improve from 0.25664\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8910 - loss: 0.2761 - val_accuracy: 0.9194 - val_loss: 0.2830 - learning_rate: 2.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9162 - loss: 0.2378\n",
      "Epoch 33: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.9159 - loss: 0.2382 - val_accuracy: 0.9113 - val_loss: 0.2674 - learning_rate: 4.0000e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9041 - loss: 0.2839\n",
      "Epoch 34: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.9040 - loss: 0.2837 - val_accuracy: 0.9113 - val_loss: 0.2731 - learning_rate: 4.0000e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8831 - loss: 0.2844\n",
      "Epoch 35: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8832 - loss: 0.2842 - val_accuracy: 0.9113 - val_loss: 0.2667 - learning_rate: 4.0000e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8968 - loss: 0.2535\n",
      "Epoch 36: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8968 - loss: 0.2537 - val_accuracy: 0.9194 - val_loss: 0.2688 - learning_rate: 4.0000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9049 - loss: 0.2581\n",
      "Epoch 37: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.9048 - loss: 0.2583 - val_accuracy: 0.9274 - val_loss: 0.2702 - learning_rate: 4.0000e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9088 - loss: 0.2494\n",
      "Epoch 38: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.9086 - loss: 0.2496 - val_accuracy: 0.9113 - val_loss: 0.2674 - learning_rate: 4.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8932 - loss: 0.2768\n",
      "Epoch 39: val_loss did not improve from 0.25664\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8933 - loss: 0.2766 - val_accuracy: 0.9194 - val_loss: 0.2694 - learning_rate: 4.0000e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8960 - loss: 0.2566\n",
      "Epoch 40: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8960 - loss: 0.2568 - val_accuracy: 0.9194 - val_loss: 0.2693 - learning_rate: 8.0000e-07\n",
      "Epoch 41/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8888 - loss: 0.2671\n",
      "Epoch 41: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8889 - loss: 0.2671 - val_accuracy: 0.9194 - val_loss: 0.2695 - learning_rate: 8.0000e-07\n",
      "Epoch 42/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8872 - loss: 0.2811\n",
      "Epoch 42: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8872 - loss: 0.2809 - val_accuracy: 0.9194 - val_loss: 0.2692 - learning_rate: 8.0000e-07\n",
      "Epoch 43/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9055 - loss: 0.2361\n",
      "Epoch 43: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.9052 - loss: 0.2366 - val_accuracy: 0.9194 - val_loss: 0.2693 - learning_rate: 8.0000e-07\n",
      "Epoch 44/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8969 - loss: 0.2693\n",
      "Epoch 44: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.8969 - loss: 0.2693 - val_accuracy: 0.9113 - val_loss: 0.2690 - learning_rate: 8.0000e-07\n",
      "Epoch 45/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9034 - loss: 0.2502\n",
      "Epoch 45: val_loss did not improve from 0.25664\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.9034 - loss: 0.2502 - val_accuracy: 0.9113 - val_loss: 0.2695 - learning_rate: 8.0000e-07\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG19_from_scratch_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 944ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.85      0.90      0.88       103\n",
      "Shoot and Fruit Borer       0.93      0.89      0.91       145\n",
      "\n",
      "             accuracy                           0.90       248\n",
      "            macro avg       0.89      0.90      0.89       248\n",
      "         weighted avg       0.90      0.90      0.90       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG19_from_scratch_bs16 is complete. Total time: 01:23:02 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG19\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07d61d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG19_transfer_learning_bs16 ---\n",
      "Mode: transfer_learning, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 557ms/step - accuracy: 0.5122 - loss: 1.0450 - val_accuracy: 0.5887 - val_loss: 0.6358\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.4909 - loss: 1.0130 - val_accuracy: 0.6855 - val_loss: 0.6223\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.5196 - loss: 0.8717 - val_accuracy: 0.7419 - val_loss: 0.6193\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.5268 - loss: 0.8612 - val_accuracy: 0.7742 - val_loss: 0.6158\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.5066 - loss: 0.8676 - val_accuracy: 0.7984 - val_loss: 0.6093\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.5169 - loss: 0.8400 - val_accuracy: 0.8065 - val_loss: 0.5942\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 571ms/step - accuracy: 0.5050 - loss: 0.8181 - val_accuracy: 0.8226 - val_loss: 0.5842\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.5141 - loss: 0.8009 - val_accuracy: 0.8226 - val_loss: 0.5739\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.5351 - loss: 0.7472 - val_accuracy: 0.8226 - val_loss: 0.5671\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.5654 - loss: 0.7115 - val_accuracy: 0.8306 - val_loss: 0.5578\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.5620 - loss: 0.7157 - val_accuracy: 0.8468 - val_loss: 0.5502\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 570ms/step - accuracy: 0.5885 - loss: 0.6873 - val_accuracy: 0.8306 - val_loss: 0.5420\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 575ms/step - accuracy: 0.5515 - loss: 0.7154 - val_accuracy: 0.8468 - val_loss: 0.5361\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.6126 - loss: 0.6440 - val_accuracy: 0.8548 - val_loss: 0.5302\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 568ms/step - accuracy: 0.6537 - loss: 0.6222 - val_accuracy: 0.8548 - val_loss: 0.5219\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.6678 - loss: 0.6033 - val_accuracy: 0.8629 - val_loss: 0.5174\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.6630 - loss: 0.6132 - val_accuracy: 0.8629 - val_loss: 0.5121\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 571ms/step - accuracy: 0.6735 - loss: 0.6064 - val_accuracy: 0.8548 - val_loss: 0.5061\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.6827 - loss: 0.6080 - val_accuracy: 0.8629 - val_loss: 0.5013\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 570ms/step - accuracy: 0.6922 - loss: 0.5849 - val_accuracy: 0.8468 - val_loss: 0.4950\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.6648 - loss: 0.5895 - val_accuracy: 0.8548 - val_loss: 0.4903\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.6715 - loss: 0.5958 - val_accuracy: 0.8790 - val_loss: 0.4867\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 569ms/step - accuracy: 0.6994 - loss: 0.5722 - val_accuracy: 0.8629 - val_loss: 0.4810\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7178 - loss: 0.5617 - val_accuracy: 0.8710 - val_loss: 0.4776\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 571ms/step - accuracy: 0.6869 - loss: 0.5737 - val_accuracy: 0.8710 - val_loss: 0.4733\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.7172 - loss: 0.5613 - val_accuracy: 0.8710 - val_loss: 0.4688\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 570ms/step - accuracy: 0.7174 - loss: 0.5602 - val_accuracy: 0.8629 - val_loss: 0.4650\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 568ms/step - accuracy: 0.7457 - loss: 0.5389 - val_accuracy: 0.8629 - val_loss: 0.4616\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 577ms/step - accuracy: 0.7272 - loss: 0.5447 - val_accuracy: 0.8629 - val_loss: 0.4583\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 571ms/step - accuracy: 0.7393 - loss: 0.5462 - val_accuracy: 0.8629 - val_loss: 0.4548\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7409 - loss: 0.5300 - val_accuracy: 0.8629 - val_loss: 0.4514\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 571ms/step - accuracy: 0.7542 - loss: 0.5222 - val_accuracy: 0.8629 - val_loss: 0.4482\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 571ms/step - accuracy: 0.7481 - loss: 0.5320 - val_accuracy: 0.8629 - val_loss: 0.4458\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.7414 - loss: 0.5276 - val_accuracy: 0.8629 - val_loss: 0.4424\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 568ms/step - accuracy: 0.7519 - loss: 0.5274 - val_accuracy: 0.8629 - val_loss: 0.4392\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7694 - loss: 0.5018 - val_accuracy: 0.8629 - val_loss: 0.4365\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.8001 - loss: 0.5024 - val_accuracy: 0.8790 - val_loss: 0.4337\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7515 - loss: 0.5209 - val_accuracy: 0.8629 - val_loss: 0.4311\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 571ms/step - accuracy: 0.7672 - loss: 0.5105 - val_accuracy: 0.8629 - val_loss: 0.4288\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 570ms/step - accuracy: 0.7969 - loss: 0.4953 - val_accuracy: 0.8629 - val_loss: 0.4260\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7877 - loss: 0.4916 - val_accuracy: 0.8629 - val_loss: 0.4236\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7737 - loss: 0.5014 - val_accuracy: 0.8629 - val_loss: 0.4212\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.7741 - loss: 0.4866 - val_accuracy: 0.8629 - val_loss: 0.4189\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 571ms/step - accuracy: 0.7836 - loss: 0.4983 - val_accuracy: 0.8629 - val_loss: 0.4164\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.7920 - loss: 0.4744 - val_accuracy: 0.8710 - val_loss: 0.4143\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.7734 - loss: 0.4939 - val_accuracy: 0.8629 - val_loss: 0.4123\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7912 - loss: 0.4933 - val_accuracy: 0.8629 - val_loss: 0.4105\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 601ms/step - accuracy: 0.8178 - loss: 0.4621 - val_accuracy: 0.8710 - val_loss: 0.4081\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.8201 - loss: 0.4577 - val_accuracy: 0.8710 - val_loss: 0.4061\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.8160 - loss: 0.4730 - val_accuracy: 0.8710 - val_loss: 0.4044\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG19_transfer_learning_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 947ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.91      0.78      0.84       103\n",
      "Shoot and Fruit Borer       0.86      0.94      0.90       145\n",
      "\n",
      "             accuracy                           0.88       248\n",
      "            macro avg       0.88      0.86      0.87       248\n",
      "         weighted avg       0.88      0.88      0.87       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG19_transfer_learning_bs16 is complete. Total time: 00:30:39 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG19\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fae9fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG19_fine_tune_bs16 ---\n",
      "Mode: fine_tune, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 573ms/step - accuracy: 0.4858 - loss: 0.7496 - val_accuracy: 0.6613 - val_loss: 0.6760\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.5456 - loss: 0.7091 - val_accuracy: 0.6855 - val_loss: 0.6695\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.5429 - loss: 0.7235 - val_accuracy: 0.7097 - val_loss: 0.6575\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 582ms/step - accuracy: 0.5679 - loss: 0.7007 - val_accuracy: 0.7097 - val_loss: 0.6417\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 577ms/step - accuracy: 0.5513 - loss: 0.6996 - val_accuracy: 0.7177 - val_loss: 0.6317\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.5840 - loss: 0.6795 - val_accuracy: 0.7258 - val_loss: 0.6252\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.5866 - loss: 0.6874 - val_accuracy: 0.7258 - val_loss: 0.6132\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 585ms/step - accuracy: 0.5869 - loss: 0.6850 - val_accuracy: 0.7177 - val_loss: 0.6027\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.5866 - loss: 0.6743 - val_accuracy: 0.7419 - val_loss: 0.5946\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.6292 - loss: 0.6441 - val_accuracy: 0.7339 - val_loss: 0.5852\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 582ms/step - accuracy: 0.6147 - loss: 0.6532 - val_accuracy: 0.7419 - val_loss: 0.5779\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.6736 - loss: 0.6150 - val_accuracy: 0.7581 - val_loss: 0.5701\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 577ms/step - accuracy: 0.6727 - loss: 0.6187 - val_accuracy: 0.7661 - val_loss: 0.5636\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 583ms/step - accuracy: 0.6731 - loss: 0.6108 - val_accuracy: 0.7742 - val_loss: 0.5569\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.6702 - loss: 0.6163 - val_accuracy: 0.7823 - val_loss: 0.5500\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 584ms/step - accuracy: 0.6646 - loss: 0.6178 - val_accuracy: 0.7823 - val_loss: 0.5430\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.6537 - loss: 0.6027 - val_accuracy: 0.7823 - val_loss: 0.5369\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.6879 - loss: 0.5959 - val_accuracy: 0.7903 - val_loss: 0.5300\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 587ms/step - accuracy: 0.6976 - loss: 0.5752 - val_accuracy: 0.7984 - val_loss: 0.5239\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 579ms/step - accuracy: 0.7360 - loss: 0.5592 - val_accuracy: 0.8145 - val_loss: 0.5173\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.7488 - loss: 0.5479 - val_accuracy: 0.8145 - val_loss: 0.5112\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.7347 - loss: 0.5514 - val_accuracy: 0.8145 - val_loss: 0.5063\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.7092 - loss: 0.5848 - val_accuracy: 0.8387 - val_loss: 0.5031\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 582ms/step - accuracy: 0.7167 - loss: 0.5637 - val_accuracy: 0.8387 - val_loss: 0.4977\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 583ms/step - accuracy: 0.7264 - loss: 0.5553 - val_accuracy: 0.8306 - val_loss: 0.4929\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7561 - loss: 0.5283 - val_accuracy: 0.8387 - val_loss: 0.4880\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 585ms/step - accuracy: 0.7633 - loss: 0.5165 - val_accuracy: 0.8387 - val_loss: 0.4840\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.7559 - loss: 0.5320 - val_accuracy: 0.8387 - val_loss: 0.4793\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.7744 - loss: 0.5118 - val_accuracy: 0.8387 - val_loss: 0.4754\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 579ms/step - accuracy: 0.7548 - loss: 0.5281 - val_accuracy: 0.8387 - val_loss: 0.4717\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 582ms/step - accuracy: 0.7509 - loss: 0.5279 - val_accuracy: 0.8306 - val_loss: 0.4683\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 583ms/step - accuracy: 0.7654 - loss: 0.5241 - val_accuracy: 0.8387 - val_loss: 0.4651\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.7465 - loss: 0.5423 - val_accuracy: 0.8387 - val_loss: 0.4621\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 577ms/step - accuracy: 0.7548 - loss: 0.5372 - val_accuracy: 0.8468 - val_loss: 0.4577\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 585ms/step - accuracy: 0.7526 - loss: 0.5241 - val_accuracy: 0.8387 - val_loss: 0.4554\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.7882 - loss: 0.5014 - val_accuracy: 0.8387 - val_loss: 0.4524\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.7637 - loss: 0.5119 - val_accuracy: 0.8548 - val_loss: 0.4488\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 584ms/step - accuracy: 0.7701 - loss: 0.5072 - val_accuracy: 0.8548 - val_loss: 0.4460\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 582ms/step - accuracy: 0.7626 - loss: 0.5121 - val_accuracy: 0.8468 - val_loss: 0.4436\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 588ms/step - accuracy: 0.8154 - loss: 0.4761 - val_accuracy: 0.8548 - val_loss: 0.4402\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 579ms/step - accuracy: 0.8051 - loss: 0.4753 - val_accuracy: 0.8548 - val_loss: 0.4375\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.7877 - loss: 0.4815 - val_accuracy: 0.8548 - val_loss: 0.4352\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 586ms/step - accuracy: 0.7887 - loss: 0.4853 - val_accuracy: 0.8548 - val_loss: 0.4328\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7819 - loss: 0.4807 - val_accuracy: 0.8548 - val_loss: 0.4307\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.8191 - loss: 0.4681 - val_accuracy: 0.8548 - val_loss: 0.4280\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.7839 - loss: 0.4828 - val_accuracy: 0.8548 - val_loss: 0.4258\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 584ms/step - accuracy: 0.7984 - loss: 0.4717 - val_accuracy: 0.8548 - val_loss: 0.4236\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.7857 - loss: 0.4829 - val_accuracy: 0.8548 - val_loss: 0.4217\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 577ms/step - accuracy: 0.8006 - loss: 0.4652 - val_accuracy: 0.8629 - val_loss: 0.4197\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.8014 - loss: 0.4759 - val_accuracy: 0.8548 - val_loss: 0.4178\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG19_fine_tune_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 939ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.88      0.77      0.82       103\n",
      "Shoot and Fruit Borer       0.85      0.92      0.88       145\n",
      "\n",
      "             accuracy                           0.86       248\n",
      "            macro avg       0.86      0.85      0.85       248\n",
      "         weighted avg       0.86      0.86      0.86       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG19_fine_tune_bs16 is complete. Total time: 00:30:58 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG19\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb5fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: VGG19_full_monty_bs16 ---\n",
      "Mode: full_monty, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.4825 - loss: 0.9374\n",
      "Epoch 1: val_loss improved from inf to 0.78393, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 571ms/step - accuracy: 0.4828 - loss: 0.9366 - val_accuracy: 0.4113 - val_loss: 0.7839 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.5292 - loss: 0.7591\n",
      "Epoch 2: val_loss improved from 0.78393 to 0.71811, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.5292 - loss: 0.7592 - val_accuracy: 0.4113 - val_loss: 0.7181 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.5413 - loss: 0.7451\n",
      "Epoch 3: val_loss improved from 0.71811 to 0.69241, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.5415 - loss: 0.7451 - val_accuracy: 0.5242 - val_loss: 0.6924 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.5518 - loss: 0.7093\n",
      "Epoch 4: val_loss improved from 0.69241 to 0.67826, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.5517 - loss: 0.7097 - val_accuracy: 0.6210 - val_loss: 0.6783 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.5398 - loss: 0.7267\n",
      "Epoch 5: val_loss improved from 0.67826 to 0.67049, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.5394 - loss: 0.7267 - val_accuracy: 0.6371 - val_loss: 0.6705 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.5502 - loss: 0.7203\n",
      "Epoch 6: val_loss improved from 0.67049 to 0.65035, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.5504 - loss: 0.7202 - val_accuracy: 0.7016 - val_loss: 0.6504 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.5334 - loss: 0.7057\n",
      "Epoch 7: val_loss improved from 0.65035 to 0.64118, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.5335 - loss: 0.7056 - val_accuracy: 0.7097 - val_loss: 0.6412 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.5844 - loss: 0.6806\n",
      "Epoch 8: val_loss improved from 0.64118 to 0.63207, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.5842 - loss: 0.6807 - val_accuracy: 0.7177 - val_loss: 0.6321 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.5895 - loss: 0.6692\n",
      "Epoch 9: val_loss improved from 0.63207 to 0.62333, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 577ms/step - accuracy: 0.5897 - loss: 0.6692 - val_accuracy: 0.7500 - val_loss: 0.6233 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.6144 - loss: 0.6603\n",
      "Epoch 10: val_loss improved from 0.62333 to 0.61493, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.6145 - loss: 0.6602 - val_accuracy: 0.7419 - val_loss: 0.6149 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.5970 - loss: 0.6673\n",
      "Epoch 11: val_loss improved from 0.61493 to 0.60591, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.5972 - loss: 0.6671 - val_accuracy: 0.7661 - val_loss: 0.6059 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.6121 - loss: 0.6641\n",
      "Epoch 12: val_loss improved from 0.60591 to 0.59512, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 575ms/step - accuracy: 0.6121 - loss: 0.6640 - val_accuracy: 0.7823 - val_loss: 0.5951 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.6348 - loss: 0.6344\n",
      "Epoch 13: val_loss improved from 0.59512 to 0.58612, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.6348 - loss: 0.6344 - val_accuracy: 0.7823 - val_loss: 0.5861 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.6552 - loss: 0.6324\n",
      "Epoch 14: val_loss improved from 0.58612 to 0.58134, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 575ms/step - accuracy: 0.6552 - loss: 0.6325 - val_accuracy: 0.7903 - val_loss: 0.5813 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.6488 - loss: 0.6164\n",
      "Epoch 15: val_loss improved from 0.58134 to 0.57352, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.6489 - loss: 0.6164 - val_accuracy: 0.8145 - val_loss: 0.5735 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - accuracy: 0.6665 - loss: 0.6013\n",
      "Epoch 16: val_loss improved from 0.57352 to 0.56343, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.6664 - loss: 0.6014 - val_accuracy: 0.7984 - val_loss: 0.5634 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.6787 - loss: 0.6068\n",
      "Epoch 17: val_loss improved from 0.56343 to 0.55738, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 575ms/step - accuracy: 0.6786 - loss: 0.6068 - val_accuracy: 0.8065 - val_loss: 0.5574 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.7009 - loss: 0.5914\n",
      "Epoch 18: val_loss improved from 0.55738 to 0.55038, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 575ms/step - accuracy: 0.7007 - loss: 0.5915 - val_accuracy: 0.8145 - val_loss: 0.5504 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.7285 - loss: 0.5779\n",
      "Epoch 19: val_loss improved from 0.55038 to 0.54449, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.7284 - loss: 0.5780 - val_accuracy: 0.8145 - val_loss: 0.5445 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7083 - loss: 0.5936\n",
      "Epoch 20: val_loss improved from 0.54449 to 0.53904, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 562ms/step - accuracy: 0.7082 - loss: 0.5936 - val_accuracy: 0.8306 - val_loss: 0.5390 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.7254 - loss: 0.5649\n",
      "Epoch 21: val_loss improved from 0.53904 to 0.53152, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 577ms/step - accuracy: 0.7251 - loss: 0.5651 - val_accuracy: 0.8306 - val_loss: 0.5315 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.7142 - loss: 0.5801\n",
      "Epoch 22: val_loss improved from 0.53152 to 0.52570, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.7143 - loss: 0.5800 - val_accuracy: 0.8306 - val_loss: 0.5257 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.7052 - loss: 0.5850\n",
      "Epoch 23: val_loss improved from 0.52570 to 0.52057, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7053 - loss: 0.5849 - val_accuracy: 0.8306 - val_loss: 0.5206 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.7008 - loss: 0.5836\n",
      "Epoch 24: val_loss improved from 0.52057 to 0.51554, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 579ms/step - accuracy: 0.7009 - loss: 0.5836 - val_accuracy: 0.8387 - val_loss: 0.5155 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.7315 - loss: 0.5561\n",
      "Epoch 25: val_loss improved from 0.51554 to 0.51148, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.7313 - loss: 0.5562 - val_accuracy: 0.8387 - val_loss: 0.5115 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.7098 - loss: 0.5641\n",
      "Epoch 26: val_loss improved from 0.51148 to 0.50706, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.7098 - loss: 0.5640 - val_accuracy: 0.8468 - val_loss: 0.5071 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.7516 - loss: 0.5361\n",
      "Epoch 27: val_loss improved from 0.50706 to 0.50010, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.7514 - loss: 0.5363 - val_accuracy: 0.8306 - val_loss: 0.5001 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.7611 - loss: 0.5506\n",
      "Epoch 28: val_loss improved from 0.50010 to 0.49745, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.7611 - loss: 0.5505 - val_accuracy: 0.8468 - val_loss: 0.4975 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.7590 - loss: 0.5463\n",
      "Epoch 29: val_loss improved from 0.49745 to 0.49329, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7591 - loss: 0.5462 - val_accuracy: 0.8468 - val_loss: 0.4933 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.7664 - loss: 0.5222\n",
      "Epoch 30: val_loss improved from 0.49329 to 0.48788, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7662 - loss: 0.5223 - val_accuracy: 0.8387 - val_loss: 0.4879 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.7662 - loss: 0.5143\n",
      "Epoch 31: val_loss improved from 0.48788 to 0.48419, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 575ms/step - accuracy: 0.7659 - loss: 0.5145 - val_accuracy: 0.8387 - val_loss: 0.4842 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.7373 - loss: 0.5388\n",
      "Epoch 32: val_loss improved from 0.48419 to 0.47842, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.7374 - loss: 0.5387 - val_accuracy: 0.8548 - val_loss: 0.4784 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.7733 - loss: 0.5206\n",
      "Epoch 33: val_loss improved from 0.47842 to 0.47480, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 579ms/step - accuracy: 0.7733 - loss: 0.5206 - val_accuracy: 0.8468 - val_loss: 0.4748 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.7681 - loss: 0.5118\n",
      "Epoch 34: val_loss improved from 0.47480 to 0.47165, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7681 - loss: 0.5119 - val_accuracy: 0.8468 - val_loss: 0.4717 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.7695 - loss: 0.5117\n",
      "Epoch 35: val_loss improved from 0.47165 to 0.46928, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 574ms/step - accuracy: 0.7695 - loss: 0.5117 - val_accuracy: 0.8468 - val_loss: 0.4693 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.7503 - loss: 0.5302\n",
      "Epoch 36: val_loss improved from 0.46928 to 0.46581, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 582ms/step - accuracy: 0.7504 - loss: 0.5302 - val_accuracy: 0.8387 - val_loss: 0.4658 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.7632 - loss: 0.5085\n",
      "Epoch 37: val_loss improved from 0.46581 to 0.46158, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7632 - loss: 0.5085 - val_accuracy: 0.8468 - val_loss: 0.4616 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.7918 - loss: 0.5041\n",
      "Epoch 38: val_loss improved from 0.46158 to 0.45789, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 571ms/step - accuracy: 0.7917 - loss: 0.5042 - val_accuracy: 0.8629 - val_loss: 0.4579 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.7604 - loss: 0.5146\n",
      "Epoch 39: val_loss improved from 0.45789 to 0.45475, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7606 - loss: 0.5144 - val_accuracy: 0.8629 - val_loss: 0.4547 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.8068 - loss: 0.4853\n",
      "Epoch 40: val_loss improved from 0.45475 to 0.45164, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 579ms/step - accuracy: 0.8067 - loss: 0.4855 - val_accuracy: 0.8629 - val_loss: 0.4516 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.7970 - loss: 0.4859\n",
      "Epoch 41: val_loss improved from 0.45164 to 0.44832, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 575ms/step - accuracy: 0.7969 - loss: 0.4861 - val_accuracy: 0.8629 - val_loss: 0.4483 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.7834 - loss: 0.4947\n",
      "Epoch 42: val_loss improved from 0.44832 to 0.44559, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 572ms/step - accuracy: 0.7836 - loss: 0.4946 - val_accuracy: 0.8629 - val_loss: 0.4456 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.7753 - loss: 0.4833\n",
      "Epoch 43: val_loss improved from 0.44559 to 0.44229, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7753 - loss: 0.4834 - val_accuracy: 0.8629 - val_loss: 0.4423 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.8078 - loss: 0.4895\n",
      "Epoch 44: val_loss improved from 0.44229 to 0.43983, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.8076 - loss: 0.4894 - val_accuracy: 0.8629 - val_loss: 0.4398 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.7887 - loss: 0.5005\n",
      "Epoch 45: val_loss improved from 0.43983 to 0.43719, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 578ms/step - accuracy: 0.7887 - loss: 0.5003 - val_accuracy: 0.8629 - val_loss: 0.4372 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.7879 - loss: 0.4886\n",
      "Epoch 46: val_loss improved from 0.43719 to 0.43393, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7879 - loss: 0.4886 - val_accuracy: 0.8629 - val_loss: 0.4339 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.7891 - loss: 0.4843\n",
      "Epoch 47: val_loss improved from 0.43393 to 0.43159, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 579ms/step - accuracy: 0.7889 - loss: 0.4844 - val_accuracy: 0.8629 - val_loss: 0.4316 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.7882 - loss: 0.4762\n",
      "Epoch 48: val_loss improved from 0.43159 to 0.42969, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 580ms/step - accuracy: 0.7882 - loss: 0.4763 - val_accuracy: 0.8629 - val_loss: 0.4297 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.7950 - loss: 0.4750\n",
      "Epoch 49: val_loss improved from 0.42969 to 0.42789, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 576ms/step - accuracy: 0.7951 - loss: 0.4750 - val_accuracy: 0.8629 - val_loss: 0.4279 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.8153 - loss: 0.4661\n",
      "Epoch 50: val_loss improved from 0.42789 to 0.42510, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - accuracy: 0.8152 - loss: 0.4662 - val_accuracy: 0.8629 - val_loss: 0.4251 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 51/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8320 - loss: 0.3890\n",
      "Epoch 51: val_loss improved from 0.42510 to 0.17134, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.8325 - loss: 0.3880 - val_accuracy: 0.9435 - val_loss: 0.1713 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9205 - loss: 0.2225\n",
      "Epoch 52: val_loss improved from 0.17134 to 0.13459, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9207 - loss: 0.2221 - val_accuracy: 0.9274 - val_loss: 0.1346 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9473 - loss: 0.1348\n",
      "Epoch 53: val_loss did not improve from 0.13459\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9473 - loss: 0.1348 - val_accuracy: 0.9355 - val_loss: 0.1410 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9572 - loss: 0.1346\n",
      "Epoch 54: val_loss improved from 0.13459 to 0.13375, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9572 - loss: 0.1343 - val_accuracy: 0.9355 - val_loss: 0.1337 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9518 - loss: 0.1072\n",
      "Epoch 55: val_loss improved from 0.13375 to 0.11523, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9519 - loss: 0.1071 - val_accuracy: 0.9597 - val_loss: 0.1152 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9744 - loss: 0.0785\n",
      "Epoch 56: val_loss improved from 0.11523 to 0.10340, saving model to results\\VGG19_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9743 - loss: 0.0787 - val_accuracy: 0.9597 - val_loss: 0.1034 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9694 - loss: 0.0792\n",
      "Epoch 57: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9694 - loss: 0.0792 - val_accuracy: 0.9435 - val_loss: 0.1657 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9752 - loss: 0.0799\n",
      "Epoch 58: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9752 - loss: 0.0799 - val_accuracy: 0.9516 - val_loss: 0.1166 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9737 - loss: 0.0724\n",
      "Epoch 59: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9737 - loss: 0.0724 - val_accuracy: 0.9516 - val_loss: 0.1158 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9803 - loss: 0.0713\n",
      "Epoch 60: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9801 - loss: 0.0715 - val_accuracy: 0.9597 - val_loss: 0.1048 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 0.0490\n",
      "Epoch 61: val_loss did not improve from 0.10340\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 0.0490 - val_accuracy: 0.9677 - val_loss: 0.1143 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9861 - loss: 0.0416\n",
      "Epoch 62: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9861 - loss: 0.0416 - val_accuracy: 0.9516 - val_loss: 0.1134 - learning_rate: 2.0000e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9826 - loss: 0.0423\n",
      "Epoch 63: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9827 - loss: 0.0422 - val_accuracy: 0.9516 - val_loss: 0.1198 - learning_rate: 2.0000e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 0.0345\n",
      "Epoch 64: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9874 - loss: 0.0346 - val_accuracy: 0.9516 - val_loss: 0.1068 - learning_rate: 2.0000e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9909 - loss: 0.0295\n",
      "Epoch 65: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9908 - loss: 0.0295 - val_accuracy: 0.9435 - val_loss: 0.1396 - learning_rate: 2.0000e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9905 - loss: 0.0246\n",
      "Epoch 66: val_loss did not improve from 0.10340\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9905 - loss: 0.0246 - val_accuracy: 0.9597 - val_loss: 0.1269 - learning_rate: 2.0000e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0305\n",
      "Epoch 67: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0304 - val_accuracy: 0.9597 - val_loss: 0.1303 - learning_rate: 4.0000e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0330\n",
      "Epoch 68: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0330 - val_accuracy: 0.9597 - val_loss: 0.1303 - learning_rate: 4.0000e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9941 - loss: 0.0209\n",
      "Epoch 69: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9941 - loss: 0.0211 - val_accuracy: 0.9597 - val_loss: 0.1267 - learning_rate: 4.0000e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9956 - loss: 0.0225\n",
      "Epoch 70: val_loss did not improve from 0.10340\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9955 - loss: 0.0226 - val_accuracy: 0.9435 - val_loss: 0.1343 - learning_rate: 4.0000e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9868 - loss: 0.0327\n",
      "Epoch 71: val_loss did not improve from 0.10340\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.9868 - loss: 0.0326 - val_accuracy: 0.9597 - val_loss: 0.1307 - learning_rate: 4.0000e-07\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- VGG19_full_monty_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 923ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.97      0.93      0.95       103\n",
      "Shoot and Fruit Borer       0.95      0.98      0.97       145\n",
      "\n",
      "             accuracy                           0.96       248\n",
      "            macro avg       0.96      0.96      0.96       248\n",
      "         weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for VGG19_full_monty_bs16 is complete. Total time: 00:55:10 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"VGG19\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91dbc4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet50_from_scratch_bs16 ---\n",
      "Mode: from_scratch, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6296 - loss: 1.0094\n",
      "Epoch 1: val_loss improved from inf to 2.16371, saving model to results\\ResNet50_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.6298 - loss: 1.0073 - val_accuracy: 0.5887 - val_loss: 2.1637 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7168 - loss: 0.7694\n",
      "Epoch 2: val_loss did not improve from 2.16371\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7169 - loss: 0.7697 - val_accuracy: 0.5887 - val_loss: 4.2559 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7162 - loss: 0.7602\n",
      "Epoch 3: val_loss did not improve from 2.16371\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7165 - loss: 0.7590 - val_accuracy: 0.5887 - val_loss: 6.6364 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7410 - loss: 0.6860\n",
      "Epoch 4: val_loss did not improve from 2.16371\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7410 - loss: 0.6863 - val_accuracy: 0.5887 - val_loss: 4.6438 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7827 - loss: 0.6256\n",
      "Epoch 5: val_loss did not improve from 2.16371\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.7827 - loss: 0.6263 - val_accuracy: 0.5887 - val_loss: 3.2901 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8258 - loss: 0.4571\n",
      "Epoch 6: val_loss did not improve from 2.16371\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8254 - loss: 0.4581 - val_accuracy: 0.5887 - val_loss: 2.7282 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8066 - loss: 0.5618\n",
      "Epoch 7: val_loss did not improve from 2.16371\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8064 - loss: 0.5620 - val_accuracy: 0.5887 - val_loss: 3.5735 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8310 - loss: 0.5135\n",
      "Epoch 8: val_loss did not improve from 2.16371\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8311 - loss: 0.5128 - val_accuracy: 0.6048 - val_loss: 2.2616 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8183 - loss: 0.4740\n",
      "Epoch 9: val_loss improved from 2.16371 to 0.81621, saving model to results\\ResNet50_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.8184 - loss: 0.4737 - val_accuracy: 0.6774 - val_loss: 0.8162 - learning_rate: 2.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8496 - loss: 0.3670\n",
      "Epoch 10: val_loss improved from 0.81621 to 0.32777, saving model to results\\ResNet50_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.8495 - loss: 0.3677 - val_accuracy: 0.8790 - val_loss: 0.3278 - learning_rate: 2.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8628 - loss: 0.3174\n",
      "Epoch 11: val_loss improved from 0.32777 to 0.24243, saving model to results\\ResNet50_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8627 - loss: 0.3180 - val_accuracy: 0.9113 - val_loss: 0.2424 - learning_rate: 2.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8277 - loss: 0.4779\n",
      "Epoch 12: val_loss did not improve from 0.24243\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8279 - loss: 0.4769 - val_accuracy: 0.9113 - val_loss: 0.2820 - learning_rate: 2.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8321 - loss: 0.4257\n",
      "Epoch 13: val_loss improved from 0.24243 to 0.22449, saving model to results\\ResNet50_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.8323 - loss: 0.4254 - val_accuracy: 0.9194 - val_loss: 0.2245 - learning_rate: 2.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8426 - loss: 0.3889\n",
      "Epoch 14: val_loss improved from 0.22449 to 0.19093, saving model to results\\ResNet50_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1s/step - accuracy: 0.8427 - loss: 0.3889 - val_accuracy: 0.9274 - val_loss: 0.1909 - learning_rate: 2.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8703 - loss: 0.3525\n",
      "Epoch 15: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8703 - loss: 0.3524 - val_accuracy: 0.9032 - val_loss: 0.2200 - learning_rate: 2.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8851 - loss: 0.3290\n",
      "Epoch 16: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8847 - loss: 0.3300 - val_accuracy: 0.9194 - val_loss: 0.2371 - learning_rate: 2.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8734 - loss: 0.3490\n",
      "Epoch 17: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8734 - loss: 0.3490 - val_accuracy: 0.8790 - val_loss: 0.2880 - learning_rate: 2.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8811 - loss: 0.3348\n",
      "Epoch 18: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8810 - loss: 0.3349 - val_accuracy: 0.9113 - val_loss: 0.2825 - learning_rate: 2.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.4092\n",
      "Epoch 19: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.4087 - val_accuracy: 0.8790 - val_loss: 0.3555 - learning_rate: 2.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9118 - loss: 0.2383\n",
      "Epoch 20: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.9115 - loss: 0.2396 - val_accuracy: 0.9032 - val_loss: 0.2586 - learning_rate: 2.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8681 - loss: 0.3467\n",
      "Epoch 21: val_loss did not improve from 0.19093\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1s/step - accuracy: 0.8683 - loss: 0.3464 - val_accuracy: 0.8871 - val_loss: 0.3249 - learning_rate: 2.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8878 - loss: 0.3123\n",
      "Epoch 22: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8878 - loss: 0.3121 - val_accuracy: 0.9194 - val_loss: 0.2454 - learning_rate: 4.0000e-06\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8721 - loss: 0.3220\n",
      "Epoch 23: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1s/step - accuracy: 0.8723 - loss: 0.3220 - val_accuracy: 0.9274 - val_loss: 0.2542 - learning_rate: 4.0000e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8984 - loss: 0.3031\n",
      "Epoch 24: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8985 - loss: 0.3027 - val_accuracy: 0.9032 - val_loss: 0.2814 - learning_rate: 4.0000e-06\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9038 - loss: 0.2478\n",
      "Epoch 25: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.9037 - loss: 0.2480 - val_accuracy: 0.9194 - val_loss: 0.2464 - learning_rate: 4.0000e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8889 - loss: 0.3128\n",
      "Epoch 26: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8887 - loss: 0.3127 - val_accuracy: 0.9194 - val_loss: 0.2221 - learning_rate: 4.0000e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8914 - loss: 0.2710\n",
      "Epoch 27: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8914 - loss: 0.2710 - val_accuracy: 0.9194 - val_loss: 0.2620 - learning_rate: 4.0000e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9045 - loss: 0.2512\n",
      "Epoch 28: val_loss did not improve from 0.19093\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.9043 - loss: 0.2514 - val_accuracy: 0.9194 - val_loss: 0.2218 - learning_rate: 4.0000e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8706 - loss: 0.3248\n",
      "Epoch 29: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8707 - loss: 0.3243 - val_accuracy: 0.9194 - val_loss: 0.2265 - learning_rate: 8.0000e-07\n",
      "Epoch 30/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8913 - loss: 0.2630\n",
      "Epoch 30: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8914 - loss: 0.2634 - val_accuracy: 0.9274 - val_loss: 0.2364 - learning_rate: 8.0000e-07\n",
      "Epoch 31/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8929 - loss: 0.2686\n",
      "Epoch 31: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.8929 - loss: 0.2687 - val_accuracy: 0.9274 - val_loss: 0.2382 - learning_rate: 8.0000e-07\n",
      "Epoch 32/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9071 - loss: 0.2314\n",
      "Epoch 32: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.9070 - loss: 0.2316 - val_accuracy: 0.9274 - val_loss: 0.2370 - learning_rate: 8.0000e-07\n",
      "Epoch 33/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9195 - loss: 0.2322\n",
      "Epoch 33: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.9193 - loss: 0.2327 - val_accuracy: 0.9274 - val_loss: 0.2375 - learning_rate: 8.0000e-07\n",
      "Epoch 34/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9097 - loss: 0.2383\n",
      "Epoch 34: val_loss did not improve from 0.19093\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.9096 - loss: 0.2385 - val_accuracy: 0.9274 - val_loss: 0.2373 - learning_rate: 8.0000e-07\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet50_from_scratch_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 716ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.88      0.84      0.86       103\n",
      "Shoot and Fruit Borer       0.89      0.92      0.90       145\n",
      "\n",
      "             accuracy                           0.89       248\n",
      "            macro avg       0.89      0.88      0.88       248\n",
      "         weighted avg       0.89      0.89      0.89       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet50_from_scratch_bs16 is complete. Total time: 00:54:34 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet50\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42db5f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet50_transfer_learning_bs16 ---\n",
      "Mode: transfer_learning, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 474ms/step - accuracy: 0.4777 - loss: 0.8856 - val_accuracy: 0.3871 - val_loss: 0.7150\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.4779 - loss: 0.8229 - val_accuracy: 0.3710 - val_loss: 0.7056\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 445ms/step - accuracy: 0.5106 - loss: 0.8092 - val_accuracy: 0.4032 - val_loss: 0.6996\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 446ms/step - accuracy: 0.5135 - loss: 0.7781 - val_accuracy: 0.4113 - val_loss: 0.6996\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.4960 - loss: 0.7722 - val_accuracy: 0.6210 - val_loss: 0.6870\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.5057 - loss: 0.7676 - val_accuracy: 0.4113 - val_loss: 0.6979\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.5392 - loss: 0.7313 - val_accuracy: 0.6694 - val_loss: 0.6830\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5080 - loss: 0.7306 - val_accuracy: 0.6210 - val_loss: 0.6827\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.5341 - loss: 0.7026 - val_accuracy: 0.6935 - val_loss: 0.6736\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5202 - loss: 0.7084 - val_accuracy: 0.5806 - val_loss: 0.6830\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5240 - loss: 0.7232 - val_accuracy: 0.6935 - val_loss: 0.6752\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5323 - loss: 0.7101 - val_accuracy: 0.6855 - val_loss: 0.6715\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5294 - loss: 0.6975 - val_accuracy: 0.6210 - val_loss: 0.6762\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5543 - loss: 0.6902 - val_accuracy: 0.6048 - val_loss: 0.6778\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - accuracy: 0.5333 - loss: 0.7005 - val_accuracy: 0.6855 - val_loss: 0.6660\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5562 - loss: 0.6874 - val_accuracy: 0.6613 - val_loss: 0.6701\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.4993 - loss: 0.7068 - val_accuracy: 0.6935 - val_loss: 0.6576\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5107 - loss: 0.6919 - val_accuracy: 0.6452 - val_loss: 0.6683\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.5517 - loss: 0.6860 - val_accuracy: 0.6855 - val_loss: 0.6615\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5637 - loss: 0.6780 - val_accuracy: 0.6935 - val_loss: 0.6632\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.5548 - loss: 0.6802 - val_accuracy: 0.7016 - val_loss: 0.6536\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5537 - loss: 0.6791 - val_accuracy: 0.6855 - val_loss: 0.6573\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.5973 - loss: 0.6608 - val_accuracy: 0.7097 - val_loss: 0.6493\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.6099 - loss: 0.6738 - val_accuracy: 0.6935 - val_loss: 0.6546\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5706 - loss: 0.6883 - val_accuracy: 0.6774 - val_loss: 0.6529\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.5652 - loss: 0.6796 - val_accuracy: 0.6774 - val_loss: 0.6405\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.6168 - loss: 0.6629 - val_accuracy: 0.6774 - val_loss: 0.6572\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.5521 - loss: 0.6740 - val_accuracy: 0.7097 - val_loss: 0.6445\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.5883 - loss: 0.6745 - val_accuracy: 0.6935 - val_loss: 0.6445\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - accuracy: 0.5363 - loss: 0.6890 - val_accuracy: 0.7016 - val_loss: 0.6472\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.5849 - loss: 0.6705 - val_accuracy: 0.7016 - val_loss: 0.6466\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.5882 - loss: 0.6697 - val_accuracy: 0.7016 - val_loss: 0.6413\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.5662 - loss: 0.6763 - val_accuracy: 0.6855 - val_loss: 0.6519\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.5876 - loss: 0.6762 - val_accuracy: 0.7016 - val_loss: 0.6442\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.6019 - loss: 0.6602 - val_accuracy: 0.7097 - val_loss: 0.6460\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.5836 - loss: 0.6795 - val_accuracy: 0.7097 - val_loss: 0.6374\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.6275 - loss: 0.6550 - val_accuracy: 0.7177 - val_loss: 0.6417\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.5822 - loss: 0.6665 - val_accuracy: 0.7097 - val_loss: 0.6349\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.6126 - loss: 0.6555 - val_accuracy: 0.7016 - val_loss: 0.6399\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.6178 - loss: 0.6606 - val_accuracy: 0.7016 - val_loss: 0.6375\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.6155 - loss: 0.6585 - val_accuracy: 0.7177 - val_loss: 0.6280\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.5823 - loss: 0.6518 - val_accuracy: 0.7177 - val_loss: 0.6312\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.6256 - loss: 0.6466 - val_accuracy: 0.7016 - val_loss: 0.6341\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.6048 - loss: 0.6555 - val_accuracy: 0.7016 - val_loss: 0.6338\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.6252 - loss: 0.6541 - val_accuracy: 0.7177 - val_loss: 0.6393\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.6330 - loss: 0.6539 - val_accuracy: 0.7177 - val_loss: 0.6272\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 445ms/step - accuracy: 0.5881 - loss: 0.6681 - val_accuracy: 0.7177 - val_loss: 0.6387\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 440ms/step - accuracy: 0.6119 - loss: 0.6663 - val_accuracy: 0.7016 - val_loss: 0.6328\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - accuracy: 0.5989 - loss: 0.6629 - val_accuracy: 0.7016 - val_loss: 0.6274\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 441ms/step - accuracy: 0.6207 - loss: 0.6589 - val_accuracy: 0.7016 - val_loss: 0.6272\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet50_transfer_learning_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 704ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.62      0.50      0.56       103\n",
      "Shoot and Fruit Borer       0.69      0.78      0.73       145\n",
      "\n",
      "             accuracy                           0.67       248\n",
      "            macro avg       0.65      0.64      0.64       248\n",
      "         weighted avg       0.66      0.67      0.66       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet50_transfer_learning_bs16 is complete. Total time: 00:23:34 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet50\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5b002d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet50_fine_tune_bs16 ---\n",
      "Mode: fine_tune, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 770ms/step - accuracy: 0.5264 - loss: 0.9117 - val_accuracy: 0.6129 - val_loss: 0.6853\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5050 - loss: 0.8839 - val_accuracy: 0.5323 - val_loss: 0.6904\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.4830 - loss: 0.8670 - val_accuracy: 0.4355 - val_loss: 0.6934\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 733ms/step - accuracy: 0.4891 - loss: 0.8432 - val_accuracy: 0.5565 - val_loss: 0.6869\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 734ms/step - accuracy: 0.4991 - loss: 0.8232 - val_accuracy: 0.6855 - val_loss: 0.6785\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.4793 - loss: 0.8090 - val_accuracy: 0.6935 - val_loss: 0.6783\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5272 - loss: 0.7675 - val_accuracy: 0.7177 - val_loss: 0.6776\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 736ms/step - accuracy: 0.5322 - loss: 0.7452 - val_accuracy: 0.7016 - val_loss: 0.6747\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 740ms/step - accuracy: 0.5217 - loss: 0.7349 - val_accuracy: 0.7419 - val_loss: 0.6744\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 735ms/step - accuracy: 0.5290 - loss: 0.7143 - val_accuracy: 0.5484 - val_loss: 0.6811\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5313 - loss: 0.7179 - val_accuracy: 0.7177 - val_loss: 0.6668\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 741ms/step - accuracy: 0.5344 - loss: 0.7164 - val_accuracy: 0.7177 - val_loss: 0.6645\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 739ms/step - accuracy: 0.5320 - loss: 0.7187 - val_accuracy: 0.6774 - val_loss: 0.6737\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5177 - loss: 0.7207 - val_accuracy: 0.7097 - val_loss: 0.6701\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 740ms/step - accuracy: 0.5050 - loss: 0.7215 - val_accuracy: 0.7258 - val_loss: 0.6628\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 740ms/step - accuracy: 0.5594 - loss: 0.6896 - val_accuracy: 0.7339 - val_loss: 0.6615\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 739ms/step - accuracy: 0.5488 - loss: 0.6991 - val_accuracy: 0.7258 - val_loss: 0.6606\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 740ms/step - accuracy: 0.5418 - loss: 0.7001 - val_accuracy: 0.7016 - val_loss: 0.6520\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 739ms/step - accuracy: 0.5713 - loss: 0.6919 - val_accuracy: 0.6613 - val_loss: 0.6672\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 740ms/step - accuracy: 0.5921 - loss: 0.6781 - val_accuracy: 0.7097 - val_loss: 0.6518\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 740ms/step - accuracy: 0.5641 - loss: 0.6763 - val_accuracy: 0.7097 - val_loss: 0.6548\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 741ms/step - accuracy: 0.5905 - loss: 0.6682 - val_accuracy: 0.7258 - val_loss: 0.6557\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.5537 - loss: 0.6786 - val_accuracy: 0.7097 - val_loss: 0.6513\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 736ms/step - accuracy: 0.5755 - loss: 0.6847 - val_accuracy: 0.6774 - val_loss: 0.6596\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5869 - loss: 0.6732 - val_accuracy: 0.6774 - val_loss: 0.6581\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5481 - loss: 0.6913 - val_accuracy: 0.7258 - val_loss: 0.6509\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.5758 - loss: 0.6674 - val_accuracy: 0.7177 - val_loss: 0.6532\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.5916 - loss: 0.6827 - val_accuracy: 0.7097 - val_loss: 0.6469\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5487 - loss: 0.6744 - val_accuracy: 0.7177 - val_loss: 0.6396\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 752ms/step - accuracy: 0.5852 - loss: 0.6759 - val_accuracy: 0.7419 - val_loss: 0.6485\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 752ms/step - accuracy: 0.5589 - loss: 0.6774 - val_accuracy: 0.7016 - val_loss: 0.6429\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 749ms/step - accuracy: 0.6264 - loss: 0.6619 - val_accuracy: 0.7177 - val_loss: 0.6449\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 747ms/step - accuracy: 0.5802 - loss: 0.6773 - val_accuracy: 0.7339 - val_loss: 0.6453\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 748ms/step - accuracy: 0.6264 - loss: 0.6551 - val_accuracy: 0.7016 - val_loss: 0.6420\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 753ms/step - accuracy: 0.5985 - loss: 0.6708 - val_accuracy: 0.7097 - val_loss: 0.6391\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 735ms/step - accuracy: 0.6054 - loss: 0.6673 - val_accuracy: 0.7339 - val_loss: 0.6417\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.6102 - loss: 0.6654 - val_accuracy: 0.7097 - val_loss: 0.6348\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.5985 - loss: 0.6661 - val_accuracy: 0.7339 - val_loss: 0.6300\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 735ms/step - accuracy: 0.6298 - loss: 0.6534 - val_accuracy: 0.7339 - val_loss: 0.6401\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.5934 - loss: 0.6618 - val_accuracy: 0.7097 - val_loss: 0.6290\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 736ms/step - accuracy: 0.5926 - loss: 0.6639 - val_accuracy: 0.7258 - val_loss: 0.6372\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.6218 - loss: 0.6525 - val_accuracy: 0.7339 - val_loss: 0.6266\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.5799 - loss: 0.6664 - val_accuracy: 0.7097 - val_loss: 0.6337\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 737ms/step - accuracy: 0.6246 - loss: 0.6569 - val_accuracy: 0.7097 - val_loss: 0.6276\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.5860 - loss: 0.6652 - val_accuracy: 0.7097 - val_loss: 0.6261\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 738ms/step - accuracy: 0.6063 - loss: 0.6652 - val_accuracy: 0.7339 - val_loss: 0.6221\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 733ms/step - accuracy: 0.6416 - loss: 0.6424 - val_accuracy: 0.7339 - val_loss: 0.6350\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 734ms/step - accuracy: 0.5909 - loss: 0.6678 - val_accuracy: 0.7097 - val_loss: 0.6287\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 736ms/step - accuracy: 0.6440 - loss: 0.6576 - val_accuracy: 0.7177 - val_loss: 0.6245\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 739ms/step - accuracy: 0.6044 - loss: 0.6704 - val_accuracy: 0.7339 - val_loss: 0.6196\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet50_fine_tune_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step  \n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.69      0.43      0.53       103\n",
      "Shoot and Fruit Borer       0.68      0.86      0.76       145\n",
      "\n",
      "             accuracy                           0.68       248\n",
      "            macro avg       0.68      0.64      0.64       248\n",
      "         weighted avg       0.68      0.68      0.66       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet50_fine_tune_bs16 is complete. Total time: 00:39:31 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet50\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea56975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet50_full_monty_bs16 ---\n",
      "Mode: full_monty, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.4918 - loss: 0.8969\n",
      "Epoch 1: val_loss improved from inf to 0.69322, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 475ms/step - accuracy: 0.4919 - loss: 0.8966 - val_accuracy: 0.4516 - val_loss: 0.6932 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.4883 - loss: 0.9190\n",
      "Epoch 2: val_loss improved from 0.69322 to 0.68368, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 442ms/step - accuracy: 0.4884 - loss: 0.9185 - val_accuracy: 0.5968 - val_loss: 0.6837 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.4942 - loss: 0.8665\n",
      "Epoch 3: val_loss did not improve from 0.68368\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 426ms/step - accuracy: 0.4946 - loss: 0.8661 - val_accuracy: 0.5161 - val_loss: 0.6908 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.5087 - loss: 0.8322\n",
      "Epoch 4: val_loss improved from 0.68368 to 0.68021, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 439ms/step - accuracy: 0.5086 - loss: 0.8321 - val_accuracy: 0.5968 - val_loss: 0.6802 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.5064 - loss: 0.7877\n",
      "Epoch 5: val_loss did not improve from 0.68021\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 420ms/step - accuracy: 0.5061 - loss: 0.7879 - val_accuracy: 0.4113 - val_loss: 0.6951 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.5212 - loss: 0.7788\n",
      "Epoch 6: val_loss improved from 0.68021 to 0.67996, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 445ms/step - accuracy: 0.5208 - loss: 0.7789 - val_accuracy: 0.6774 - val_loss: 0.6800 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.5417 - loss: 0.7406\n",
      "Epoch 7: val_loss did not improve from 0.67996\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 432ms/step - accuracy: 0.5414 - loss: 0.7408 - val_accuracy: 0.6694 - val_loss: 0.6826 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.5545 - loss: 0.7260\n",
      "Epoch 8: val_loss improved from 0.67996 to 0.67921, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5540 - loss: 0.7263 - val_accuracy: 0.6613 - val_loss: 0.6792 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.4543 - loss: 0.8009\n",
      "Epoch 9: val_loss improved from 0.67921 to 0.67269, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.4548 - loss: 0.8003 - val_accuracy: 0.6774 - val_loss: 0.6727 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.5115 - loss: 0.7257\n",
      "Epoch 10: val_loss did not improve from 0.67269\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 426ms/step - accuracy: 0.5117 - loss: 0.7257 - val_accuracy: 0.6452 - val_loss: 0.6804 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.5041 - loss: 0.7287\n",
      "Epoch 11: val_loss improved from 0.67269 to 0.66833, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5044 - loss: 0.7286 - val_accuracy: 0.6694 - val_loss: 0.6683 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.5167 - loss: 0.7158\n",
      "Epoch 12: val_loss did not improve from 0.66833\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 429ms/step - accuracy: 0.5168 - loss: 0.7158 - val_accuracy: 0.6452 - val_loss: 0.6772 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.5612 - loss: 0.6894\n",
      "Epoch 13: val_loss did not improve from 0.66833\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 428ms/step - accuracy: 0.5609 - loss: 0.6895 - val_accuracy: 0.6774 - val_loss: 0.6743 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.5004 - loss: 0.7201\n",
      "Epoch 14: val_loss improved from 0.66833 to 0.66622, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.5009 - loss: 0.7200 - val_accuracy: 0.6855 - val_loss: 0.6662 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.5453 - loss: 0.6964\n",
      "Epoch 15: val_loss did not improve from 0.66622\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 424ms/step - accuracy: 0.5451 - loss: 0.6965 - val_accuracy: 0.6371 - val_loss: 0.6749 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.5277 - loss: 0.7094\n",
      "Epoch 16: val_loss did not improve from 0.66622\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 425ms/step - accuracy: 0.5278 - loss: 0.7093 - val_accuracy: 0.6452 - val_loss: 0.6728 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.5141 - loss: 0.7016\n",
      "Epoch 17: val_loss did not improve from 0.66622\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 428ms/step - accuracy: 0.5140 - loss: 0.7017 - val_accuracy: 0.6694 - val_loss: 0.6695 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.5382 - loss: 0.6960\n",
      "Epoch 18: val_loss did not improve from 0.66622\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 429ms/step - accuracy: 0.5379 - loss: 0.6961 - val_accuracy: 0.6613 - val_loss: 0.6682 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.5286 - loss: 0.7087\n",
      "Epoch 19: val_loss improved from 0.66622 to 0.66105, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 443ms/step - accuracy: 0.5285 - loss: 0.7086 - val_accuracy: 0.7097 - val_loss: 0.6610 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5365 - loss: 0.6929\n",
      "Epoch 20: val_loss improved from 0.66105 to 0.65335, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 449ms/step - accuracy: 0.5366 - loss: 0.6929 - val_accuracy: 0.6855 - val_loss: 0.6533 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.5789 - loss: 0.6809\n",
      "Epoch 21: val_loss did not improve from 0.65335\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 431ms/step - accuracy: 0.5787 - loss: 0.6810 - val_accuracy: 0.7016 - val_loss: 0.6609 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5928 - loss: 0.6701\n",
      "Epoch 22: val_loss did not improve from 0.65335\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 435ms/step - accuracy: 0.5926 - loss: 0.6702 - val_accuracy: 0.7097 - val_loss: 0.6566 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5714 - loss: 0.6781\n",
      "Epoch 23: val_loss did not improve from 0.65335\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 435ms/step - accuracy: 0.5710 - loss: 0.6782 - val_accuracy: 0.7016 - val_loss: 0.6571 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.5506 - loss: 0.6855\n",
      "Epoch 24: val_loss did not improve from 0.65335\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 434ms/step - accuracy: 0.5505 - loss: 0.6855 - val_accuracy: 0.6855 - val_loss: 0.6610 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5766 - loss: 0.6764\n",
      "Epoch 25: val_loss improved from 0.65335 to 0.65027, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 449ms/step - accuracy: 0.5766 - loss: 0.6764 - val_accuracy: 0.7258 - val_loss: 0.6503 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5754 - loss: 0.6647\n",
      "Epoch 26: val_loss improved from 0.65027 to 0.65002, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 447ms/step - accuracy: 0.5753 - loss: 0.6648 - val_accuracy: 0.7177 - val_loss: 0.6500 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5779 - loss: 0.6808\n",
      "Epoch 27: val_loss improved from 0.65002 to 0.64297, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.5781 - loss: 0.6807 - val_accuracy: 0.6855 - val_loss: 0.6430 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5464 - loss: 0.6831\n",
      "Epoch 28: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5465 - loss: 0.6831 - val_accuracy: 0.6855 - val_loss: 0.6447 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.5753 - loss: 0.6745\n",
      "Epoch 29: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 432ms/step - accuracy: 0.5755 - loss: 0.6745 - val_accuracy: 0.7016 - val_loss: 0.6482 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5881 - loss: 0.6700\n",
      "Epoch 30: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5879 - loss: 0.6701 - val_accuracy: 0.7258 - val_loss: 0.6444 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5693 - loss: 0.6811\n",
      "Epoch 31: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5695 - loss: 0.6810 - val_accuracy: 0.7258 - val_loss: 0.6438 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.6032 - loss: 0.6600\n",
      "Epoch 32: val_loss did not improve from 0.64297\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.6029 - loss: 0.6602 - val_accuracy: 0.7097 - val_loss: 0.6466 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5601 - loss: 0.6812\n",
      "Epoch 33: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5603 - loss: 0.6811 - val_accuracy: 0.7016 - val_loss: 0.6445 - learning_rate: 2.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5345 - loss: 0.6872\n",
      "Epoch 34: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5349 - loss: 0.6871 - val_accuracy: 0.7016 - val_loss: 0.6444 - learning_rate: 2.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.5811 - loss: 0.6675\n",
      "Epoch 35: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 438ms/step - accuracy: 0.5812 - loss: 0.6676 - val_accuracy: 0.7097 - val_loss: 0.6451 - learning_rate: 2.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5866 - loss: 0.6623\n",
      "Epoch 36: val_loss did not improve from 0.64297\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.5864 - loss: 0.6624 - val_accuracy: 0.7097 - val_loss: 0.6447 - learning_rate: 2.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5930 - loss: 0.6687\n",
      "Epoch 37: val_loss did not improve from 0.64297\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5927 - loss: 0.6688 - val_accuracy: 0.7097 - val_loss: 0.6433 - learning_rate: 2.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5785 - loss: 0.6749\n",
      "Epoch 38: val_loss improved from 0.64297 to 0.64293, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 448ms/step - accuracy: 0.5787 - loss: 0.6748 - val_accuracy: 0.7177 - val_loss: 0.6429 - learning_rate: 4.0000e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.5803 - loss: 0.6612\n",
      "Epoch 39: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 433ms/step - accuracy: 0.5803 - loss: 0.6613 - val_accuracy: 0.7097 - val_loss: 0.6431 - learning_rate: 4.0000e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.5930 - loss: 0.6618\n",
      "Epoch 40: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 434ms/step - accuracy: 0.5932 - loss: 0.6618 - val_accuracy: 0.7097 - val_loss: 0.6430 - learning_rate: 4.0000e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.5946 - loss: 0.6589\n",
      "Epoch 41: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 433ms/step - accuracy: 0.5943 - loss: 0.6590 - val_accuracy: 0.7097 - val_loss: 0.6432 - learning_rate: 4.0000e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.6018 - loss: 0.6627\n",
      "Epoch 42: val_loss did not improve from 0.64293\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 433ms/step - accuracy: 0.6020 - loss: 0.6627 - val_accuracy: 0.7097 - val_loss: 0.6431 - learning_rate: 4.0000e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.6000 - loss: 0.6633\n",
      "Epoch 43: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 435ms/step - accuracy: 0.5999 - loss: 0.6634 - val_accuracy: 0.7097 - val_loss: 0.6431 - learning_rate: 8.0000e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.6035 - loss: 0.6657\n",
      "Epoch 44: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 435ms/step - accuracy: 0.6033 - loss: 0.6658 - val_accuracy: 0.7097 - val_loss: 0.6432 - learning_rate: 8.0000e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5359 - loss: 0.6876\n",
      "Epoch 45: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 435ms/step - accuracy: 0.5363 - loss: 0.6875 - val_accuracy: 0.7097 - val_loss: 0.6432 - learning_rate: 8.0000e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5726 - loss: 0.6723\n",
      "Epoch 46: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5726 - loss: 0.6723 - val_accuracy: 0.7097 - val_loss: 0.6432 - learning_rate: 8.0000e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5761 - loss: 0.6701\n",
      "Epoch 47: val_loss did not improve from 0.64293\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.5764 - loss: 0.6701 - val_accuracy: 0.7097 - val_loss: 0.6431 - learning_rate: 8.0000e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.6149 - loss: 0.6545\n",
      "Epoch 48: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 435ms/step - accuracy: 0.6147 - loss: 0.6547 - val_accuracy: 0.7097 - val_loss: 0.6431 - learning_rate: 1.6000e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.6053 - loss: 0.6702\n",
      "Epoch 49: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 436ms/step - accuracy: 0.6049 - loss: 0.6702 - val_accuracy: 0.7097 - val_loss: 0.6431 - learning_rate: 1.6000e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.5688 - loss: 0.6758\n",
      "Epoch 50: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 433ms/step - accuracy: 0.5687 - loss: 0.6758 - val_accuracy: 0.7097 - val_loss: 0.6431 - learning_rate: 1.6000e-07\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 51/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913ms/step - accuracy: 0.5691 - loss: 2.3056\n",
      "Epoch 51: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 996ms/step - accuracy: 0.5700 - loss: 2.2908 - val_accuracy: 0.4113 - val_loss: 1.0452 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950ms/step - accuracy: 0.7192 - loss: 0.5623\n",
      "Epoch 52: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.7193 - loss: 0.5624 - val_accuracy: 0.4113 - val_loss: 1.5490 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971ms/step - accuracy: 0.7618 - loss: 0.4775\n",
      "Epoch 53: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.7619 - loss: 0.4776 - val_accuracy: 0.4113 - val_loss: 2.5886 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978ms/step - accuracy: 0.7725 - loss: 0.4853\n",
      "Epoch 54: val_loss did not improve from 0.64293\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.7726 - loss: 0.4849 - val_accuracy: 0.4113 - val_loss: 1.7406 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979ms/step - accuracy: 0.7788 - loss: 0.4516\n",
      "Epoch 55: val_loss improved from 0.64293 to 0.59462, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.7793 - loss: 0.4511 - val_accuracy: 0.6129 - val_loss: 0.5946 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945ms/step - accuracy: 0.8026 - loss: 0.4411\n",
      "Epoch 56: val_loss improved from 0.59462 to 0.41617, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8028 - loss: 0.4409 - val_accuracy: 0.9194 - val_loss: 0.4162 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956ms/step - accuracy: 0.8340 - loss: 0.3752\n",
      "Epoch 57: val_loss improved from 0.41617 to 0.29899, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8341 - loss: 0.3751 - val_accuracy: 0.9435 - val_loss: 0.2990 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978ms/step - accuracy: 0.8457 - loss: 0.3807\n",
      "Epoch 58: val_loss did not improve from 0.29899\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8456 - loss: 0.3807 - val_accuracy: 0.7661 - val_loss: 0.4681 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982ms/step - accuracy: 0.8298 - loss: 0.4294\n",
      "Epoch 59: val_loss did not improve from 0.29899\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8300 - loss: 0.4285 - val_accuracy: 0.8145 - val_loss: 0.4615 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988ms/step - accuracy: 0.8795 - loss: 0.3142\n",
      "Epoch 60: val_loss did not improve from 0.29899\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8795 - loss: 0.3142 - val_accuracy: 0.7984 - val_loss: 0.4472 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - accuracy: 0.8886 - loss: 0.3175\n",
      "Epoch 61: val_loss improved from 0.29899 to 0.22950, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.8884 - loss: 0.3176 - val_accuracy: 0.9194 - val_loss: 0.2295 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981ms/step - accuracy: 0.8593 - loss: 0.3207\n",
      "Epoch 62: val_loss improved from 0.22950 to 0.21638, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8591 - loss: 0.3211 - val_accuracy: 0.9355 - val_loss: 0.2164 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979ms/step - accuracy: 0.8851 - loss: 0.2868\n",
      "Epoch 63: val_loss did not improve from 0.21638\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8850 - loss: 0.2871 - val_accuracy: 0.8952 - val_loss: 0.2202 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977ms/step - accuracy: 0.8889 - loss: 0.2793\n",
      "Epoch 64: val_loss did not improve from 0.21638\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8888 - loss: 0.2797 - val_accuracy: 0.9194 - val_loss: 0.2310 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970ms/step - accuracy: 0.8636 - loss: 0.2989\n",
      "Epoch 65: val_loss did not improve from 0.21638\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8638 - loss: 0.2989 - val_accuracy: 0.9032 - val_loss: 0.2684 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977ms/step - accuracy: 0.8777 - loss: 0.2821\n",
      "Epoch 66: val_loss did not improve from 0.21638\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8776 - loss: 0.2825 - val_accuracy: 0.8548 - val_loss: 0.3395 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972ms/step - accuracy: 0.8804 - loss: 0.2705\n",
      "Epoch 67: val_loss improved from 0.21638 to 0.20210, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8804 - loss: 0.2708 - val_accuracy: 0.9274 - val_loss: 0.2021 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972ms/step - accuracy: 0.8583 - loss: 0.3471\n",
      "Epoch 68: val_loss did not improve from 0.20210\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8585 - loss: 0.3464 - val_accuracy: 0.9032 - val_loss: 0.2320 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971ms/step - accuracy: 0.8801 - loss: 0.2740\n",
      "Epoch 69: val_loss did not improve from 0.20210\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8800 - loss: 0.2742 - val_accuracy: 0.8468 - val_loss: 0.4218 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973ms/step - accuracy: 0.9028 - loss: 0.2667\n",
      "Epoch 70: val_loss did not improve from 0.20210\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9028 - loss: 0.2663 - val_accuracy: 0.9435 - val_loss: 0.2161 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971ms/step - accuracy: 0.8955 - loss: 0.2542\n",
      "Epoch 71: val_loss did not improve from 0.20210\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8954 - loss: 0.2542 - val_accuracy: 0.9355 - val_loss: 0.2172 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967ms/step - accuracy: 0.8947 - loss: 0.2333\n",
      "Epoch 72: val_loss did not improve from 0.20210\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8947 - loss: 0.2335 - val_accuracy: 0.8629 - val_loss: 0.3749 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968ms/step - accuracy: 0.8763 - loss: 0.2813\n",
      "Epoch 73: val_loss did not improve from 0.20210\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8766 - loss: 0.2807 - val_accuracy: 0.9113 - val_loss: 0.2172 - learning_rate: 2.0000e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970ms/step - accuracy: 0.9077 - loss: 0.2325\n",
      "Epoch 74: val_loss did not improve from 0.20210\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9076 - loss: 0.2325 - val_accuracy: 0.8952 - val_loss: 0.2146 - learning_rate: 2.0000e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971ms/step - accuracy: 0.9090 - loss: 0.2151\n",
      "Epoch 75: val_loss improved from 0.20210 to 0.19903, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9090 - loss: 0.2151 - val_accuracy: 0.9355 - val_loss: 0.1990 - learning_rate: 2.0000e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.9068 - loss: 0.2436\n",
      "Epoch 76: val_loss improved from 0.19903 to 0.19487, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9067 - loss: 0.2436 - val_accuracy: 0.9355 - val_loss: 0.1949 - learning_rate: 2.0000e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968ms/step - accuracy: 0.9160 - loss: 0.2031\n",
      "Epoch 77: val_loss did not improve from 0.19487\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9160 - loss: 0.2032 - val_accuracy: 0.9032 - val_loss: 0.2535 - learning_rate: 2.0000e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.9156 - loss: 0.2127\n",
      "Epoch 78: val_loss improved from 0.19487 to 0.19371, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9155 - loss: 0.2128 - val_accuracy: 0.9355 - val_loss: 0.1937 - learning_rate: 2.0000e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968ms/step - accuracy: 0.9071 - loss: 0.2360\n",
      "Epoch 79: val_loss improved from 0.19371 to 0.18333, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9071 - loss: 0.2361 - val_accuracy: 0.9274 - val_loss: 0.1833 - learning_rate: 2.0000e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973ms/step - accuracy: 0.9246 - loss: 0.1940\n",
      "Epoch 80: val_loss improved from 0.18333 to 0.17812, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9245 - loss: 0.1943 - val_accuracy: 0.9435 - val_loss: 0.1781 - learning_rate: 2.0000e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966ms/step - accuracy: 0.9260 - loss: 0.1785\n",
      "Epoch 81: val_loss improved from 0.17812 to 0.17739, saving model to results\\ResNet50_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9259 - loss: 0.1787 - val_accuracy: 0.9355 - val_loss: 0.1774 - learning_rate: 2.0000e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966ms/step - accuracy: 0.9000 - loss: 0.2126\n",
      "Epoch 82: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9002 - loss: 0.2124 - val_accuracy: 0.9032 - val_loss: 0.2451 - learning_rate: 2.0000e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967ms/step - accuracy: 0.9292 - loss: 0.1780\n",
      "Epoch 83: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9291 - loss: 0.1781 - val_accuracy: 0.9194 - val_loss: 0.1992 - learning_rate: 2.0000e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967ms/step - accuracy: 0.9144 - loss: 0.2270\n",
      "Epoch 84: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9145 - loss: 0.2267 - val_accuracy: 0.9113 - val_loss: 0.1964 - learning_rate: 2.0000e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.9063 - loss: 0.1953\n",
      "Epoch 85: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9064 - loss: 0.1952 - val_accuracy: 0.9274 - val_loss: 0.1906 - learning_rate: 2.0000e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967ms/step - accuracy: 0.9375 - loss: 0.1813\n",
      "Epoch 86: val_loss did not improve from 0.17739\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9375 - loss: 0.1813 - val_accuracy: 0.9355 - val_loss: 0.1899 - learning_rate: 2.0000e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.9453 - loss: 0.1574\n",
      "Epoch 87: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9452 - loss: 0.1575 - val_accuracy: 0.9194 - val_loss: 0.1924 - learning_rate: 4.0000e-07\n",
      "Epoch 88/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967ms/step - accuracy: 0.9320 - loss: 0.1850\n",
      "Epoch 88: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9320 - loss: 0.1849 - val_accuracy: 0.9194 - val_loss: 0.1901 - learning_rate: 4.0000e-07\n",
      "Epoch 89/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971ms/step - accuracy: 0.9107 - loss: 0.2118\n",
      "Epoch 89: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9106 - loss: 0.2118 - val_accuracy: 0.9194 - val_loss: 0.1890 - learning_rate: 4.0000e-07\n",
      "Epoch 90/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970ms/step - accuracy: 0.9193 - loss: 0.1822\n",
      "Epoch 90: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9192 - loss: 0.1825 - val_accuracy: 0.9194 - val_loss: 0.1850 - learning_rate: 4.0000e-07\n",
      "Epoch 91/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.9423 - loss: 0.1557\n",
      "Epoch 91: val_loss did not improve from 0.17739\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9420 - loss: 0.1562 - val_accuracy: 0.9194 - val_loss: 0.1796 - learning_rate: 4.0000e-07\n",
      "Epoch 92/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968ms/step - accuracy: 0.9360 - loss: 0.1700\n",
      "Epoch 92: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9359 - loss: 0.1701 - val_accuracy: 0.9194 - val_loss: 0.1790 - learning_rate: 8.0000e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968ms/step - accuracy: 0.9287 - loss: 0.1858\n",
      "Epoch 93: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9285 - loss: 0.1861 - val_accuracy: 0.9194 - val_loss: 0.1798 - learning_rate: 8.0000e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974ms/step - accuracy: 0.9290 - loss: 0.1709\n",
      "Epoch 94: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9290 - loss: 0.1710 - val_accuracy: 0.9274 - val_loss: 0.1802 - learning_rate: 8.0000e-08\n",
      "Epoch 95/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967ms/step - accuracy: 0.9221 - loss: 0.1916\n",
      "Epoch 95: val_loss did not improve from 0.17739\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9221 - loss: 0.1915 - val_accuracy: 0.9274 - val_loss: 0.1806 - learning_rate: 8.0000e-08\n",
      "Epoch 96/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.9330 - loss: 0.1799\n",
      "Epoch 96: val_loss did not improve from 0.17739\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.5999999902760466e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9329 - loss: 0.1800 - val_accuracy: 0.9274 - val_loss: 0.1814 - learning_rate: 8.0000e-08\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet50_full_monty_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 790ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.96      0.83      0.89       103\n",
      "Shoot and Fruit Borer       0.89      0.97      0.93       145\n",
      "\n",
      "             accuracy                           0.91       248\n",
      "            macro avg       0.92      0.90      0.91       248\n",
      "         weighted avg       0.92      0.91      0.91       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet50_full_monty_bs16 is complete. Total time: 01:14:26 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet50\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd28a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet152_from_scratch_bs16 ---\n",
      "Mode: from_scratch, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Training from Scratch ---\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6169 - loss: 1.0801\n",
      "Epoch 1: val_loss improved from inf to 1.96719, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 4s/step - accuracy: 0.6170 - loss: 1.0792 - val_accuracy: 0.5887 - val_loss: 1.9672 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6008 - loss: 1.0304\n",
      "Epoch 2: val_loss did not improve from 1.96719\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.6009 - loss: 1.0292 - val_accuracy: 0.5887 - val_loss: 5.2653 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7174 - loss: 0.7239\n",
      "Epoch 3: val_loss did not improve from 1.96719\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 4s/step - accuracy: 0.7175 - loss: 0.7243 - val_accuracy: 0.5887 - val_loss: 6.0969 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6955 - loss: 0.7084\n",
      "Epoch 4: val_loss did not improve from 1.96719\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.6957 - loss: 0.7088 - val_accuracy: 0.5887 - val_loss: 9.1157 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7616 - loss: 0.5819\n",
      "Epoch 5: val_loss did not improve from 1.96719\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.7615 - loss: 0.5818 - val_accuracy: 0.5887 - val_loss: 8.0538 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7933 - loss: 0.5505\n",
      "Epoch 6: val_loss did not improve from 1.96719\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.7929 - loss: 0.5517 - val_accuracy: 0.5887 - val_loss: 8.6194 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7398 - loss: 0.6433\n",
      "Epoch 7: val_loss did not improve from 1.96719\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.7400 - loss: 0.6432 - val_accuracy: 0.5887 - val_loss: 5.1408 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7859 - loss: 0.5564\n",
      "Epoch 8: val_loss did not improve from 1.96719\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 4s/step - accuracy: 0.7856 - loss: 0.5567 - val_accuracy: 0.5887 - val_loss: 3.8592 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8007 - loss: 0.5807\n",
      "Epoch 9: val_loss did not improve from 1.96719\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.8008 - loss: 0.5799 - val_accuracy: 0.5887 - val_loss: 2.0727 - learning_rate: 2.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8095 - loss: 0.4650\n",
      "Epoch 10: val_loss improved from 1.96719 to 0.61351, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.8095 - loss: 0.4649 - val_accuracy: 0.6935 - val_loss: 0.6135 - learning_rate: 2.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7796 - loss: 0.5030\n",
      "Epoch 11: val_loss improved from 0.61351 to 0.51342, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 4s/step - accuracy: 0.7800 - loss: 0.5023 - val_accuracy: 0.8065 - val_loss: 0.5134 - learning_rate: 2.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8003 - loss: 0.4659\n",
      "Epoch 12: val_loss improved from 0.51342 to 0.30843, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.8004 - loss: 0.4661 - val_accuracy: 0.8629 - val_loss: 0.3084 - learning_rate: 2.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8212 - loss: 0.4619\n",
      "Epoch 13: val_loss improved from 0.30843 to 0.28797, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.8212 - loss: 0.4620 - val_accuracy: 0.9032 - val_loss: 0.2880 - learning_rate: 2.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8158 - loss: 0.4449\n",
      "Epoch 14: val_loss did not improve from 0.28797\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8159 - loss: 0.4451 - val_accuracy: 0.9113 - val_loss: 0.3078 - learning_rate: 2.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8182 - loss: 0.4118\n",
      "Epoch 15: val_loss did not improve from 0.28797\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.8183 - loss: 0.4121 - val_accuracy: 0.8548 - val_loss: 0.3304 - learning_rate: 2.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8086 - loss: 0.4963\n",
      "Epoch 16: val_loss improved from 0.28797 to 0.27359, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.8086 - loss: 0.4960 - val_accuracy: 0.8952 - val_loss: 0.2736 - learning_rate: 2.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8673 - loss: 0.3733\n",
      "Epoch 17: val_loss did not improve from 0.27359\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 4s/step - accuracy: 0.8668 - loss: 0.3741 - val_accuracy: 0.8548 - val_loss: 0.2961 - learning_rate: 2.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8111 - loss: 0.4352\n",
      "Epoch 18: val_loss improved from 0.27359 to 0.26917, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 4s/step - accuracy: 0.8113 - loss: 0.4347 - val_accuracy: 0.9032 - val_loss: 0.2692 - learning_rate: 2.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8173 - loss: 0.4148\n",
      "Epoch 19: val_loss did not improve from 0.26917\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 4s/step - accuracy: 0.8174 - loss: 0.4150 - val_accuracy: 0.8790 - val_loss: 0.3335 - learning_rate: 2.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8092 - loss: 0.4696\n",
      "Epoch 20: val_loss improved from 0.26917 to 0.22096, saving model to results\\ResNet152_from_scratch_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 4s/step - accuracy: 0.8093 - loss: 0.4693 - val_accuracy: 0.9032 - val_loss: 0.2210 - learning_rate: 2.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8276 - loss: 0.4224\n",
      "Epoch 21: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.8275 - loss: 0.4227 - val_accuracy: 0.8952 - val_loss: 0.2586 - learning_rate: 2.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8292 - loss: 0.4009\n",
      "Epoch 22: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8292 - loss: 0.4010 - val_accuracy: 0.9032 - val_loss: 0.2571 - learning_rate: 2.0000e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8426 - loss: 0.3727\n",
      "Epoch 23: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8424 - loss: 0.3733 - val_accuracy: 0.8871 - val_loss: 0.3183 - learning_rate: 2.0000e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8213 - loss: 0.4631\n",
      "Epoch 24: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8213 - loss: 0.4628 - val_accuracy: 0.8952 - val_loss: 0.2894 - learning_rate: 2.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8634 - loss: 0.3630\n",
      "Epoch 25: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8630 - loss: 0.3635 - val_accuracy: 0.8710 - val_loss: 0.2836 - learning_rate: 2.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8295 - loss: 0.3903\n",
      "Epoch 26: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8294 - loss: 0.3904 - val_accuracy: 0.8548 - val_loss: 0.3308 - learning_rate: 2.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8199 - loss: 0.4436\n",
      "Epoch 27: val_loss did not improve from 0.22096\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 4s/step - accuracy: 0.8200 - loss: 0.4438 - val_accuracy: 0.9113 - val_loss: 0.2553 - learning_rate: 2.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8515 - loss: 0.3400\n",
      "Epoch 28: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8512 - loss: 0.3405 - val_accuracy: 0.8790 - val_loss: 0.2568 - learning_rate: 4.0000e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8432 - loss: 0.3968\n",
      "Epoch 29: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8432 - loss: 0.3968 - val_accuracy: 0.8871 - val_loss: 0.2603 - learning_rate: 4.0000e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8205 - loss: 0.4251\n",
      "Epoch 30: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8205 - loss: 0.4249 - val_accuracy: 0.8710 - val_loss: 0.2551 - learning_rate: 4.0000e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8522 - loss: 0.4228\n",
      "Epoch 31: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8520 - loss: 0.4227 - val_accuracy: 0.8710 - val_loss: 0.2651 - learning_rate: 4.0000e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8401 - loss: 0.4222\n",
      "Epoch 32: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8399 - loss: 0.4226 - val_accuracy: 0.8871 - val_loss: 0.2533 - learning_rate: 4.0000e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8462 - loss: 0.3704\n",
      "Epoch 33: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8461 - loss: 0.3705 - val_accuracy: 0.8710 - val_loss: 0.2431 - learning_rate: 4.0000e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8290 - loss: 0.4306\n",
      "Epoch 34: val_loss did not improve from 0.22096\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8293 - loss: 0.4297 - val_accuracy: 0.8629 - val_loss: 0.2470 - learning_rate: 4.0000e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8689 - loss: 0.3225\n",
      "Epoch 35: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 4s/step - accuracy: 0.8687 - loss: 0.3233 - val_accuracy: 0.8629 - val_loss: 0.2545 - learning_rate: 8.0000e-07\n",
      "Epoch 36/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8649 - loss: 0.3228\n",
      "Epoch 36: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.8649 - loss: 0.3230 - val_accuracy: 0.8871 - val_loss: 0.2561 - learning_rate: 8.0000e-07\n",
      "Epoch 37/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8310 - loss: 0.4029\n",
      "Epoch 37: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.8311 - loss: 0.4026 - val_accuracy: 0.8710 - val_loss: 0.2526 - learning_rate: 8.0000e-07\n",
      "Epoch 38/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8599 - loss: 0.3632\n",
      "Epoch 38: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 4s/step - accuracy: 0.8600 - loss: 0.3631 - val_accuracy: 0.8710 - val_loss: 0.2640 - learning_rate: 8.0000e-07\n",
      "Epoch 39/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8379 - loss: 0.3584\n",
      "Epoch 39: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 4s/step - accuracy: 0.8380 - loss: 0.3585 - val_accuracy: 0.9032 - val_loss: 0.2474 - learning_rate: 8.0000e-07\n",
      "Epoch 40/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8269 - loss: 0.4265\n",
      "Epoch 40: val_loss did not improve from 0.22096\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 4s/step - accuracy: 0.8272 - loss: 0.4260 - val_accuracy: 0.8790 - val_loss: 0.2451 - learning_rate: 8.0000e-07\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet152_from_scratch_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.91      0.83      0.87       103\n",
      "Shoot and Fruit Borer       0.89      0.94      0.91       145\n",
      "\n",
      "             accuracy                           0.90       248\n",
      "            macro avg       0.90      0.89      0.89       248\n",
      "         weighted avg       0.90      0.90      0.89       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet152_from_scratch_bs16 is complete. Total time: 02:54:34 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet152\",\n",
    "    training_mode='from_scratch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d168e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet152_transfer_learning_bs16 ---\n",
      "Mode: transfer_learning, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Transfer Learning ---\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m234698864/234698864\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 0us/step\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.5044 - loss: 0.9298 - val_accuracy: 0.5726 - val_loss: 0.6742\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4665 - loss: 0.8445 - val_accuracy: 0.6129 - val_loss: 0.6799\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.5497 - loss: 0.7744 - val_accuracy: 0.5968 - val_loss: 0.6891\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.5289 - loss: 0.7698 - val_accuracy: 0.6210 - val_loss: 0.6833\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4657 - loss: 0.7963 - val_accuracy: 0.6048 - val_loss: 0.6873\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.4982 - loss: 0.7729 - val_accuracy: 0.5968 - val_loss: 0.6839\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.5201 - loss: 0.7497 - val_accuracy: 0.5887 - val_loss: 0.6885\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.5248 - loss: 0.7192 - val_accuracy: 0.6371 - val_loss: 0.6812\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.5402 - loss: 0.7305 - val_accuracy: 0.6210 - val_loss: 0.6806\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.5440 - loss: 0.7074 - val_accuracy: 0.6613 - val_loss: 0.6729\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.5319 - loss: 0.6953 - val_accuracy: 0.6129 - val_loss: 0.6789\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.5110 - loss: 0.7208 - val_accuracy: 0.6774 - val_loss: 0.6720\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.5332 - loss: 0.7128 - val_accuracy: 0.6855 - val_loss: 0.6711\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5135 - loss: 0.6995 - val_accuracy: 0.6613 - val_loss: 0.6720\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.5568 - loss: 0.6783 - val_accuracy: 0.6613 - val_loss: 0.6652\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.5041 - loss: 0.7174 - val_accuracy: 0.6613 - val_loss: 0.6661\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.5177 - loss: 0.7020 - val_accuracy: 0.6290 - val_loss: 0.6738\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.5589 - loss: 0.6970 - val_accuracy: 0.6694 - val_loss: 0.6625\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5358 - loss: 0.6894 - val_accuracy: 0.6855 - val_loss: 0.6641\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5453 - loss: 0.6791 - val_accuracy: 0.6935 - val_loss: 0.6655\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6128 - loss: 0.6664 - val_accuracy: 0.6935 - val_loss: 0.6682\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5778 - loss: 0.6767 - val_accuracy: 0.7016 - val_loss: 0.6612\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5588 - loss: 0.6819 - val_accuracy: 0.6532 - val_loss: 0.6682\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6100 - loss: 0.6645 - val_accuracy: 0.6935 - val_loss: 0.6619\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6005 - loss: 0.6672 - val_accuracy: 0.6855 - val_loss: 0.6622\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5885 - loss: 0.6734 - val_accuracy: 0.7016 - val_loss: 0.6590\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5930 - loss: 0.6675 - val_accuracy: 0.6935 - val_loss: 0.6599\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5786 - loss: 0.6804 - val_accuracy: 0.6935 - val_loss: 0.6631\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6150 - loss: 0.6665 - val_accuracy: 0.7097 - val_loss: 0.6549\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.6022 - loss: 0.6611 - val_accuracy: 0.6855 - val_loss: 0.6500\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6206 - loss: 0.6587 - val_accuracy: 0.6935 - val_loss: 0.6523\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6153 - loss: 0.6508 - val_accuracy: 0.7016 - val_loss: 0.6536\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.5832 - loss: 0.6683 - val_accuracy: 0.7097 - val_loss: 0.6518\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6110 - loss: 0.6619 - val_accuracy: 0.7016 - val_loss: 0.6497\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6155 - loss: 0.6670 - val_accuracy: 0.7016 - val_loss: 0.6508\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6007 - loss: 0.6605 - val_accuracy: 0.6855 - val_loss: 0.6463\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6292 - loss: 0.6550 - val_accuracy: 0.7016 - val_loss: 0.6508\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.5873 - loss: 0.6649 - val_accuracy: 0.6855 - val_loss: 0.6447\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6439 - loss: 0.6514 - val_accuracy: 0.7016 - val_loss: 0.6497\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.6137 - loss: 0.6609 - val_accuracy: 0.6855 - val_loss: 0.6409\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.6338 - loss: 0.6427 - val_accuracy: 0.6935 - val_loss: 0.6421\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.6048 - loss: 0.6672 - val_accuracy: 0.7097 - val_loss: 0.6434\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6447 - loss: 0.6450 - val_accuracy: 0.7177 - val_loss: 0.6431\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.6414 - loss: 0.6474 - val_accuracy: 0.7097 - val_loss: 0.6417\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.5699 - loss: 0.6692 - val_accuracy: 0.6855 - val_loss: 0.6370\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6236 - loss: 0.6492 - val_accuracy: 0.6935 - val_loss: 0.6387\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6082 - loss: 0.6531 - val_accuracy: 0.7177 - val_loss: 0.6398\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6538 - loss: 0.6472 - val_accuracy: 0.6935 - val_loss: 0.6372\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6107 - loss: 0.6648 - val_accuracy: 0.7016 - val_loss: 0.6372\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6778 - loss: 0.6401 - val_accuracy: 0.7016 - val_loss: 0.6362\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet152_transfer_learning_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.70      0.55      0.62       103\n",
      "Shoot and Fruit Borer       0.72      0.83      0.78       145\n",
      "\n",
      "             accuracy                           0.72       248\n",
      "            macro avg       0.71      0.69      0.70       248\n",
      "         weighted avg       0.72      0.72      0.71       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet152_transfer_learning_bs16 is complete. Total time: 01:01:02 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet152\",\n",
    "    training_mode='transfer_learning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dc4eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet152_fine_tune_bs16 ---\n",
      "Mode: fine_tune, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Fine Tune ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.5075 - loss: 1.3522 - val_accuracy: 0.5887 - val_loss: 0.7087\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5266 - loss: 0.9017 - val_accuracy: 0.5887 - val_loss: 0.6713\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5304 - loss: 0.8623 - val_accuracy: 0.4274 - val_loss: 0.6917\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5226 - loss: 0.8527 - val_accuracy: 0.5968 - val_loss: 0.6849\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.4901 - loss: 0.8190 - val_accuracy: 0.6694 - val_loss: 0.6817\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5017 - loss: 0.8065 - val_accuracy: 0.5887 - val_loss: 0.6848\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5087 - loss: 0.8110 - val_accuracy: 0.6935 - val_loss: 0.6775\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5125 - loss: 0.8002 - val_accuracy: 0.7016 - val_loss: 0.6753\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.4872 - loss: 0.7945 - val_accuracy: 0.6774 - val_loss: 0.6768\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5174 - loss: 0.7577 - val_accuracy: 0.4355 - val_loss: 0.6907\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5611 - loss: 0.7147 - val_accuracy: 0.6855 - val_loss: 0.6719\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5081 - loss: 0.7262 - val_accuracy: 0.6935 - val_loss: 0.6760\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5405 - loss: 0.7327 - val_accuracy: 0.7016 - val_loss: 0.6741\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5127 - loss: 0.7286 - val_accuracy: 0.6935 - val_loss: 0.6704\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.5421 - loss: 0.7144 - val_accuracy: 0.7016 - val_loss: 0.6739\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.4946 - loss: 0.7274 - val_accuracy: 0.6855 - val_loss: 0.6679\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5676 - loss: 0.7023 - val_accuracy: 0.6855 - val_loss: 0.6657\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5074 - loss: 0.7010 - val_accuracy: 0.6935 - val_loss: 0.6715\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5355 - loss: 0.6916 - val_accuracy: 0.7016 - val_loss: 0.6659\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5370 - loss: 0.6918 - val_accuracy: 0.7016 - val_loss: 0.6645\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5537 - loss: 0.6888 - val_accuracy: 0.7016 - val_loss: 0.6632\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5684 - loss: 0.6856 - val_accuracy: 0.7016 - val_loss: 0.6590\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5877 - loss: 0.6766 - val_accuracy: 0.7177 - val_loss: 0.6642\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5568 - loss: 0.6826 - val_accuracy: 0.6935 - val_loss: 0.6583\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5930 - loss: 0.6688 - val_accuracy: 0.6855 - val_loss: 0.6549\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.5488 - loss: 0.6892 - val_accuracy: 0.7016 - val_loss: 0.6558\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5993 - loss: 0.6654 - val_accuracy: 0.6694 - val_loss: 0.6518\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6176 - loss: 0.6643 - val_accuracy: 0.7097 - val_loss: 0.6630\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5846 - loss: 0.6631 - val_accuracy: 0.6694 - val_loss: 0.6484\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 2s/step - accuracy: 0.5904 - loss: 0.6665 - val_accuracy: 0.7177 - val_loss: 0.6576\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.5966 - loss: 0.6675 - val_accuracy: 0.7016 - val_loss: 0.6516\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5947 - loss: 0.6664 - val_accuracy: 0.6774 - val_loss: 0.6482\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5861 - loss: 0.6691 - val_accuracy: 0.7097 - val_loss: 0.6547\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6114 - loss: 0.6597 - val_accuracy: 0.7097 - val_loss: 0.6487\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5997 - loss: 0.6583 - val_accuracy: 0.7097 - val_loss: 0.6475\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6212 - loss: 0.6553 - val_accuracy: 0.6855 - val_loss: 0.6489\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6086 - loss: 0.6621 - val_accuracy: 0.7097 - val_loss: 0.6455\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6194 - loss: 0.6657 - val_accuracy: 0.7097 - val_loss: 0.6453\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6044 - loss: 0.6573 - val_accuracy: 0.7339 - val_loss: 0.6533\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5576 - loss: 0.6738 - val_accuracy: 0.7016 - val_loss: 0.6463\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6324 - loss: 0.6527 - val_accuracy: 0.7097 - val_loss: 0.6434\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.6157 - loss: 0.6519 - val_accuracy: 0.7097 - val_loss: 0.6483\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5968 - loss: 0.6626 - val_accuracy: 0.7177 - val_loss: 0.6454\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6014 - loss: 0.6610 - val_accuracy: 0.6935 - val_loss: 0.6431\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6047 - loss: 0.6664 - val_accuracy: 0.7016 - val_loss: 0.6410\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6097 - loss: 0.6653 - val_accuracy: 0.7097 - val_loss: 0.6395\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.6211 - loss: 0.6489 - val_accuracy: 0.7097 - val_loss: 0.6444\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.6232 - loss: 0.6654 - val_accuracy: 0.7177 - val_loss: 0.6370\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.6297 - loss: 0.6535 - val_accuracy: 0.7016 - val_loss: 0.6386\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.6208 - loss: 0.6546 - val_accuracy: 0.7016 - val_loss: 0.6378\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet152_fine_tune_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.71      0.52      0.60       103\n",
      "Shoot and Fruit Borer       0.72      0.85      0.78       145\n",
      "\n",
      "             accuracy                           0.71       248\n",
      "            macro avg       0.71      0.69      0.69       248\n",
      "         weighted avg       0.71      0.71      0.70       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet152_fine_tune_bs16 is complete. Total time: 01:51:00 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet152\",\n",
    "    training_mode='fine_tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d13fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "--- Starting Experiment: ResNet152_full_monty_bs16 ---\n",
      "Mode: full_monty, Batch Size: 16, LR: 0.0001, Input: 224x224\n",
      "================================================================================\n",
      "\n",
      "Loading data from 'processed_data\\BrinjalFruitX_224x224_balanced_classless'...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- CONFIGURATION: Full Monty ---\n",
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5131 - loss: 0.8203\n",
      "Epoch 1: val_loss improved from inf to 0.69498, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.5131 - loss: 0.8201 - val_accuracy: 0.5565 - val_loss: 0.6950 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5061 - loss: 0.8359\n",
      "Epoch 2: val_loss improved from 0.69498 to 0.68687, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.5062 - loss: 0.8355 - val_accuracy: 0.5887 - val_loss: 0.6869 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5261 - loss: 0.7846\n",
      "Epoch 3: val_loss improved from 0.68687 to 0.68378, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.5260 - loss: 0.7846 - val_accuracy: 0.5726 - val_loss: 0.6838 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4842 - loss: 0.7855\n",
      "Epoch 4: val_loss did not improve from 0.68378\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.4842 - loss: 0.7855 - val_accuracy: 0.5645 - val_loss: 0.6893 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5267 - loss: 0.7346\n",
      "Epoch 5: val_loss did not improve from 0.68378\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.5264 - loss: 0.7348 - val_accuracy: 0.5968 - val_loss: 0.6858 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5334 - loss: 0.7386\n",
      "Epoch 6: val_loss improved from 0.68378 to 0.67576, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.5333 - loss: 0.7383 - val_accuracy: 0.5726 - val_loss: 0.6758 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5179 - loss: 0.7487\n",
      "Epoch 7: val_loss did not improve from 0.67576\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5179 - loss: 0.7486 - val_accuracy: 0.6210 - val_loss: 0.6810 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5251 - loss: 0.7112\n",
      "Epoch 8: val_loss did not improve from 0.67576\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5253 - loss: 0.7112 - val_accuracy: 0.6371 - val_loss: 0.6778 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4855 - loss: 0.7190\n",
      "Epoch 9: val_loss did not improve from 0.67576\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.4856 - loss: 0.7191 - val_accuracy: 0.6613 - val_loss: 0.6773 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5381 - loss: 0.7163\n",
      "Epoch 10: val_loss did not improve from 0.67576\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5381 - loss: 0.7163 - val_accuracy: 0.6129 - val_loss: 0.6801 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5550 - loss: 0.6969\n",
      "Epoch 11: val_loss improved from 0.67576 to 0.67177, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5551 - loss: 0.6969 - val_accuracy: 0.6371 - val_loss: 0.6718 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5611 - loss: 0.6958\n",
      "Epoch 12: val_loss did not improve from 0.67177\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 0.6957 - val_accuracy: 0.6371 - val_loss: 0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 0.6959\n",
      "Epoch 13: val_loss did not improve from 0.67177\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 0.6958 - val_accuracy: 0.6694 - val_loss: 0.6726 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5251 - loss: 0.7038\n",
      "Epoch 14: val_loss improved from 0.67177 to 0.66481, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5251 - loss: 0.7038 - val_accuracy: 0.6129 - val_loss: 0.6648 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5561 - loss: 0.7042\n",
      "Epoch 15: val_loss did not improve from 0.66481\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.5561 - loss: 0.7042 - val_accuracy: 0.6371 - val_loss: 0.6664 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5552 - loss: 0.6899\n",
      "Epoch 16: val_loss did not improve from 0.66481\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5551 - loss: 0.6899 - val_accuracy: 0.6694 - val_loss: 0.6689 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5576 - loss: 0.6770\n",
      "Epoch 17: val_loss improved from 0.66481 to 0.66407, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5576 - loss: 0.6770 - val_accuracy: 0.6452 - val_loss: 0.6641 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5509 - loss: 0.6940\n",
      "Epoch 18: val_loss did not improve from 0.66407\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5508 - loss: 0.6940 - val_accuracy: 0.6935 - val_loss: 0.6669 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5869 - loss: 0.6625\n",
      "Epoch 19: val_loss did not improve from 0.66407\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.5867 - loss: 0.6627 - val_accuracy: 0.6452 - val_loss: 0.6642 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5748 - loss: 0.6751\n",
      "Epoch 20: val_loss did not improve from 0.66407\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5747 - loss: 0.6751 - val_accuracy: 0.6935 - val_loss: 0.6683 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5799 - loss: 0.6833\n",
      "Epoch 21: val_loss did not improve from 0.66407\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5800 - loss: 0.6832 - val_accuracy: 0.7016 - val_loss: 0.6666 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5856 - loss: 0.6723\n",
      "Epoch 22: val_loss improved from 0.66407 to 0.65869, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5855 - loss: 0.6723 - val_accuracy: 0.6452 - val_loss: 0.6587 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5962 - loss: 0.6797\n",
      "Epoch 23: val_loss did not improve from 0.65869\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.5960 - loss: 0.6796 - val_accuracy: 0.6935 - val_loss: 0.6655 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5443 - loss: 0.6819\n",
      "Epoch 24: val_loss did not improve from 0.65869\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.5446 - loss: 0.6817 - val_accuracy: 0.6935 - val_loss: 0.6651 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6197 - loss: 0.6657\n",
      "Epoch 25: val_loss improved from 0.65869 to 0.65637, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.6194 - loss: 0.6658 - val_accuracy: 0.6694 - val_loss: 0.6564 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5989 - loss: 0.6687\n",
      "Epoch 26: val_loss did not improve from 0.65637\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.5989 - loss: 0.6687 - val_accuracy: 0.7258 - val_loss: 0.6612 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5953 - loss: 0.6702\n",
      "Epoch 27: val_loss did not improve from 0.65637\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.5951 - loss: 0.6702 - val_accuracy: 0.6935 - val_loss: 0.6578 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5876 - loss: 0.6759\n",
      "Epoch 28: val_loss improved from 0.65637 to 0.65589, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5879 - loss: 0.6757 - val_accuracy: 0.6774 - val_loss: 0.6559 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5783 - loss: 0.6701\n",
      "Epoch 29: val_loss did not improve from 0.65589\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5785 - loss: 0.6702 - val_accuracy: 0.6935 - val_loss: 0.6564 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5741 - loss: 0.6714\n",
      "Epoch 30: val_loss improved from 0.65589 to 0.65527, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.5746 - loss: 0.6712 - val_accuracy: 0.6855 - val_loss: 0.6553 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5778 - loss: 0.6694\n",
      "Epoch 31: val_loss improved from 0.65527 to 0.65050, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.5781 - loss: 0.6693 - val_accuracy: 0.6774 - val_loss: 0.6505 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6008 - loss: 0.6661\n",
      "Epoch 32: val_loss did not improve from 0.65050\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6007 - loss: 0.6661 - val_accuracy: 0.6774 - val_loss: 0.6521 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5988 - loss: 0.6706\n",
      "Epoch 33: val_loss did not improve from 0.65050\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5987 - loss: 0.6706 - val_accuracy: 0.7177 - val_loss: 0.6546 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6253 - loss: 0.6524\n",
      "Epoch 34: val_loss improved from 0.65050 to 0.64661, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.6250 - loss: 0.6525 - val_accuracy: 0.6613 - val_loss: 0.6466 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5902 - loss: 0.6661\n",
      "Epoch 35: val_loss did not improve from 0.64661\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.5903 - loss: 0.6660 - val_accuracy: 0.6935 - val_loss: 0.6521 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5593 - loss: 0.6646\n",
      "Epoch 36: val_loss did not improve from 0.64661\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.5595 - loss: 0.6646 - val_accuracy: 0.7097 - val_loss: 0.6541 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6048 - loss: 0.6609\n",
      "Epoch 37: val_loss improved from 0.64661 to 0.64602, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.6047 - loss: 0.6608 - val_accuracy: 0.6774 - val_loss: 0.6460 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5891 - loss: 0.6643\n",
      "Epoch 38: val_loss improved from 0.64602 to 0.64492, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5894 - loss: 0.6642 - val_accuracy: 0.6774 - val_loss: 0.6449 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6059 - loss: 0.6480\n",
      "Epoch 39: val_loss did not improve from 0.64492\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.6058 - loss: 0.6481 - val_accuracy: 0.6855 - val_loss: 0.6485 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5960 - loss: 0.6621\n",
      "Epoch 40: val_loss did not improve from 0.64492\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.5961 - loss: 0.6621 - val_accuracy: 0.7177 - val_loss: 0.6503 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6316 - loss: 0.6598\n",
      "Epoch 41: val_loss improved from 0.64492 to 0.64147, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.6314 - loss: 0.6597 - val_accuracy: 0.6694 - val_loss: 0.6415 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6310 - loss: 0.6556\n",
      "Epoch 42: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6308 - loss: 0.6557 - val_accuracy: 0.7016 - val_loss: 0.6432 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5924 - loss: 0.6636\n",
      "Epoch 43: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5925 - loss: 0.6635 - val_accuracy: 0.6774 - val_loss: 0.6446 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6337 - loss: 0.6585\n",
      "Epoch 44: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6333 - loss: 0.6586 - val_accuracy: 0.7016 - val_loss: 0.6454 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6638 - loss: 0.6480\n",
      "Epoch 45: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6635 - loss: 0.6480 - val_accuracy: 0.7097 - val_loss: 0.6457 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6109 - loss: 0.6558\n",
      "Epoch 46: val_loss did not improve from 0.64147\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6110 - loss: 0.6557 - val_accuracy: 0.7177 - val_loss: 0.6500 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5975 - loss: 0.6585\n",
      "Epoch 47: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.5976 - loss: 0.6585 - val_accuracy: 0.7177 - val_loss: 0.6456 - learning_rate: 2.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6339 - loss: 0.6500\n",
      "Epoch 48: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6340 - loss: 0.6500 - val_accuracy: 0.7177 - val_loss: 0.6451 - learning_rate: 2.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6600 - loss: 0.6473\n",
      "Epoch 49: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6596 - loss: 0.6475 - val_accuracy: 0.6935 - val_loss: 0.6436 - learning_rate: 2.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6384 - loss: 0.6551\n",
      "Epoch 50: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6383 - loss: 0.6551 - val_accuracy: 0.6935 - val_loss: 0.6436 - learning_rate: 2.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\n",
      "--- STAGE 2: Fine-Tuning ---\n",
      "Epoch 51/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6424 - loss: 0.6669\n",
      "Epoch 51: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 3s/step - accuracy: 0.6422 - loss: 0.6671 - val_accuracy: 0.4113 - val_loss: 0.8542 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6320 - loss: 0.6972\n",
      "Epoch 52: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 3s/step - accuracy: 0.6320 - loss: 0.6970 - val_accuracy: 0.4113 - val_loss: 1.0470 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6442 - loss: 0.6805\n",
      "Epoch 53: val_loss did not improve from 0.64147\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 3s/step - accuracy: 0.6445 - loss: 0.6802 - val_accuracy: 0.4113 - val_loss: 0.7800 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6789 - loss: 0.6216\n",
      "Epoch 54: val_loss improved from 0.64147 to 0.60445, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - accuracy: 0.6791 - loss: 0.6215 - val_accuracy: 0.6935 - val_loss: 0.6045 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7180 - loss: 0.5906\n",
      "Epoch 55: val_loss improved from 0.60445 to 0.51628, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - accuracy: 0.7178 - loss: 0.5911 - val_accuracy: 0.7903 - val_loss: 0.5163 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7072 - loss: 0.6082\n",
      "Epoch 56: val_loss did not improve from 0.51628\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.7072 - loss: 0.6078 - val_accuracy: 0.6935 - val_loss: 0.6038 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7153 - loss: 0.5582\n",
      "Epoch 57: val_loss improved from 0.51628 to 0.43127, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.7155 - loss: 0.5581 - val_accuracy: 0.7661 - val_loss: 0.4313 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7434 - loss: 0.5441\n",
      "Epoch 58: val_loss improved from 0.43127 to 0.42390, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - accuracy: 0.7433 - loss: 0.5443 - val_accuracy: 0.8226 - val_loss: 0.4239 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7011 - loss: 0.5851\n",
      "Epoch 59: val_loss improved from 0.42390 to 0.38175, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.7017 - loss: 0.5843 - val_accuracy: 0.8468 - val_loss: 0.3818 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7235 - loss: 0.5328\n",
      "Epoch 60: val_loss did not improve from 0.38175\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.7239 - loss: 0.5324 - val_accuracy: 0.5403 - val_loss: 0.9582 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7745 - loss: 0.4839\n",
      "Epoch 61: val_loss did not improve from 0.38175\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - accuracy: 0.7741 - loss: 0.4843 - val_accuracy: 0.6129 - val_loss: 0.9549 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7864 - loss: 0.4692\n",
      "Epoch 62: val_loss did not improve from 0.38175\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - accuracy: 0.7862 - loss: 0.4695 - val_accuracy: 0.7823 - val_loss: 0.4494 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7585 - loss: 0.5070\n",
      "Epoch 63: val_loss did not improve from 0.38175\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.7586 - loss: 0.5070 - val_accuracy: 0.4435 - val_loss: 1.3217 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7691 - loss: 0.4681\n",
      "Epoch 64: val_loss did not improve from 0.38175\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.7692 - loss: 0.4681 - val_accuracy: 0.5000 - val_loss: 1.4757 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8054 - loss: 0.4292\n",
      "Epoch 65: val_loss did not improve from 0.38175\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8053 - loss: 0.4294 - val_accuracy: 0.6210 - val_loss: 0.7574 - learning_rate: 2.0000e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7971 - loss: 0.4513\n",
      "Epoch 66: val_loss did not improve from 0.38175\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.7971 - loss: 0.4511 - val_accuracy: 0.7177 - val_loss: 0.5870 - learning_rate: 2.0000e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8162 - loss: 0.4116\n",
      "Epoch 67: val_loss improved from 0.38175 to 0.29709, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.8163 - loss: 0.4113 - val_accuracy: 0.8871 - val_loss: 0.2971 - learning_rate: 2.0000e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8621 - loss: 0.3591\n",
      "Epoch 68: val_loss improved from 0.29709 to 0.29375, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3s/step - accuracy: 0.8620 - loss: 0.3591 - val_accuracy: 0.8871 - val_loss: 0.2937 - learning_rate: 2.0000e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8136 - loss: 0.3927\n",
      "Epoch 69: val_loss did not improve from 0.29375\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8135 - loss: 0.3929 - val_accuracy: 0.7661 - val_loss: 0.5407 - learning_rate: 2.0000e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8335 - loss: 0.3835\n",
      "Epoch 70: val_loss did not improve from 0.29375\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8335 - loss: 0.3835 - val_accuracy: 0.8710 - val_loss: 0.3240 - learning_rate: 2.0000e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8342 - loss: 0.3809\n",
      "Epoch 71: val_loss did not improve from 0.29375\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8343 - loss: 0.3807 - val_accuracy: 0.8387 - val_loss: 0.3548 - learning_rate: 2.0000e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8240 - loss: 0.3865\n",
      "Epoch 72: val_loss did not improve from 0.29375\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8240 - loss: 0.3865 - val_accuracy: 0.8065 - val_loss: 0.3696 - learning_rate: 2.0000e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8607 - loss: 0.3431\n",
      "Epoch 73: val_loss did not improve from 0.29375\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8604 - loss: 0.3436 - val_accuracy: 0.8710 - val_loss: 0.3234 - learning_rate: 2.0000e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8608 - loss: 0.3553\n",
      "Epoch 74: val_loss improved from 0.29375 to 0.28650, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3s/step - accuracy: 0.8605 - loss: 0.3554 - val_accuracy: 0.8871 - val_loss: 0.2865 - learning_rate: 4.0000e-07\n",
      "Epoch 75/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8496 - loss: 0.3411\n",
      "Epoch 75: val_loss improved from 0.28650 to 0.27106, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.8495 - loss: 0.3413 - val_accuracy: 0.8871 - val_loss: 0.2711 - learning_rate: 4.0000e-07\n",
      "Epoch 76/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8461 - loss: 0.3503\n",
      "Epoch 76: val_loss did not improve from 0.27106\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8461 - loss: 0.3503 - val_accuracy: 0.8790 - val_loss: 0.3094 - learning_rate: 4.0000e-07\n",
      "Epoch 77/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8582 - loss: 0.2974\n",
      "Epoch 77: val_loss did not improve from 0.27106\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8582 - loss: 0.2979 - val_accuracy: 0.8710 - val_loss: 0.2827 - learning_rate: 4.0000e-07\n",
      "Epoch 78/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8224 - loss: 0.3659\n",
      "Epoch 78: val_loss did not improve from 0.27106\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8226 - loss: 0.3657 - val_accuracy: 0.8871 - val_loss: 0.2875 - learning_rate: 4.0000e-07\n",
      "Epoch 79/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8472 - loss: 0.3368\n",
      "Epoch 79: val_loss improved from 0.27106 to 0.26519, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.8472 - loss: 0.3369 - val_accuracy: 0.8871 - val_loss: 0.2652 - learning_rate: 4.0000e-07\n",
      "Epoch 80/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8132 - loss: 0.3611\n",
      "Epoch 80: val_loss did not improve from 0.26519\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8133 - loss: 0.3611 - val_accuracy: 0.8871 - val_loss: 0.2658 - learning_rate: 4.0000e-07\n",
      "Epoch 81/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8460 - loss: 0.3367\n",
      "Epoch 81: val_loss did not improve from 0.26519\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 3s/step - accuracy: 0.8458 - loss: 0.3368 - val_accuracy: 0.8790 - val_loss: 0.2669 - learning_rate: 4.0000e-07\n",
      "Epoch 82/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8670 - loss: 0.3023\n",
      "Epoch 82: val_loss did not improve from 0.26519\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8669 - loss: 0.3026 - val_accuracy: 0.9032 - val_loss: 0.2972 - learning_rate: 4.0000e-07\n",
      "Epoch 83/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8401 - loss: 0.3728\n",
      "Epoch 83: val_loss did not improve from 0.26519\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8403 - loss: 0.3725 - val_accuracy: 0.8952 - val_loss: 0.2780 - learning_rate: 4.0000e-07\n",
      "Epoch 84/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8793 - loss: 0.2961\n",
      "Epoch 84: val_loss did not improve from 0.26519\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 8.00000009348878e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - accuracy: 0.8792 - loss: 0.2964 - val_accuracy: 0.8952 - val_loss: 0.2702 - learning_rate: 4.0000e-07\n",
      "Epoch 85/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8555 - loss: 0.3451\n",
      "Epoch 85: val_loss did not improve from 0.26519\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 3s/step - accuracy: 0.8556 - loss: 0.3448 - val_accuracy: 0.9032 - val_loss: 0.2707 - learning_rate: 8.0000e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8622 - loss: 0.3118\n",
      "Epoch 86: val_loss did not improve from 0.26519\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8622 - loss: 0.3117 - val_accuracy: 0.9113 - val_loss: 0.2696 - learning_rate: 8.0000e-08\n",
      "Epoch 87/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8528 - loss: 0.3155\n",
      "Epoch 87: val_loss improved from 0.26519 to 0.26366, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.8531 - loss: 0.3154 - val_accuracy: 0.9032 - val_loss: 0.2637 - learning_rate: 8.0000e-08\n",
      "Epoch 88/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8702 - loss: 0.2980\n",
      "Epoch 88: val_loss improved from 0.26366 to 0.25842, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 3s/step - accuracy: 0.8701 - loss: 0.2983 - val_accuracy: 0.9113 - val_loss: 0.2584 - learning_rate: 8.0000e-08\n",
      "Epoch 89/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8705 - loss: 0.2907\n",
      "Epoch 89: val_loss did not improve from 0.25842\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8705 - loss: 0.2909 - val_accuracy: 0.8952 - val_loss: 0.2669 - learning_rate: 8.0000e-08\n",
      "Epoch 90/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8634 - loss: 0.3223\n",
      "Epoch 90: val_loss improved from 0.25842 to 0.25603, saving model to results\\ResNet152_full_monty_bs16\\best_model.keras\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - accuracy: 0.8635 - loss: 0.3223 - val_accuracy: 0.9113 - val_loss: 0.2560 - learning_rate: 8.0000e-08\n",
      "Epoch 91/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8676 - loss: 0.3070\n",
      "Epoch 91: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8675 - loss: 0.3071 - val_accuracy: 0.9113 - val_loss: 0.2578 - learning_rate: 8.0000e-08\n",
      "Epoch 92/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8720 - loss: 0.3031\n",
      "Epoch 92: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8719 - loss: 0.3033 - val_accuracy: 0.9113 - val_loss: 0.2588 - learning_rate: 8.0000e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8603 - loss: 0.3020\n",
      "Epoch 93: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 3s/step - accuracy: 0.8602 - loss: 0.3024 - val_accuracy: 0.9113 - val_loss: 0.2661 - learning_rate: 8.0000e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8679 - loss: 0.3113\n",
      "Epoch 94: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8681 - loss: 0.3110 - val_accuracy: 0.9032 - val_loss: 0.2603 - learning_rate: 8.0000e-08\n",
      "Epoch 95/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8710 - loss: 0.3029\n",
      "Epoch 95: val_loss did not improve from 0.25603\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.5999999902760466e-08.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8709 - loss: 0.3031 - val_accuracy: 0.9113 - val_loss: 0.2611 - learning_rate: 8.0000e-08\n",
      "Epoch 96/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8558 - loss: 0.2955\n",
      "Epoch 96: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8559 - loss: 0.2955 - val_accuracy: 0.9113 - val_loss: 0.2602 - learning_rate: 1.6000e-08\n",
      "Epoch 97/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8763 - loss: 0.2844\n",
      "Epoch 97: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8761 - loss: 0.2846 - val_accuracy: 0.9113 - val_loss: 0.2598 - learning_rate: 1.6000e-08\n",
      "Epoch 98/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8729 - loss: 0.2992\n",
      "Epoch 98: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8727 - loss: 0.2995 - val_accuracy: 0.9032 - val_loss: 0.2623 - learning_rate: 1.6000e-08\n",
      "Epoch 99/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8534 - loss: 0.3489\n",
      "Epoch 99: val_loss did not improve from 0.25603\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8534 - loss: 0.3486 - val_accuracy: 0.9032 - val_loss: 0.2606 - learning_rate: 1.6000e-08\n",
      "Epoch 100/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8521 - loss: 0.3153\n",
      "Epoch 100: val_loss did not improve from 0.25603\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.1999999094978194e-09.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.8522 - loss: 0.3153 - val_accuracy: 0.9032 - val_loss: 0.2609 - learning_rate: 1.6000e-08\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "\n",
      "Generating and saving performance plot...\n",
      "\n",
      "--- ResNet152_full_monty_bs16 Final Test Set Evaluation ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       Healty Brinjal       0.87      0.81      0.84       103\n",
      "Shoot and Fruit Borer       0.87      0.92      0.89       145\n",
      "\n",
      "             accuracy                           0.87       248\n",
      "            macro avg       0.87      0.86      0.87       248\n",
      "         weighted avg       0.87      0.87      0.87       248\n",
      "\n",
      "\n",
      "Updating summary results file...\n",
      "\n",
      "--- Experiment for ResNet152_full_monty_bs16 is complete. Total time: 03:45:11 ---\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    model_choice=\"ResNet152\",\n",
    "    training_mode='full_monty'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a05dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53855c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28da54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
