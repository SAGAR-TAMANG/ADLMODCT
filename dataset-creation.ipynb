{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0610c47",
   "metadata": {},
   "source": [
    "## Create  Datasets used in this Project using this ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba7fa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b12530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'processed_data\\BrinjalFruitX_299x299' is ready.\n",
      "Starting image loading and preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 5/5 [00:47<00:00,  9.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading complete.\n",
      "Converted to NumPy arrays. Image data shape: (1802, 299, 299, 3), Labels shape: (1802,)\n",
      "Data splitting complete:\n",
      "  Training set:   1260 samples\n",
      "  Validation set: 181 samples\n",
      "  Test set:       361 samples\n",
      "Saving processed data to .npy files...\n",
      "All data has been processed and saved successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define paths and parameters\n",
    "RAW_DATA_DIR = os.path.join('raw_data', 'BrinjalFruitX')\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_299x299')\n",
    "IMG_SIZE = (299, 299)\n",
    "TEST_SPLIT_SIZE = 0.20 # 20% for the final test set\n",
    "VALIDATION_SPLIT_SIZE = 0.125 # 10% of the original data (0.125 * 0.8 = 0.1)\n",
    "RANDOM_STATE = 42 # For reproducible splits\n",
    "\n",
    "# --- 2. Create Processed Data Directory ---\n",
    "# This ensures the folder exists before we try to save files to it.\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(f\"Directory '{PROCESSED_DIR}' is ready.\")\n",
    "\n",
    "# --- 3. Load Images and Labels ---\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Get class names from the folder names in the raw data directory\n",
    "class_names = sorted([d for d in os.listdir(RAW_DATA_DIR) if os.path.isdir(os.path.join(RAW_DATA_DIR, d))])\n",
    "# Create a mapping from class name to an integer index\n",
    "label_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(\"Starting image loading and preprocessing...\")\n",
    "# Use tqdm for a progress bar\n",
    "for class_name in tqdm(class_names, desc=\"Processing classes\"):\n",
    "    class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
    "    class_label = label_map[class_name]\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image was loaded correctly\n",
    "        if image is not None:\n",
    "            # Convert image from BGR (OpenCV's default) to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # Resize image to the standard size\n",
    "            image = cv2.resize(image, IMG_SIZE)\n",
    "            \n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "        else:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "\n",
    "print(\"Image loading complete.\")\n",
    "\n",
    "# --- 4. Convert to NumPy Arrays and Normalize ---\n",
    "# Convert lists to NumPy arrays for efficient processing\n",
    "images_np = np.array(images)\n",
    "labels_np = np.array(labels)\n",
    "\n",
    "# Normalize pixel values from the [0, 255] range to the [0.0, 1.0] range\n",
    "images_np = images_np / 255.0\n",
    "\n",
    "print(f\"Converted to NumPy arrays. Image data shape: {images_np.shape}, Labels shape: {labels_np.shape}\")\n",
    "\n",
    "# --- 5. Split the Data ---\n",
    "# First split: separate out the 20% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images_np,\n",
    "    labels_np,\n",
    "    test_size=TEST_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels_np  # Ensures class distribution is similar across splits\n",
    ")\n",
    "\n",
    "# Second split: separate the remaining data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=VALIDATION_SPLIT_SIZE, # 0.125 of the 80% results in 10% of the original data\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_val # Stratify again for the validation split\n",
    ")\n",
    "\n",
    "print(\"Data splitting complete:\")\n",
    "print(f\"  Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"  Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"  Test set:       {X_test.shape[0]} samples\")\n",
    "\n",
    "# --- 6. Save the Processed Data ---\n",
    "print(\"Saving processed data to .npy files...\")\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_train.npy'), y_train)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_val.npy'), y_val)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_test.npy'), y_test)\n",
    "\n",
    "# Save the class names/label map for later use in decoding predictions\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(\"All data has been processed and saved successfully! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2daee963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'processed_data\\BrinjalFruitX_600x600' is ready.\n",
      "Starting image loading and preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 5/5 [00:44<00:00,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading complete.\n",
      "Converted to NumPy arrays. Image data shape: (1802, 600, 600, 3), Labels shape: (1802,)\n",
      "Data splitting complete:\n",
      "  Training set:   1260 samples\n",
      "  Validation set: 181 samples\n",
      "  Test set:       361 samples\n",
      "Saving processed data to .npy files...\n",
      "All data has been processed and saved successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define paths and parameters\n",
    "RAW_DATA_DIR = os.path.join('raw_data', 'BrinjalFruitX')\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_600x600')\n",
    "IMG_SIZE = (600, 600)\n",
    "TEST_SPLIT_SIZE = 0.20 # 20% for the final test set\n",
    "VALIDATION_SPLIT_SIZE = 0.125 # 10% of the original data (0.125 * 0.8 = 0.1)\n",
    "RANDOM_STATE = 42 # For reproducible splits\n",
    "\n",
    "# --- 2. Create Processed Data Directory ---\n",
    "# This ensures the folder exists before we try to save files to it.\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(f\"Directory '{PROCESSED_DIR}' is ready.\")\n",
    "\n",
    "# --- 3. Load Images and Labels ---\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Get class names from the folder names in the raw data directory\n",
    "class_names = sorted([d for d in os.listdir(RAW_DATA_DIR) if os.path.isdir(os.path.join(RAW_DATA_DIR, d))])\n",
    "# Create a mapping from class name to an integer index\n",
    "label_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(\"Starting image loading and preprocessing...\")\n",
    "# Use tqdm for a progress bar\n",
    "for class_name in tqdm(class_names, desc=\"Processing classes\"):\n",
    "    class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
    "    class_label = label_map[class_name]\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image was loaded correctly\n",
    "        if image is not None:\n",
    "            # Convert image from BGR (OpenCV's default) to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # Resize image to the standard size\n",
    "            image = cv2.resize(image, IMG_SIZE)\n",
    "            \n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "        else:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "\n",
    "print(\"Image loading complete.\")\n",
    "\n",
    "# --- 4. Convert to NumPy Arrays and Normalize ---\n",
    "# Convert lists to NumPy arrays for efficient processing\n",
    "images_np = np.array(images)\n",
    "labels_np = np.array(labels)\n",
    "\n",
    "# Normalize pixel values from the [0, 255] range to the [0.0, 1.0] range\n",
    "images_np = images_np / 255.0\n",
    "\n",
    "print(f\"Converted to NumPy arrays. Image data shape: {images_np.shape}, Labels shape: {labels_np.shape}\")\n",
    "\n",
    "# --- 5. Split the Data ---\n",
    "# First split: separate out the 20% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images_np,\n",
    "    labels_np,\n",
    "    test_size=TEST_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels_np  # Ensures class distribution is similar across splits\n",
    ")\n",
    "\n",
    "# Second split: separate the remaining data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=VALIDATION_SPLIT_SIZE, # 0.125 of the 80% results in 10% of the original data\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_val # Stratify again for the validation split\n",
    ")\n",
    "\n",
    "print(\"Data splitting complete:\")\n",
    "print(f\"  Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"  Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"  Test set:       {X_test.shape[0]} samples\")\n",
    "\n",
    "# --- 6. Save the Processed Data ---\n",
    "print(\"Saving processed data to .npy files...\")\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_train.npy'), y_train)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_val.npy'), y_val)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_test.npy'), y_test)\n",
    "\n",
    "# Save the class names/label map for later use in decoding predictions\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(\"All data has been processed and saved successfully! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c8583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'processed_data\\BrinjalFruitX_balanced' is ready.\n",
      "Starting image loading and preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 5/5 [00:44<00:00,  8.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading complete.\n",
      "Converted to NumPy arrays. Image data shape: (1802, 224, 224, 3), Labels shape: (1802,)\n",
      "\n",
      "Data splitting complete:\n",
      "  Original Training set:   1260 samples\n",
      "  Validation set:          181 samples\n",
      "  Test set:                361 samples\n",
      "\n",
      "Handling class imbalance on the training set...\n",
      "\n",
      "--- Class Distribution After Oversampling (Training Set) ---\n",
      "{0: 507, 1: 507, 2: 507, 3: 507, 4: 507}\n",
      "  Balanced Training set:   2535 samples\n",
      "\n",
      "Saving processed data to .npy files...\n",
      "\n",
      "All data has been processed and saved successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "# --- ADDED ---\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define paths and parameters\n",
    "RAW_DATA_DIR = os.path.join('raw_data', 'BrinjalFruitX')\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_balanced') # Changed output dir\n",
    "IMG_SIZE = (224, 224)\n",
    "TEST_SPLIT_SIZE = 0.20 # 20% for the final test set\n",
    "VALIDATION_SPLIT_SIZE = 0.125 # 10% of the original data (0.125 * 0.8 = 0.1)\n",
    "RANDOM_STATE = 42 # For reproducible splits\n",
    "\n",
    "# --- 2. Create Processed Data Directory ---\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(f\"Directory '{PROCESSED_DIR}' is ready.\")\n",
    "\n",
    "# --- 3. Load Images and Labels ---\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "class_names = sorted([d for d in os.listdir(RAW_DATA_DIR) if os.path.isdir(os.path.join(RAW_DATA_DIR, d))])\n",
    "label_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(\"Starting image loading and preprocessing...\")\n",
    "for class_name in tqdm(class_names, desc=\"Processing classes\"):\n",
    "    class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
    "    class_label = label_map[class_name]\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, IMG_SIZE)\n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "        else:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "\n",
    "print(\"Image loading complete.\")\n",
    "\n",
    "# --- 4. Convert to NumPy Arrays and Normalize ---\n",
    "images_np = np.array(images)\n",
    "labels_np = np.array(labels)\n",
    "images_np = images_np / 255.0\n",
    "\n",
    "print(f\"Converted to NumPy arrays. Image data shape: {images_np.shape}, Labels shape: {labels_np.shape}\")\n",
    "\n",
    "# --- 5. Split the Data ---\n",
    "# First split: separate out the 20% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images_np,\n",
    "    labels_np,\n",
    "    test_size=TEST_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels_np\n",
    ")\n",
    "\n",
    "# Second split: separate the remaining data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=VALIDATION_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete:\")\n",
    "print(f\"  Original Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"  Validation set:          {X_val.shape[0]} samples\")\n",
    "print(f\"  Test set:                {X_test.shape[0]} samples\")\n",
    "\n",
    "# --- ADDED: Handle Class Imbalance using Oversampling on the Training Set ONLY ---\n",
    "print(\"\\nHandling class imbalance on the training set...\")\n",
    "\n",
    "# Reshape image data for the oversampler\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Initialize the oversampler\n",
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "\n",
    "# Apply oversampling\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "# Reshape the image data back to its original dimensions\n",
    "X_train_balanced = X_train_resampled.reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "y_train_balanced = y_train_resampled\n",
    "\n",
    "print(\"\\n--- Class Distribution After Oversampling (Training Set) ---\")\n",
    "unique, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print(f\"  Balanced Training set:   {X_train_balanced.shape[0]} samples\")\n",
    "\n",
    "# --- 6. Save the Processed Data ---\n",
    "print(\"\\nSaving processed data to .npy files...\")\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_train.npy'), X_train_balanced)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_train.npy'), y_train_balanced)\n",
    "\n",
    "# Save the original, untouched validation and test sets\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_val.npy'), y_val)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_test.npy'), y_test)\n",
    "\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(\"\\nAll data has been processed and saved successfully! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5cb4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'processed_data\\BrinjalFruitX_balanced_classless' is ready.\n",
      "Starting image loading and preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 2/2 [01:16<00:00, 38.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading complete.\n",
      "Converted to NumPy arrays. Image data shape: (1239, 224, 224, 3), Labels shape: (1239,)\n",
      "\n",
      "Data splitting complete:\n",
      "  Original Training set:   867 samples\n",
      "  Validation set:          124 samples\n",
      "  Test set:                248 samples\n",
      "\n",
      "Handling class imbalance on the training set...\n",
      "\n",
      "--- Class Distribution After Oversampling (Training Set) ---\n",
      "{0: 507, 1: 507}\n",
      "  Balanced Training set:   1014 samples\n",
      "\n",
      "Saving processed data to .npy files...\n",
      "\n",
      "All data has been processed and saved successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "# --- ADDED ---\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define paths and parameters\n",
    "RAW_DATA_DIR = os.path.join('raw_data', 'BrinjalFruitX')\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_balanced_classless') # Changed output dir\n",
    "IMG_SIZE = (224, 224)\n",
    "TEST_SPLIT_SIZE = 0.20 # 20% for the final test set\n",
    "VALIDATION_SPLIT_SIZE = 0.125 # 10% of the original data (0.125 * 0.8 = 0.1)\n",
    "RANDOM_STATE = 42 # For reproducible splits\n",
    "\n",
    "# --- 2. Create Processed Data Directory ---\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(f\"Directory '{PROCESSED_DIR}' is ready.\")\n",
    "\n",
    "# --- 3. Load Images and Labels ---\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "class_names = sorted([d for d in os.listdir(RAW_DATA_DIR) if os.path.isdir(os.path.join(RAW_DATA_DIR, d))])\n",
    "label_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(\"Starting image loading and preprocessing...\")\n",
    "for class_name in tqdm(class_names, desc=\"Processing classes\"):\n",
    "    class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
    "    class_label = label_map[class_name]\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, IMG_SIZE)\n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "        else:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "\n",
    "print(\"Image loading complete.\")\n",
    "\n",
    "# --- 4. Convert to NumPy Arrays and Normalize ---\n",
    "images_np = np.array(images)\n",
    "labels_np = np.array(labels)\n",
    "images_np = images_np / 255.0\n",
    "\n",
    "print(f\"Converted to NumPy arrays. Image data shape: {images_np.shape}, Labels shape: {labels_np.shape}\")\n",
    "\n",
    "# --- 5. Split the Data ---\n",
    "# First split: separate out the 20% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images_np,\n",
    "    labels_np,\n",
    "    test_size=TEST_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels_np\n",
    ")\n",
    "\n",
    "# Second split: separate the remaining data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=VALIDATION_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete:\")\n",
    "print(f\"  Original Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"  Validation set:          {X_val.shape[0]} samples\")\n",
    "print(f\"  Test set:                {X_test.shape[0]} samples\")\n",
    "\n",
    "# --- ADDED: Handle Class Imbalance using Oversampling on the Training Set ONLY ---\n",
    "print(\"\\nHandling class imbalance on the training set...\")\n",
    "\n",
    "# Reshape image data for the oversampler\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Initialize the oversampler\n",
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "\n",
    "# Apply oversampling\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "# Reshape the image data back to its original dimensions\n",
    "X_train_balanced = X_train_resampled.reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "y_train_balanced = y_train_resampled\n",
    "\n",
    "print(\"\\n--- Class Distribution After Oversampling (Training Set) ---\")\n",
    "unique, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print(f\"  Balanced Training set:   {X_train_balanced.shape[0]} samples\")\n",
    "\n",
    "# --- 6. Save the Processed Data ---\n",
    "print(\"\\nSaving processed data to .npy files...\")\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_train.npy'), X_train_balanced)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_train.npy'), y_train_balanced)\n",
    "\n",
    "# Save the original, untouched validation and test sets\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_val.npy'), y_val)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_test.npy'), y_test)\n",
    "\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(\"\\nAll data has been processed and saved successfully! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c42d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'processed_data\\BrinjalFruitX_299x299_balanced_classless' is ready.\n",
      "Starting image loading and preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 2/2 [00:35<00:00, 17.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading complete.\n",
      "Converted to NumPy arrays. Image data shape: (1239, 299, 299, 3), Labels shape: (1239,)\n",
      "\n",
      "Data splitting complete:\n",
      "  Original Training set:   867 samples\n",
      "  Validation set:          124 samples\n",
      "  Test set:                248 samples\n",
      "\n",
      "Handling class imbalance on the training set...\n",
      "\n",
      "--- Class Distribution After Oversampling (Training Set) ---\n",
      "{0: 507, 1: 507}\n",
      "  Balanced Training set:   1014 samples\n",
      "\n",
      "Saving processed data to .npy files...\n",
      "\n",
      "All data has been processed and saved successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "# --- ADDED ---\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define paths and parameters\n",
    "RAW_DATA_DIR = os.path.join('raw_data', 'BrinjalFruitX')\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_299x299_balanced_classless') # Changed output dir\n",
    "IMG_SIZE = (299, 299)\n",
    "TEST_SPLIT_SIZE = 0.20 # 20% for the final test set\n",
    "VALIDATION_SPLIT_SIZE = 0.125 # 10% of the original data (0.125 * 0.8 = 0.1)\n",
    "RANDOM_STATE = 42 # For reproducible splits\n",
    "\n",
    "# --- 2. Create Processed Data Directory ---\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(f\"Directory '{PROCESSED_DIR}' is ready.\")\n",
    "\n",
    "# --- 3. Load Images and Labels ---\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "class_names = sorted([d for d in os.listdir(RAW_DATA_DIR) if os.path.isdir(os.path.join(RAW_DATA_DIR, d))])\n",
    "label_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(\"Starting image loading and preprocessing...\")\n",
    "for class_name in tqdm(class_names, desc=\"Processing classes\"):\n",
    "    class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
    "    class_label = label_map[class_name]\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, IMG_SIZE)\n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "        else:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "\n",
    "print(\"Image loading complete.\")\n",
    "\n",
    "# --- 4. Convert to NumPy Arrays and Normalize ---\n",
    "images_np = np.array(images)\n",
    "labels_np = np.array(labels)\n",
    "images_np = images_np / 255.0\n",
    "\n",
    "print(f\"Converted to NumPy arrays. Image data shape: {images_np.shape}, Labels shape: {labels_np.shape}\")\n",
    "\n",
    "# --- 5. Split the Data ---\n",
    "# First split: separate out the 20% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images_np,\n",
    "    labels_np,\n",
    "    test_size=TEST_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels_np\n",
    ")\n",
    "\n",
    "# Second split: separate the remaining data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=VALIDATION_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete:\")\n",
    "print(f\"  Original Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"  Validation set:          {X_val.shape[0]} samples\")\n",
    "print(f\"  Test set:                {X_test.shape[0]} samples\")\n",
    "\n",
    "# --- ADDED: Handle Class Imbalance using Oversampling on the Training Set ONLY ---\n",
    "print(\"\\nHandling class imbalance on the training set...\")\n",
    "\n",
    "# Reshape image data for the oversampler\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Initialize the oversampler\n",
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "\n",
    "# Apply oversampling\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "# Reshape the image data back to its original dimensions\n",
    "X_train_balanced = X_train_resampled.reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "y_train_balanced = y_train_resampled\n",
    "\n",
    "print(\"\\n--- Class Distribution After Oversampling (Training Set) ---\")\n",
    "unique, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print(f\"  Balanced Training set:   {X_train_balanced.shape[0]} samples\")\n",
    "\n",
    "# --- 6. Save the Processed Data ---\n",
    "print(\"\\nSaving processed data to .npy files...\")\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_train.npy'), X_train_balanced)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_train.npy'), y_train_balanced)\n",
    "\n",
    "# Save the original, untouched validation and test sets\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_val.npy'), y_val)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_test.npy'), y_test)\n",
    "\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(\"\\nAll data has been processed and saved successfully! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd44588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'processed_data\\BrinjalFruitX_600x600_balanced_classless' is ready.\n",
      "Starting image loading and preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 2/2 [00:35<00:00, 17.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading complete.\n",
      "Converted to NumPy arrays. Image data shape: (1239, 600, 600, 3), Labels shape: (1239,)\n",
      "\n",
      "Data splitting complete:\n",
      "  Original Training set:   867 samples\n",
      "  Validation set:          124 samples\n",
      "  Test set:                248 samples\n",
      "\n",
      "Handling class imbalance on the training set...\n",
      "\n",
      "--- Class Distribution After Oversampling (Training Set) ---\n",
      "{0: 507, 1: 507}\n",
      "  Balanced Training set:   1014 samples\n",
      "\n",
      "Saving processed data to .npy files...\n",
      "\n",
      "All data has been processed and saved successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "# --- ADDED ---\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define paths and parameters\n",
    "RAW_DATA_DIR = os.path.join('raw_data', 'BrinjalFruitX')\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX_600x600_balanced_classless') # Changed output dir\n",
    "IMG_SIZE = (600, 600)\n",
    "TEST_SPLIT_SIZE = 0.20 # 20% for the final test set\n",
    "VALIDATION_SPLIT_SIZE = 0.125 # 10% of the original data (0.125 * 0.8 = 0.1)\n",
    "RANDOM_STATE = 42 # For reproducible splits\n",
    "\n",
    "# --- 2. Create Processed Data Directory ---\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(f\"Directory '{PROCESSED_DIR}' is ready.\")\n",
    "\n",
    "# --- 3. Load Images and Labels ---\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "class_names = sorted([d for d in os.listdir(RAW_DATA_DIR) if os.path.isdir(os.path.join(RAW_DATA_DIR, d))])\n",
    "label_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(\"Starting image loading and preprocessing...\")\n",
    "for class_name in tqdm(class_names, desc=\"Processing classes\"):\n",
    "    class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
    "    class_label = label_map[class_name]\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, IMG_SIZE)\n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "        else:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "\n",
    "print(\"Image loading complete.\")\n",
    "\n",
    "# --- 4. Convert to NumPy Arrays and Normalize ---\n",
    "images_np = np.array(images)\n",
    "labels_np = np.array(labels)\n",
    "images_np = images_np / 255.0\n",
    "\n",
    "print(f\"Converted to NumPy arrays. Image data shape: {images_np.shape}, Labels shape: {labels_np.shape}\")\n",
    "\n",
    "# --- 5. Split the Data ---\n",
    "# First split: separate out the 20% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images_np,\n",
    "    labels_np,\n",
    "    test_size=TEST_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels_np\n",
    ")\n",
    "\n",
    "# Second split: separate the remaining data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=VALIDATION_SPLIT_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete:\")\n",
    "print(f\"  Original Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"  Validation set:          {X_val.shape[0]} samples\")\n",
    "print(f\"  Test set:                {X_test.shape[0]} samples\")\n",
    "\n",
    "# --- ADDED: Handle Class Imbalance using Oversampling on the Training Set ONLY ---\n",
    "print(\"\\nHandling class imbalance on the training set...\")\n",
    "\n",
    "# Reshape image data for the oversampler\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Initialize the oversampler\n",
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "\n",
    "# Apply oversampling\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "# Reshape the image data back to its original dimensions\n",
    "X_train_balanced = X_train_resampled.reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "y_train_balanced = y_train_resampled\n",
    "\n",
    "print(\"\\n--- Class Distribution After Oversampling (Training Set) ---\")\n",
    "unique, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print(f\"  Balanced Training set:   {X_train_balanced.shape[0]} samples\")\n",
    "\n",
    "# --- 6. Save the Processed Data ---\n",
    "print(\"\\nSaving processed data to .npy files...\")\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_train.npy'), X_train_balanced)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_train.npy'), y_train_balanced)\n",
    "\n",
    "# Save the original, untouched validation and test sets\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_val.npy'), y_val)\n",
    "\n",
    "np.save(os.path.join(PROCESSED_DIR, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(PROCESSED_DIR, 'y_test.npy'), y_test)\n",
    "\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(\"\\nAll data has been processed and saved successfully! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed14a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
